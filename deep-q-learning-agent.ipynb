{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an alternative version of the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code of the DQN agent.\n",
    "\n",
    "Inspired from here: https://medium.com/@hkabhi916/mastering-deep-q-learning-with-pytorch-a-comprehensive-guide-a7e690d644fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.05587,
     "end_time": "2020-09-01T17:19:39.818427",
     "exception": false,
     "start_time": "2020-09-01T17:19:39.762557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termcolor not installed, skipping dependency\n",
      "No pygame installed, ignoring import\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from kaggle_environments import make, evaluate\n",
    "import random\n",
    "\n",
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "EPS_START = 1.0\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY = 0.995\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, insize, action_space):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(insize, 64)\n",
    "        self.layer1 = nn.Linear(64, 32)\n",
    "        self.layer2 = nn.Linear(32, action_space)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = tc.tanh(self.input(x))\n",
    "        x = F.relu(self.input(x))\n",
    "        #x = tc.tanh(self.layer1(x))\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeepQLearner:\n",
    "    \"\"\"The trainer, to be serialised\"\"\"\n",
    "\n",
    "    def __init__(self, config, discount=0.99, learning_rate=0.001):\n",
    "\n",
    "        print(f\"Creating agent with {config}\")\n",
    "        self.square_options = 3  # empty, player 1, player2\n",
    "\n",
    "        # hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = GAMMA\n",
    "        self.epsilon = EPS_START\n",
    "        self.epsilon_decay = EPS_DECAY\n",
    "        self.discount = discount\n",
    "        self.batch_size = BATCH_SIZE\n",
    "\n",
    "        self.memory = deque(maxlen=10000)\n",
    "\n",
    "        self.action_range = config.columns\n",
    "        # E.g. for board states rows*cols that can be in position 0, 1, 2\n",
    "        self.state_len = config.rows * config.columns\n",
    "\n",
    "        self.model = DQN(self.state_len, self.action_range)\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def act(self, board):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_range)\n",
    "        state_tensor = torch.as_tensor(board, dtype=torch.float)\n",
    "        action_predictions = self.model(state_tensor)\n",
    "        return torch.argmax(action_predictions).item()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                next_rewards = torch.max(self.model(torch.tensor(next_state, dtype=torch.float32))).item()\n",
    "                #print(f\"Next rewards: {next_rewards}\")\n",
    "                target = reward + self.discount * next_rewards\n",
    "            target_f = self.model(torch.tensor(state, dtype=torch.float32)).detach().numpy()\n",
    "            target_f[action] = target  # WHY? because we know the reward for this selected action, so we put it in the y (target/label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss_function(torch.tensor(target_f), self.model(torch.tensor(state, dtype=torch.float32)))\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if self.epsilon > EPS_END:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def save(self, filename=\"model.pt\"):\n",
    "        print(f\"Saving {filename} (whole model, includes file path)\")\n",
    "        torch.save(self.model, filename)\n",
    "\n",
    "    def save_state_dict(self, filename=\"model_state_dict.pt\"):\n",
    "        print(f\"Saving {filename} (state dict only)\")\n",
    "        torch.save(self.model.state_dict(), filename)\n",
    "\n",
    "    def load(self, filename=\"model.pt\"):\n",
    "        print(f\"Loading {filename}\")\n",
    "        self.model = torch.load(filename)\n",
    "\n",
    "    def load_from_state_dict(self, filename=\"model_state_dict.pt\"):\n",
    "        print(f\"Loading model from state dict {filename}\")\n",
    "        self.model = FFDNN(self.state_len, self.action_range)\n",
    "        state_dict = torch.load(filename)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for custom reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_windows(grid, num_discs, piece, config):\n",
    "    num_windows = 0\n",
    "    # horizontal\n",
    "    for row in range(config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[row, col:col+config.inarow])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # vertical\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns):\n",
    "            window = list(grid[row:row+config.inarow, col])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # positive diagonal\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # negative diagonal\n",
    "    for row in range(config.inarow-1, config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    return num_windows\n",
    "\n",
    "def drop_piece(grid, col, mark, config):\n",
    "    next_grid = grid.copy()\n",
    "    for row in range(config.rows-1, -1, -1):\n",
    "        if next_grid[row][col] == 0:\n",
    "            break\n",
    "    next_grid[row][col] = mark\n",
    "    return next_grid\n",
    "\n",
    "def check_window(window, num_discs, piece, config):\n",
    "    return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n",
    "\n",
    "def get_heuristic(grid, mark, config):\n",
    "    score = 0\n",
    "    for i in range(config.inarow):\n",
    "        num = count_windows(grid, i+1, mark, config)\n",
    "        if (i==(config.inarow-1) and num>=1):\n",
    "            return 2**(config.inarow+3)\n",
    "        score += 2**(i+1) * num\n",
    "        num_opp = count_windows(grid, i+1, mark%2+1, config)\n",
    "        if (i==(config.inarow-1) and num_opp>=1):\n",
    "            return -2**(2*(config.inarow+3))\n",
    "        score -= 2**(2*(i+1)) * num_opp\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Obs: {'remainingOverageTime': 60, 'step': 0, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mark': 1}\n",
      "Episode: 1, Total Reward: -98\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 2, Total Reward: -100116\n",
      "Episode: 3, Total Reward: -268\n",
      "Episode: 4, Total Reward: -506\n",
      "Episode: 5, Total Reward: -84\n",
      "Episode: 6, Total Reward: -204\n",
      "Episode: 7, Total Reward: -164\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 8, Total Reward: -99960\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 9, Total Reward: -100042\n",
      "Episode: 10, Total Reward: -106\n",
      "Episode: 11, Total Reward: -34\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 12, Total Reward: -100044\n",
      "Episode: 13, Total Reward: -80\n",
      "Episode: 14, Total Reward: -200\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 15, Total Reward: -100032\n",
      "Episode: 16, Total Reward: -178\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 17, Total Reward: -100016\n",
      "Episode: 18, Total Reward: -114\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 19, Total Reward: -100012\n",
      "Episode: 20, Total Reward: -220\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 21, Total Reward: -100098\n",
      "Episode: 22, Total Reward: -118\n",
      "Episode: 23, Total Reward: -138\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 24, Total Reward: -100026\n",
      "Episode: 25, Total Reward: -60\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 26, Total Reward: -100120\n",
      "Episode: 27, Total Reward: -66\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 28, Total Reward: -100182\n",
      "Episode: 29, Total Reward: -64\n",
      "Episode: 30, Total Reward: -198\n",
      "Episode: 31, Total Reward: -548\n",
      "Episode: 32, Total Reward: -146\n",
      "Episode: 33, Total Reward: -4\n",
      "Episode: 34, Total Reward: -110\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 35, Total Reward: -99908\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 36, Total Reward: -100178\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 37, Total Reward: -100080\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 38, Total Reward: -100228\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 39, Total Reward: -100024\n",
      "Episode: 40, Total Reward: -124\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 41, Total Reward: -100142\n",
      "Episode: 42, Total Reward: -236\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 43, Total Reward: -100106\n",
      "Episode: 44, Total Reward: -104\n",
      "Episode: 45, Total Reward: -184\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 46, Total Reward: -100058\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 47, Total Reward: -99996\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 48, Total Reward: -100192\n",
      "Episode: 49, Total Reward: -136\n",
      "Episode: 50, Total Reward: -94\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 51, Total Reward: -100110\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 52, Total Reward: -99962\n",
      "Episode: 53, Total Reward: -14\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 54, Total Reward: -100062\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 55, Total Reward: -100190\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 56, Total Reward: -100074\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 57, Total Reward: -100012\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 58, Total Reward: -99998\n",
      "Episode: 59, Total Reward: -74\n",
      "Episode: 60, Total Reward: -72\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 61, Total Reward: -100146\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 62, Total Reward: -100124\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 63, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 64, Total Reward: -100174\n",
      "Episode: 65, Total Reward: -136\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 66, Total Reward: -100094\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 67, Total Reward: -100216\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 68, Total Reward: -100102\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 69, Total Reward: -100152\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 70, Total Reward: -100114\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 71, Total Reward: -100132\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 72, Total Reward: -100030\n",
      "Episode: 73, Total Reward: -106\n",
      "Episode: 74, Total Reward: -96\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 75, Total Reward: -99970\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 76, Total Reward: -100022\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 77, Total Reward: -100120\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 78, Total Reward: -100010\n",
      "Episode: 79, Total Reward: -302\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 80, Total Reward: -100110\n",
      "Episode: 81, Total Reward: -130\n",
      "Episode: 82, Total Reward: -166\n",
      "Episode: 83, Total Reward: -160\n",
      "Episode: 84, Total Reward: -224\n",
      "Episode: 85, Total Reward: -120\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 86, Total Reward: -100124\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 87, Total Reward: -100102\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 88, Total Reward: -100108\n",
      "Episode: 89, Total Reward: -316\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 90, Total Reward: -100128\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 91, Total Reward: -100024\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 92, Total Reward: -100056\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 93, Total Reward: -99986\n",
      "Episode: 94, Total Reward: -242\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 95, Total Reward: -100032\n",
      "Episode: 96, Total Reward: -194\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 97, Total Reward: -100130\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 98, Total Reward: -100078\n",
      "Episode: 99, Total Reward: -168\n",
      "Episode: 100, Total Reward: -152\n",
      "Episode: 101, Total Reward: -50\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 102, Total Reward: -100138\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 103, Total Reward: -100114\n",
      "Episode: 104, Total Reward: -126\n",
      "Episode: 105, Total Reward: -126\n",
      "Episode: 106, Total Reward: -196\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 107, Total Reward: -100146\n",
      "Episode: 108, Total Reward: -130\n",
      "Episode: 109, Total Reward: -120\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 110, Total Reward: -100010\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 111, Total Reward: -100012\n",
      "Episode: 112, Total Reward: 16\n",
      "Episode: 113, Total Reward: -30\n",
      "Episode: 114, Total Reward: -134\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 115, Total Reward: -100024\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 116, Total Reward: -100020\n",
      "Episode: 117, Total Reward: -328\n",
      "Episode: 118, Total Reward: -276\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 119, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 120, Total Reward: -100068\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 121, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 122, Total Reward: -100012\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 123, Total Reward: -100098\n",
      "Episode: 124, Total Reward: -292\n",
      "Episode: 125, Total Reward: -46\n",
      "Episode: 126, Total Reward: -84\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 127, Total Reward: -100138\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 128, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 129, Total Reward: -100068\n",
      "Episode: 130, Total Reward: -168\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 131, Total Reward: -100098\n",
      "Episode: 132, Total Reward: -162\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 133, Total Reward: -100122\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 134, Total Reward: -100024\n",
      "Episode: 135, Total Reward: -174\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 136, Total Reward: -100206\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 137, Total Reward: -100030\n",
      "Episode: 138, Total Reward: -180\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 139, Total Reward: -100138\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 140, Total Reward: -100154\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 141, Total Reward: -100296\n",
      "Episode: 142, Total Reward: -74\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 143, Total Reward: -99998\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 144, Total Reward: -100000\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 145, Total Reward: -100010\n",
      "Episode: 146, Total Reward: -74\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 147, Total Reward: -100034\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 148, Total Reward: -100370\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 149, Total Reward: -100052\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 150, Total Reward: -100072\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 151, Total Reward: -99986\n",
      "Episode: 152, Total Reward: -108\n",
      "Episode: 153, Total Reward: -74\n",
      "Episode: 154, Total Reward: -98\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 155, Total Reward: -100078\n",
      "Episode: 156, Total Reward: -214\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 157, Total Reward: -100044\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 158, Total Reward: -100010\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 159, Total Reward: -100274\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 160, Total Reward: -100124\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 161, Total Reward: -100100\n",
      "Episode: 162, Total Reward: -88\n",
      "Episode: 163, Total Reward: -148\n",
      "Episode: 164, Total Reward: -166\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 165, Total Reward: -100142\n",
      "Episode: 166, Total Reward: -354\n",
      "Episode: 167, Total Reward: -66\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 168, Total Reward: -100024\n",
      "Episode: 169, Total Reward: -178\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 170, Total Reward: -100024\n",
      "Episode: 171, Total Reward: -58\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 172, Total Reward: -99986\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 173, Total Reward: -100004\n",
      "Episode: 174, Total Reward: -98\n",
      "Episode: 175, Total Reward: -114\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 176, Total Reward: -100082\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 177, Total Reward: -100090\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 178, Total Reward: -100082\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 179, Total Reward: -99994\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 180, Total Reward: -100036\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 181, Total Reward: -100060\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 182, Total Reward: -100166\n",
      "Episode: 183, Total Reward: -58\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 184, Total Reward: -99978\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 185, Total Reward: -99980\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 186, Total Reward: -99978\n",
      "Episode: 187, Total Reward: -162\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 188, Total Reward: -100250\n",
      "Episode: 189, Total Reward: -168\n",
      "Episode: 190, Total Reward: -126\n",
      "Episode: 191, Total Reward: -126\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 192, Total Reward: -100498\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 193, Total Reward: -100012\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 194, Total Reward: -100534\n",
      "Episode: 195, Total Reward: -88\n",
      "Episode: 196, Total Reward: -388\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 197, Total Reward: -100122\n",
      "Episode: 198, Total Reward: -66\n",
      "Episode: 199, Total Reward: -144\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 200, Total Reward: -100052\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 201, Total Reward: -100088\n",
      "Episode: 202, Total Reward: -98\n",
      "Episode: 203, Total Reward: -92\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 204, Total Reward: -100096\n",
      "Episode: 205, Total Reward: -196\n",
      "Episode: 206, Total Reward: -330\n",
      "Episode: 207, Total Reward: -194\n",
      "Episode: 208, Total Reward: -324\n",
      "Episode: 209, Total Reward: -86\n",
      "Episode: 210, Total Reward: -96\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 211, Total Reward: -100044\n",
      "Episode: 212, Total Reward: -202\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 213, Total Reward: -100048\n",
      "Episode: 214, Total Reward: -146\n",
      "Episode: 215, Total Reward: -202\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 216, Total Reward: -100122\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 217, Total Reward: -100052\n",
      "Episode: 218, Total Reward: -106\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 219, Total Reward: -100048\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 220, Total Reward: -100122\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 221, Total Reward: -100052\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 222, Total Reward: -100068\n",
      "Episode: 223, Total Reward: -96\n",
      "Episode: 224, Total Reward: -96\n",
      "Episode: 225, Total Reward: -96\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 226, Total Reward: -100006\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 227, Total Reward: -100048\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 228, Total Reward: -100092\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 229, Total Reward: -100090\n",
      "Episode: 230, Total Reward: -138\n",
      "Episode: 231, Total Reward: -166\n",
      "Episode: 232, Total Reward: -160\n",
      "Episode: 233, Total Reward: -96\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 234, Total Reward: -100088\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 235, Total Reward: -100052\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 236, Total Reward: -99978\n",
      "Episode: 237, Total Reward: -68\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 238, Total Reward: -100002\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 239, Total Reward: -100048\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 240, Total Reward: -100118\n",
      "Episode: 241, Total Reward: -148\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 242, Total Reward: -100068\n",
      "Episode: 243, Total Reward: -96\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 244, Total Reward: -100036\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 245, Total Reward: -100076\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 246, Total Reward: -100076\n",
      "Episode: 247, Total Reward: -114\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 248, Total Reward: -100076\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 249, Total Reward: -100076\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 250, Total Reward: -100048\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 251, Total Reward: -100032\n",
      "Episode: 252, Total Reward: -180\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 253, Total Reward: -100032\n",
      "Episode: 254, Total Reward: -42\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 255, Total Reward: -99922\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 256, Total Reward: -99936\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 257, Total Reward: -99920\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 258, Total Reward: -99956\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 259, Total Reward: -100042\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 260, Total Reward: -99956\n",
      "Episode: 261, Total Reward: -16\n",
      "Episode: 262, Total Reward: -78\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 263, Total Reward: -99944\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 264, Total Reward: -100064\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 265, Total Reward: -100132\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 266, Total Reward: -100064\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 267, Total Reward: -100122\n",
      "Episode: 268, Total Reward: -182\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 269, Total Reward: -100090\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 270, Total Reward: -100066\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 271, Total Reward: -100082\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 272, Total Reward: -100072\n",
      "Episode: 273, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 274, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 275, Total Reward: -100070\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 276, Total Reward: -100138\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 277, Total Reward: -100100\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 278, Total Reward: -100114\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 279, Total Reward: -100078\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 280, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 281, Total Reward: -100150\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 282, Total Reward: -100030\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 283, Total Reward: -99952\n",
      "Episode: 284, Total Reward: -224\n",
      "Episode: 285, Total Reward: -32\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 286, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 287, Total Reward: -100078\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 288, Total Reward: -100094\n",
      "Episode: 289, Total Reward: -118\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 290, Total Reward: -100142\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 291, Total Reward: -100080\n",
      "Episode: 292, Total Reward: -242\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 293, Total Reward: -100188\n",
      "Episode: 294, Total Reward: -174\n",
      "Episode: 295, Total Reward: -120\n",
      "Episode: 296, Total Reward: -116\n",
      "Episode: 297, Total Reward: -88\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 298, Total Reward: -99952\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 299, Total Reward: -99978\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 300, Total Reward: -99964\n",
      "Episode: 301, Total Reward: -142\n",
      "Episode: 302, Total Reward: -22\n",
      "Episode: 303, Total Reward: -236\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 304, Total Reward: -100058\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 305, Total Reward: -100074\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 306, Total Reward: -100182\n",
      "Episode: 307, Total Reward: -36\n",
      "Episode: 308, Total Reward: -2\n",
      "Episode: 309, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 310, Total Reward: -100124\n",
      "Episode: 311, Total Reward: -168\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 312, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 313, Total Reward: -100144\n",
      "Episode: 314, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 315, Total Reward: -100078\n",
      "Episode: 316, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 317, Total Reward: -100090\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 318, Total Reward: -100014\n",
      "Episode: 319, Total Reward: -126\n",
      "Episode: 320, Total Reward: -276\n",
      "Episode: 321, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 322, Total Reward: -100228\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 323, Total Reward: -100082\n",
      "Episode: 324, Total Reward: -242\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 325, Total Reward: -100038\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 326, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 327, Total Reward: -100096\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 328, Total Reward: -100094\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 329, Total Reward: -100078\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 330, Total Reward: -100058\n",
      "Episode: 331, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 332, Total Reward: -100048\n",
      "Episode: 333, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 334, Total Reward: -100136\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 335, Total Reward: -100176\n",
      "Episode: 336, Total Reward: -238\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 337, Total Reward: -100122\n",
      "Episode: 338, Total Reward: -168\n",
      "Episode: 339, Total Reward: -278\n",
      "Episode: 340, Total Reward: -82\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 341, Total Reward: -100144\n",
      "Episode: 342, Total Reward: -136\n",
      "Episode: 343, Total Reward: -88\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 344, Total Reward: -99978\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 345, Total Reward: -99958\n",
      "Episode: 346, Total Reward: -22\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 347, Total Reward: -99990\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 348, Total Reward: -99914\n",
      "Episode: 349, Total Reward: -40\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 350, Total Reward: -99956\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 351, Total Reward: -99958\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 352, Total Reward: -100188\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 353, Total Reward: -100054\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 354, Total Reward: -100114\n",
      "Episode: 355, Total Reward: -40\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 356, Total Reward: -99794\n",
      "Episode: 357, Total Reward: -88\n",
      "Episode: 358, Total Reward: -42\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 359, Total Reward: -100170\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 360, Total Reward: -100078\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 361, Total Reward: -100090\n",
      "Episode: 362, Total Reward: -84\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 363, Total Reward: -100026\n",
      "Episode: 364, Total Reward: -246\n",
      "Episode: 365, Total Reward: -292\n",
      "Episode: 366, Total Reward: -138\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 367, Total Reward: -100112\n",
      "Episode: 368, Total Reward: -50\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 369, Total Reward: -100082\n",
      "Episode: 370, Total Reward: -126\n",
      "Episode: 371, Total Reward: -44\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 372, Total Reward: -100018\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 373, Total Reward: -100322\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 374, Total Reward: -100048\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 375, Total Reward: -100048\n",
      "Episode: 376, Total Reward: -156\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 377, Total Reward: -100092\n",
      "Episode: 378, Total Reward: -158\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 379, Total Reward: -100184\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 380, Total Reward: -100110\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 381, Total Reward: -99912\n",
      "Episode: 382, Total Reward: -102\n",
      "Episode: 383, Total Reward: -126\n",
      "Episode: 384, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 385, Total Reward: -100094\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 386, Total Reward: -100020\n",
      "Episode: 387, Total Reward: -10\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 388, Total Reward: -99918\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 389, Total Reward: -99922\n",
      "Episode: 390, Total Reward: -60\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 391, Total Reward: -99912\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 392, Total Reward: -99918\n",
      "Episode: 393, Total Reward: -318\n",
      "Episode: 394, Total Reward: -42\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 395, Total Reward: -99920\n",
      "Episode: 396, Total Reward: -42\n",
      "Episode: 397, Total Reward: -138\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 398, Total Reward: -100020\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 399, Total Reward: -99990\n",
      "Episode: 400, Total Reward: -58\n",
      "Episode: 401, Total Reward: -88\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 402, Total Reward: -100062\n",
      "Episode: 403, Total Reward: -252\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 404, Total Reward: -100036\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 405, Total Reward: -99974\n",
      "Episode: 406, Total Reward: -58\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 407, Total Reward: -99972\n",
      "Episode: 408, Total Reward: -40\n",
      "Episode: 409, Total Reward: -112\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 410, Total Reward: -99968\n",
      "Episode: 411, Total Reward: -46\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 412, Total Reward: -100118\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 413, Total Reward: -99996\n",
      "Episode: 414, Total Reward: -176\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 415, Total Reward: -100036\n",
      "Episode: 416, Total Reward: -96\n",
      "Episode: 417, Total Reward: -80\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 418, Total Reward: -100004\n",
      "Episode: 419, Total Reward: -80\n",
      "Episode: 420, Total Reward: -80\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 421, Total Reward: -100014\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 422, Total Reward: -100004\n",
      "Episode: 423, Total Reward: -58\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 424, Total Reward: -100016\n",
      "Episode: 425, Total Reward: -198\n",
      "Episode: 426, Total Reward: -58\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 427, Total Reward: -100022\n",
      "Episode: 428, Total Reward: -100\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 429, Total Reward: -99984\n",
      "Episode: 430, Total Reward: -142\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 431, Total Reward: -99974\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 432, Total Reward: -100012\n",
      "Episode: 433, Total Reward: -102\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 434, Total Reward: -100060\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 435, Total Reward: -100036\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 436, Total Reward: -100066\n",
      "Episode: 437, Total Reward: -128\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 438, Total Reward: -100134\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 439, Total Reward: -100050\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 440, Total Reward: -100006\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 441, Total Reward: -100030\n",
      "Episode: 442, Total Reward: -438\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 443, Total Reward: -100654\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 444, Total Reward: -100044\n",
      "Episode: 445, Total Reward: -130\n",
      "Episode: 446, Total Reward: -132\n",
      "Episode: 447, Total Reward: -42\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 448, Total Reward: -100050\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 449, Total Reward: -100092\n",
      "Episode: 450, Total Reward: -172\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 451, Total Reward: -100078\n",
      "Episode: 452, Total Reward: -104\n",
      "Episode: 453, Total Reward: -166\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 454, Total Reward: -100104\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 455, Total Reward: -100078\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 456, Total Reward: -100078\n",
      "Episode: 457, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 458, Total Reward: -100068\n",
      "Episode: 459, Total Reward: -184\n",
      "Episode: 460, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 461, Total Reward: -100154\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 462, Total Reward: -100074\n",
      "Episode: 463, Total Reward: -136\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 464, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 465, Total Reward: -100078\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 466, Total Reward: -100060\n",
      "Episode: 467, Total Reward: -126\n",
      "Episode: 468, Total Reward: -176\n",
      "Episode: 469, Total Reward: -130\n",
      "Episode: 470, Total Reward: -162\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 471, Total Reward: -100138\n",
      "Episode: 472, Total Reward: -126\n",
      "Episode: 473, Total Reward: -166\n",
      "Episode: 474, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 475, Total Reward: -100082\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 476, Total Reward: -100084\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 477, Total Reward: -100072\n",
      "Episode: 478, Total Reward: -110\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 479, Total Reward: -100078\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 480, Total Reward: -100100\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 481, Total Reward: -100078\n",
      "Episode: 482, Total Reward: -122\n",
      "Episode: 483, Total Reward: -144\n",
      "Episode: 484, Total Reward: -110\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 485, Total Reward: -100008\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 486, Total Reward: -99990\n",
      "Episode: 487, Total Reward: -24\n",
      "Episode: 488, Total Reward: -76\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 489, Total Reward: -100034\n",
      "Episode: 490, Total Reward: -40\n",
      "Episode: 491, Total Reward: -94\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 492, Total Reward: -100252\n",
      "Episode: 493, Total Reward: -150\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 494, Total Reward: -99994\n",
      "Episode: 495, Total Reward: -82\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 496, Total Reward: -99980\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 497, Total Reward: -100008\n",
      "Episode: 498, Total Reward: -188\n",
      "Episode: 499, Total Reward: -32\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 500, Total Reward: -99978\n",
      "Episode: 501, Total Reward: -102\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 502, Total Reward: -100082\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 503, Total Reward: -100164\n",
      "Episode: 504, Total Reward: -46\n",
      "Episode: 505, Total Reward: -232\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 506, Total Reward: -100150\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 507, Total Reward: -100018\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 508, Total Reward: -100090\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 509, Total Reward: -100062\n",
      "Episode: 510, Total Reward: -250\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 511, Total Reward: -100052\n",
      "Episode: 512, Total Reward: -48\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 513, Total Reward: -100080\n",
      "Episode: 514, Total Reward: -126\n",
      "Episode: 515, Total Reward: -88\n",
      "Episode: 516, Total Reward: -306\n",
      "Episode: 517, Total Reward: -160\n",
      "Episode: 518, Total Reward: -150\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 519, Total Reward: -100144\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 520, Total Reward: -100144\n",
      "Episode: 521, Total Reward: -160\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 522, Total Reward: -100184\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 523, Total Reward: -100228\n",
      "Episode: 524, Total Reward: -230\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 525, Total Reward: -100284\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 526, Total Reward: -100080\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 527, Total Reward: -100018\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 528, Total Reward: -100286\n",
      "Episode: 529, Total Reward: -98\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 530, Total Reward: -99996\n",
      "Episode: 531, Total Reward: -322\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 532, Total Reward: -100354\n",
      "Episode: 533, Total Reward: -212\n",
      "Episode: 534, Total Reward: -108\n",
      "Episode: 535, Total Reward: -152\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 536, Total Reward: -100238\n",
      "Episode: 537, Total Reward: -118\n",
      "Episode: 538, Total Reward: -78\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 539, Total Reward: -100052\n",
      "Episode: 540, Total Reward: -68\n",
      "Episode: 541, Total Reward: -128\n",
      "Episode: 542, Total Reward: -82\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 543, Total Reward: -100176\n",
      "Episode: 544, Total Reward: -328\n",
      "Episode: 545, Total Reward: -288\n",
      "Episode: 546, Total Reward: -246\n",
      "Episode: 547, Total Reward: -120\n",
      "Episode: 548, Total Reward: -282\n",
      "Episode: 549, Total Reward: -482\n",
      "Episode: 550, Total Reward: -156\n",
      "Episode: 551, Total Reward: -88\n",
      "Episode: 552, Total Reward: -82\n",
      "Episode: 553, Total Reward: -96\n",
      "Episode: 554, Total Reward: -64\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 555, Total Reward: -100258\n",
      "Episode: 556, Total Reward: -212\n",
      "Episode: 557, Total Reward: -86\n",
      "Episode: 558, Total Reward: -114\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 559, Total Reward: -100134\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 560, Total Reward: -99978\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 561, Total Reward: -100000\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 562, Total Reward: -100060\n",
      "Episode: 563, Total Reward: -56\n",
      "Episode: 564, Total Reward: -200\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 565, Total Reward: -100130\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 566, Total Reward: -100166\n",
      "Episode: 567, Total Reward: -312\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 568, Total Reward: -100082\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 569, Total Reward: -100138\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 570, Total Reward: -100150\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 571, Total Reward: -100074\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 572, Total Reward: -100120\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 573, Total Reward: -100072\n",
      "Episode: 574, Total Reward: -94\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 575, Total Reward: -99984\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 576, Total Reward: -100080\n",
      "Episode: 577, Total Reward: -86\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 578, Total Reward: -100012\n",
      "Episode: 579, Total Reward: -344\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 580, Total Reward: -100074\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 581, Total Reward: -100014\n",
      "Episode: 582, Total Reward: -128\n",
      "Episode: 583, Total Reward: -626\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 584, Total Reward: -100114\n",
      "Episode: 585, Total Reward: -98\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 586, Total Reward: -100142\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 587, Total Reward: -100086\n",
      "Episode: 588, Total Reward: -440\n",
      "Episode: 589, Total Reward: -98\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 590, Total Reward: -100042\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 591, Total Reward: -100490\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 592, Total Reward: -100010\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 593, Total Reward: -99990\n",
      "Episode: 594, Total Reward: -294\n",
      "Episode: 595, Total Reward: -270\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 596, Total Reward: -100030\n",
      "Episode: 597, Total Reward: -226\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 598, Total Reward: -100084\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 599, Total Reward: -100198\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 600, Total Reward: -100062\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 601, Total Reward: -100178\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 602, Total Reward: -100000\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 603, Total Reward: -100228\n",
      "Episode: 604, Total Reward: -90\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 605, Total Reward: -100484\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 606, Total Reward: -100052\n",
      "Episode: 607, Total Reward: -186\n",
      "Episode: 608, Total Reward: -194\n",
      "Episode: 609, Total Reward: -96\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 610, Total Reward: -100000\n",
      "Episode: 611, Total Reward: -98\n",
      "Episode: 612, Total Reward: -226\n",
      "Episode: 613, Total Reward: -90\n",
      "Episode: 614, Total Reward: -266\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 615, Total Reward: -100078\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 616, Total Reward: -100046\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 617, Total Reward: -100094\n",
      "Episode: 618, Total Reward: -196\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 619, Total Reward: -100144\n",
      "Episode: 620, Total Reward: -130\n",
      "Episode: 621, Total Reward: -168\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 622, Total Reward: -100094\n",
      "Episode: 623, Total Reward: -134\n",
      "Episode: 624, Total Reward: -126\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 625, Total Reward: -100034\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 626, Total Reward: -100098\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 627, Total Reward: -100030\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 628, Total Reward: -100210\n",
      "Episode: 629, Total Reward: -134\n",
      "Episode: 630, Total Reward: -120\n",
      "Episode: 631, Total Reward: -36\n",
      "Episode: 632, Total Reward: -86\n",
      "Episode: 633, Total Reward: -90\n",
      "Episode: 634, Total Reward: -102\n",
      "Episode: 635, Total Reward: -140\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 636, Total Reward: -100082\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 637, Total Reward: -100044\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 638, Total Reward: -100182\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 639, Total Reward: -100090\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 640, Total Reward: -100114\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 641, Total Reward: -100082\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 642, Total Reward: -100034\n",
      "Episode: 643, Total Reward: -270\n",
      "Episode: 644, Total Reward: -150\n",
      "Episode: 645, Total Reward: -170\n",
      "Episode: 646, Total Reward: -58\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 647, Total Reward: -100022\n",
      "Episode: 648, Total Reward: -46\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 649, Total Reward: -100226\n",
      "Episode: 650, Total Reward: -78\n",
      "Episode: 651, Total Reward: -114\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 652, Total Reward: -100136\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 653, Total Reward: -100082\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 654, Total Reward: -100102\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 655, Total Reward: -100304\n",
      "Episode: 656, Total Reward: -46\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 657, Total Reward: -100008\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 658, Total Reward: -100084\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 659, Total Reward: -100062\n",
      "Episode: 660, Total Reward: -64\n",
      "Episode: 661, Total Reward: -146\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 662, Total Reward: -100014\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 663, Total Reward: -100184\n",
      "Episode: 664, Total Reward: -100\n",
      "Episode: 665, Total Reward: -34\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 666, Total Reward: -100044\n",
      "Episode: 667, Total Reward: -148\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 668, Total Reward: -100264\n",
      "Episode: 669, Total Reward: -226\n",
      "Episode: 670, Total Reward: -232\n",
      "Episode: 671, Total Reward: -646\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 672, Total Reward: -100014\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 673, Total Reward: -100020\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 674, Total Reward: -100012\n",
      "Episode: 675, Total Reward: -132\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 676, Total Reward: -100036\n",
      "Episode: 677, Total Reward: -230\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 678, Total Reward: -100018\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 679, Total Reward: -100014\n",
      "Episode: 680, Total Reward: -160\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 681, Total Reward: -100328\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 682, Total Reward: -100032\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 683, Total Reward: -100020\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 684, Total Reward: -100036\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 685, Total Reward: -99996\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 686, Total Reward: -100036\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 687, Total Reward: -100224\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 688, Total Reward: -100036\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 689, Total Reward: -100058\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 690, Total Reward: -100036\n",
      "Episode: 691, Total Reward: -238\n",
      "Episode: 692, Total Reward: -160\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 693, Total Reward: -100050\n",
      "Episode: 694, Total Reward: -76\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 695, Total Reward: -100524\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 696, Total Reward: -100154\n",
      "Episode: 697, Total Reward: -356\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 698, Total Reward: -99994\n",
      "Episode: 699, Total Reward: -46\n",
      "Episode: 700, Total Reward: -84\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 701, Total Reward: -100288\n",
      "Episode: 702, Total Reward: -74\n",
      "Episode: 703, Total Reward: -136\n",
      "Episode: 704, Total Reward: -26\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 705, Total Reward: -100240\n",
      "Episode: 706, Total Reward: -112\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 707, Total Reward: -100202\n",
      "Episode: 708, Total Reward: -150\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 709, Total Reward: -100096\n",
      "Episode: 710, Total Reward: -136\n",
      "Episode: 711, Total Reward: -102\n",
      "Episode: 712, Total Reward: -290\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 713, Total Reward: -100364\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 714, Total Reward: -100464\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 715, Total Reward: -100202\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 716, Total Reward: -100122\n",
      "Episode: 717, Total Reward: -162\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 718, Total Reward: -100160\n",
      "Episode: 719, Total Reward: -78\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 720, Total Reward: -100094\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 721, Total Reward: -100078\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 722, Total Reward: -100122\n",
      "Episode: 723, Total Reward: -162\n",
      "Episode: 724, Total Reward: -202\n",
      "Episode: 725, Total Reward: -304\n",
      "Episode: 726, Total Reward: -58\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 727, Total Reward: -99940\n",
      "Episode: 728, Total Reward: -176\n",
      "Episode: 729, Total Reward: -122\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 730, Total Reward: -100050\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 731, Total Reward: -100050\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 732, Total Reward: -100020\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 733, Total Reward: -100104\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 734, Total Reward: -100074\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 735, Total Reward: -100142\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 736, Total Reward: -100036\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 737, Total Reward: -99996\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 738, Total Reward: -100090\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 739, Total Reward: -99996\n",
      "Episode: 740, Total Reward: -116\n",
      "Episode: 741, Total Reward: -246\n",
      "Episode: 742, Total Reward: -584\n",
      "Episode: 743, Total Reward: -68\n",
      "Episode: 744, Total Reward: -260\n",
      "Episode: 745, Total Reward: -176\n",
      "Episode: 746, Total Reward: -132\n",
      "Episode: 747, Total Reward: -78\n",
      "Episode: 748, Total Reward: -274\n",
      "Episode: 749, Total Reward: -88\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 750, Total Reward: -100130\n",
      "Episode: 751, Total Reward: -78\n",
      "Episode: 752, Total Reward: -70\n",
      "Episode: 753, Total Reward: -98\n",
      "Episode: 754, Total Reward: -48\n",
      "Episode: 755, Total Reward: -248\n",
      "Episode: 756, Total Reward: -60\n",
      "Episode: 757, Total Reward: -48\n",
      "Episode: 758, Total Reward: -172\n",
      "Episode: 759, Total Reward: -38\n",
      "Episode: 760, Total Reward: -296\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 761, Total Reward: -100000\n",
      "Episode: 762, Total Reward: -80\n",
      "Episode: 763, Total Reward: -198\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 764, Total Reward: -100138\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 765, Total Reward: -100152\n",
      "Episode: 766, Total Reward: -10\n",
      "Episode: 767, Total Reward: -128\n",
      "Episode: 768, Total Reward: -276\n",
      "Episode: 769, Total Reward: -88\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 770, Total Reward: -100124\n",
      "Episode: 771, Total Reward: -46\n",
      "Episode: 772, Total Reward: -38\n",
      "Episode: 773, Total Reward: -36\n",
      "Episode: 774, Total Reward: -332\n",
      "Episode: 775, Total Reward: -26\n",
      "Episode: 776, Total Reward: -38\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 777, Total Reward: -100050\n",
      "Episode: 778, Total Reward: -104\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 779, Total Reward: -100164\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 780, Total Reward: -100134\n",
      "Episode: 781, Total Reward: -282\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 782, Total Reward: -100216\n",
      "Episode: 783, Total Reward: -178\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 784, Total Reward: -100264\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 785, Total Reward: -100264\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 786, Total Reward: -100144\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 787, Total Reward: -100172\n",
      "Episode: 788, Total Reward: -52\n",
      "Episode: 789, Total Reward: -214\n",
      "Episode: 790, Total Reward: -78\n",
      "Episode: 791, Total Reward: -80\n",
      "Episode: 792, Total Reward: -210\n",
      "Episode: 793, Total Reward: -330\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 794, Total Reward: -100176\n",
      "Episode: 795, Total Reward: -148\n",
      "Episode: 796, Total Reward: -64\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 797, Total Reward: -100220\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 798, Total Reward: -100056\n",
      "Episode: 799, Total Reward: -102\n",
      "Episode: 800, Total Reward: -112\n",
      "Episode: 801, Total Reward: -130\n",
      "Episode: 802, Total Reward: -464\n",
      "Episode: 803, Total Reward: -140\n",
      "Episode: 804, Total Reward: -406\n",
      "Episode: 805, Total Reward: -100\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 806, Total Reward: -100034\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 807, Total Reward: -100358\n",
      "Episode: 808, Total Reward: -254\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 809, Total Reward: -100128\n",
      "Episode: 810, Total Reward: -488\n",
      "Episode: 811, Total Reward: -172\n",
      "Episode: 812, Total Reward: -218\n",
      "Episode: 813, Total Reward: -292\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 814, Total Reward: -100282\n",
      "Episode: 815, Total Reward: -486\n",
      "Episode: 816, Total Reward: -172\n",
      "Episode: 817, Total Reward: -150\n",
      "Episode: 818, Total Reward: -280\n",
      "Episode: 819, Total Reward: -142\n",
      "Episode: 820, Total Reward: -64\n",
      "Episode: 821, Total Reward: -308\n",
      "Episode: 822, Total Reward: -104\n",
      "Episode: 823, Total Reward: -132\n",
      "Episode: 824, Total Reward: -78\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 825, Total Reward: -100030\n",
      "Episode: 826, Total Reward: -46\n",
      "Episode: 827, Total Reward: -62\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 828, Total Reward: -100012\n",
      "Episode: 829, Total Reward: -66\n",
      "Episode: 830, Total Reward: -158\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 831, Total Reward: -100030\n",
      "Episode: 832, Total Reward: -208\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 833, Total Reward: -100030\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 834, Total Reward: -100024\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 835, Total Reward: -99976\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 836, Total Reward: -100028\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 837, Total Reward: -100040\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 838, Total Reward: -100006\n",
      "Episode: 839, Total Reward: -66\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 840, Total Reward: -100030\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 841, Total Reward: -100028\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 842, Total Reward: -100004\n",
      "Episode: 843, Total Reward: -62\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 844, Total Reward: -100024\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 845, Total Reward: -99976\n",
      "Episode: 846, Total Reward: -86\n",
      "Episode: 847, Total Reward: -88\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 848, Total Reward: -100014\n",
      "Episode: 849, Total Reward: -66\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 850, Total Reward: -100104\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 851, Total Reward: -99974\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 852, Total Reward: -100012\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 853, Total Reward: -100044\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 854, Total Reward: -100080\n",
      "Episode: 855, Total Reward: -60\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 856, Total Reward: -100040\n",
      "Episode: 857, Total Reward: -112\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 858, Total Reward: -100040\n",
      "Episode: 859, Total Reward: -62\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 860, Total Reward: -100016\n",
      "Episode: 861, Total Reward: -52\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 862, Total Reward: -99994\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 863, Total Reward: -99970\n",
      "Episode: 864, Total Reward: -64\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 865, Total Reward: -100042\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 866, Total Reward: -100030\n",
      "Episode: 867, Total Reward: -76\n",
      "Episode: 868, Total Reward: -60\n",
      "Episode: 869, Total Reward: -64\n",
      "Episode: 870, Total Reward: -184\n",
      "Episode: 871, Total Reward: -96\n",
      "Episode: 872, Total Reward: -52\n",
      "Episode: 873, Total Reward: -204\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 874, Total Reward: -100036\n",
      "Episode: 875, Total Reward: -52\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 876, Total Reward: -100024\n",
      "Episode: 877, Total Reward: -140\n",
      "Episode: 878, Total Reward: -106\n",
      "Episode: 879, Total Reward: -32\n",
      "Episode: 880, Total Reward: -140\n",
      "Episode: 881, Total Reward: -76\n",
      "Episode: 882, Total Reward: -104\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 883, Total Reward: -100228\n",
      "Episode: 884, Total Reward: -76\n",
      "Episode: 885, Total Reward: -104\n",
      "Episode: 886, Total Reward: -6\n",
      "Episode: 887, Total Reward: -94\n",
      "Episode: 888, Total Reward: -218\n",
      "Episode: 889, Total Reward: -158\n",
      "Episode: 890, Total Reward: -134\n",
      "Episode: 891, Total Reward: -46\n",
      "Episode: 892, Total Reward: -66\n",
      "Episode: 893, Total Reward: -32\n",
      "Episode: 894, Total Reward: -416\n",
      "Episode: 895, Total Reward: -80\n",
      "Episode: 896, Total Reward: -80\n",
      "Episode: 897, Total Reward: -76\n",
      "Episode: 898, Total Reward: -36\n",
      "Episode: 899, Total Reward: -74\n",
      "Episode: 900, Total Reward: -200\n",
      "Episode: 901, Total Reward: -80\n",
      "Episode: 902, Total Reward: -140\n",
      "Episode: 903, Total Reward: -78\n",
      "Episode: 904, Total Reward: -76\n",
      "Episode: 905, Total Reward: -100\n",
      "Episode: 906, Total Reward: -466\n",
      "Episode: 907, Total Reward: -140\n",
      "Episode: 908, Total Reward: -48\n",
      "Episode: 909, Total Reward: -110\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 910, Total Reward: -100144\n",
      "Episode: 911, Total Reward: -106\n",
      "Episode: 912, Total Reward: -140\n",
      "Episode: 913, Total Reward: -80\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 914, Total Reward: -100254\n",
      "Episode: 915, Total Reward: -398\n",
      "Episode: 916, Total Reward: -82\n",
      "Episode: 917, Total Reward: -236\n",
      "Episode: 918, Total Reward: -76\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 919, Total Reward: -100048\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 920, Total Reward: -100622\n",
      "Episode: 921, Total Reward: -20\n",
      "Episode: 922, Total Reward: -134\n",
      "Episode: 923, Total Reward: -158\n",
      "Episode: 924, Total Reward: -74\n",
      "Episode: 925, Total Reward: -140\n",
      "Episode: 926, Total Reward: -80\n",
      "Episode: 927, Total Reward: -88\n",
      "Episode: 928, Total Reward: -78\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 929, Total Reward: -100252\n",
      "Episode: 930, Total Reward: -244\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 931, Total Reward: -100186\n",
      "Episode: 932, Total Reward: -102\n",
      "Episode: 933, Total Reward: -102\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 934, Total Reward: -100282\n",
      "Episode: 935, Total Reward: -158\n",
      "Episode: 936, Total Reward: -48\n",
      "Episode: 937, Total Reward: -46\n",
      "Episode: 938, Total Reward: -92\n",
      "Episode: 939, Total Reward: -56\n",
      "Episode: 940, Total Reward: -98\n",
      "Episode: 941, Total Reward: -42\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 942, Total Reward: -100280\n",
      "Episode: 943, Total Reward: -280\n",
      "Episode: 944, Total Reward: -106\n",
      "Episode: 945, Total Reward: -56\n",
      "Episode: 946, Total Reward: -98\n",
      "Episode: 947, Total Reward: -456\n",
      "Episode: 948, Total Reward: -76\n",
      "Episode: 949, Total Reward: -76\n",
      "Episode: 950, Total Reward: -204\n",
      "Episode: 951, Total Reward: -118\n",
      "Episode: 952, Total Reward: -402\n",
      "Episode: 953, Total Reward: -198\n",
      "Episode: 954, Total Reward: -60\n",
      "Episode: 955, Total Reward: -76\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 956, Total Reward: -100070\n",
      "Episode: 957, Total Reward: -82\n",
      "Episode: 958, Total Reward: -184\n",
      "Episode: 959, Total Reward: 12\n",
      "Episode: 960, Total Reward: -52\n",
      "Episode: 961, Total Reward: -178\n",
      "Episode: 962, Total Reward: -78\n",
      "Episode: 963, Total Reward: -64\n",
      "Episode: 964, Total Reward: -80\n",
      "Episode: 965, Total Reward: -60\n",
      "Episode: 966, Total Reward: -96\n",
      "Episode: 967, Total Reward: -48\n",
      "Episode: 968, Total Reward: -280\n",
      "Episode: 969, Total Reward: -104\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 970, Total Reward: -100220\n",
      "Episode: 971, Total Reward: -78\n",
      "Episode: 972, Total Reward: -80\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 973, Total Reward: -100254\n",
      "Episode: 974, Total Reward: -76\n",
      "Episode: 975, Total Reward: -60\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 976, Total Reward: -100354\n",
      "Episode: 977, Total Reward: -76\n",
      "Episode: 978, Total Reward: -64\n",
      "Episode: 979, Total Reward: -64\n",
      "Episode: 980, Total Reward: -212\n",
      "Episode: 981, Total Reward: -104\n",
      "Episode: 982, Total Reward: -230\n",
      "Episode: 983, Total Reward: -76\n",
      "Episode: 984, Total Reward: -76\n",
      "Episode: 985, Total Reward: -104\n",
      "Episode: 986, Total Reward: -260\n",
      "Episode: 987, Total Reward: -36\n",
      "Episode: 988, Total Reward: -76\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 989, Total Reward: -100350\n",
      "Episode: 990, Total Reward: -104\n",
      "Episode: 991, Total Reward: -124\n",
      "Episode: 992, Total Reward: -106\n",
      "Episode: 993, Total Reward: -76\n",
      "Episode: 994, Total Reward: -64\n",
      "Episode: 995, Total Reward: -330\n",
      "Episode: 996, Total Reward: -80\n",
      "Episode: 997, Total Reward: -126\n",
      "Episode: 998, Total Reward: -60\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 999, Total Reward: -100198\n",
      "Episode: 1000, Total Reward: -126\n",
      "Episode: 1001, Total Reward: -76\n",
      "Episode: 1002, Total Reward: -122\n",
      "Episode: 1003, Total Reward: -202\n",
      "Episode: 1004, Total Reward: -80\n",
      "Episode: 1005, Total Reward: -180\n",
      "Episode: 1006, Total Reward: -78\n",
      "Episode: 1007, Total Reward: -274\n",
      "Episode: 1008, Total Reward: -128\n",
      "Episode: 1009, Total Reward: -64\n",
      "Episode: 1010, Total Reward: -76\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1011, Total Reward: -100250\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 1012, Total Reward: -100284\n",
      "Episode: 1013, Total Reward: -260\n",
      "Episode: 1014, Total Reward: -184\n",
      "Episode: 1015, Total Reward: -140\n",
      "Episode: 1016, Total Reward: -186\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 1017, Total Reward: -100252\n",
      "Episode: 1018, Total Reward: -234\n",
      "Episode: 1019, Total Reward: -84\n",
      "Episode: 1020, Total Reward: -78\n",
      "Episode: 1021, Total Reward: -76\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1022, Total Reward: -100136\n",
      "Episode: 1023, Total Reward: -94\n",
      "Episode: 1024, Total Reward: -128\n",
      "Episode: 1025, Total Reward: -88\n",
      "Episode: 1026, Total Reward: -76\n",
      "Episode: 1027, Total Reward: -128\n",
      "Episode: 1028, Total Reward: -126\n",
      "Episode: 1029, Total Reward: -78\n",
      "Episode: 1030, Total Reward: -48\n",
      "Episode: 1031, Total Reward: -88\n",
      "Episode: 1032, Total Reward: -314\n",
      "Episode: 1033, Total Reward: -372\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1034, Total Reward: -100092\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1035, Total Reward: -100030\n",
      "Episode: 1036, Total Reward: -80\n",
      "Episode: 1037, Total Reward: -368\n",
      "Episode: 1038, Total Reward: -64\n",
      "Episode: 1039, Total Reward: -140\n",
      "Episode: 1040, Total Reward: -316\n",
      "Episode: 1041, Total Reward: -186\n",
      "Episode: 1042, Total Reward: -80\n",
      "Episode: 1043, Total Reward: -290\n",
      "Episode: 1044, Total Reward: -78\n",
      "Episode: 1045, Total Reward: -216\n",
      "Episode: 1046, Total Reward: -78\n",
      "Episode: 1047, Total Reward: -94\n",
      "Episode: 1048, Total Reward: -186\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 1049, Total Reward: -100360\n",
      "Episode: 1050, Total Reward: -64\n",
      "Episode: 1051, Total Reward: -76\n",
      "Episode: 1052, Total Reward: -162\n",
      "Episode: 1053, Total Reward: -324\n",
      "Episode: 1054, Total Reward: -76\n",
      "Episode: 1055, Total Reward: -140\n",
      "Episode: 1056, Total Reward: -140\n",
      "Episode: 1057, Total Reward: -128\n",
      "Episode: 1058, Total Reward: -80\n",
      "Episode: 1059, Total Reward: -124\n",
      "Episode: 1060, Total Reward: -78\n",
      "Episode: 1061, Total Reward: -400\n",
      "Episode: 1062, Total Reward: -66\n",
      "Episode: 1063, Total Reward: -76\n",
      "Episode: 1064, Total Reward: -126\n",
      "Episode: 1065, Total Reward: -280\n",
      "Episode: 1066, Total Reward: -86\n",
      "Episode: 1067, Total Reward: -80\n",
      "Episode: 1068, Total Reward: -230\n",
      "Episode: 1069, Total Reward: -80\n",
      "Episode: 1070, Total Reward: -102\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1071, Total Reward: -100364\n",
      "Episode: 1072, Total Reward: -136\n",
      "Episode: 1073, Total Reward: -76\n",
      "Episode: 1074, Total Reward: -412\n",
      "Episode: 1075, Total Reward: -266\n",
      "Episode: 1076, Total Reward: -80\n",
      "Episode: 1077, Total Reward: -78\n",
      "Episode: 1078, Total Reward: -104\n",
      "Episode: 1079, Total Reward: -116\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1080, Total Reward: -100042\n",
      "Episode: 1081, Total Reward: -132\n",
      "Episode: 1082, Total Reward: -80\n",
      "Episode: 1083, Total Reward: -280\n",
      "Episode: 1084, Total Reward: -76\n",
      "Episode: 1085, Total Reward: -76\n",
      "Episode: 1086, Total Reward: -174\n",
      "Episode: 1087, Total Reward: -150\n",
      "Episode: 1088, Total Reward: -76\n",
      "Episode: 1089, Total Reward: -132\n",
      "Episode: 1090, Total Reward: -76\n",
      "Episode: 1091, Total Reward: -64\n",
      "Episode: 1092, Total Reward: -232\n",
      "Episode: 1093, Total Reward: -76\n",
      "Episode: 1094, Total Reward: -76\n",
      "Episode: 1095, Total Reward: -76\n",
      "Episode: 1096, Total Reward: -98\n",
      "Episode: 1097, Total Reward: -92\n",
      "Episode: 1098, Total Reward: -94\n",
      "Episode: 1099, Total Reward: -76\n",
      "Episode: 1100, Total Reward: -124\n",
      "Episode: 1101, Total Reward: -212\n",
      "Episode: 1102, Total Reward: -396\n",
      "Episode: 1103, Total Reward: -78\n",
      "Episode: 1104, Total Reward: -414\n",
      "Episode: 1105, Total Reward: -84\n",
      "Episode: 1106, Total Reward: -174\n",
      "Episode: 1107, Total Reward: -64\n",
      "Episode: 1108, Total Reward: -312\n",
      "Episode: 1109, Total Reward: -280\n",
      "Episode: 1110, Total Reward: -58\n",
      "Episode: 1111, Total Reward: -104\n",
      "Episode: 1112, Total Reward: -126\n",
      "Episode: 1113, Total Reward: -162\n",
      "Episode: 1114, Total Reward: -186\n",
      "Episode: 1115, Total Reward: -38\n",
      "Episode: 1116, Total Reward: -204\n",
      "Episode: 1117, Total Reward: -240\n",
      "Episode: 1118, Total Reward: -128\n",
      "Episode: 1119, Total Reward: -40\n",
      "Episode: 1120, Total Reward: -48\n",
      "Episode: 1121, Total Reward: -80\n",
      "Episode: 1122, Total Reward: -46\n",
      "Episode: 1123, Total Reward: -202\n",
      "Episode: 1124, Total Reward: -76\n",
      "Episode: 1125, Total Reward: -144\n",
      "Episode: 1126, Total Reward: -150\n",
      "Episode: 1127, Total Reward: -76\n",
      "Episode: 1128, Total Reward: -186\n",
      "Episode: 1129, Total Reward: -76\n",
      "Episode: 1130, Total Reward: -392\n",
      "Episode: 1131, Total Reward: -64\n",
      "Episode: 1132, Total Reward: -48\n",
      "Episode: 1133, Total Reward: -80\n",
      "Episode: 1134, Total Reward: -380\n",
      "Episode: 1135, Total Reward: -432\n",
      "Episode: 1136, Total Reward: -76\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1137, Total Reward: -100100\n",
      "Episode: 1138, Total Reward: -240\n",
      "Episode: 1139, Total Reward: -76\n",
      "Episode: 1140, Total Reward: -60\n",
      "Episode: 1141, Total Reward: -76\n",
      "Episode: 1142, Total Reward: -176\n",
      "Episode: 1143, Total Reward: -78\n",
      "Episode: 1144, Total Reward: -232\n",
      "Episode: 1145, Total Reward: -278\n",
      "Episode: 1146, Total Reward: -188\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1147, Total Reward: -100196\n",
      "Episode: 1148, Total Reward: -80\n",
      "Episode: 1149, Total Reward: -76\n",
      "Episode: 1150, Total Reward: -172\n",
      "Episode: 1151, Total Reward: -116\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1152, Total Reward: -100260\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1153, Total Reward: -100046\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1154, Total Reward: -100082\n",
      "Episode: 1155, Total Reward: -78\n",
      "Episode: 1156, Total Reward: -252\n",
      "Episode: 1157, Total Reward: -76\n",
      "Episode: 1158, Total Reward: -76\n",
      "Episode: 1159, Total Reward: -148\n",
      "Episode: 1160, Total Reward: -76\n",
      "Episode: 1161, Total Reward: -432\n",
      "Episode: 1162, Total Reward: -60\n",
      "Episode: 1163, Total Reward: -76\n",
      "Episode: 1164, Total Reward: -78\n",
      "Episode: 1165, Total Reward: -252\n",
      "Episode: 1166, Total Reward: -42\n",
      "Episode: 1167, Total Reward: -484\n",
      "Episode: 1168, Total Reward: -48\n",
      "Episode: 1169, Total Reward: -44\n",
      "Episode: 1170, Total Reward: -186\n",
      "Episode: 1171, Total Reward: -72\n",
      "Episode: 1172, Total Reward: -128\n",
      "Episode: 1173, Total Reward: -80\n",
      "Episode: 1174, Total Reward: -76\n",
      "Episode: 1175, Total Reward: -76\n",
      "Episode: 1176, Total Reward: -264\n",
      "Episode: 1177, Total Reward: -120\n",
      "Episode: 1178, Total Reward: -76\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1179, Total Reward: -100408\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1180, Total Reward: -100258\n",
      "Episode: 1181, Total Reward: -38\n",
      "Episode: 1182, Total Reward: -78\n",
      "Episode: 1183, Total Reward: -76\n",
      "Episode: 1184, Total Reward: -60\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1185, Total Reward: -100302\n",
      "Episode: 1186, Total Reward: -60\n",
      "Episode: 1187, Total Reward: -80\n",
      "Episode: 1188, Total Reward: -76\n",
      "Episode: 1189, Total Reward: -288\n",
      "Episode: 1190, Total Reward: -202\n",
      "Episode: 1191, Total Reward: -280\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 1192, Total Reward: -100238\n",
      "Episode: 1193, Total Reward: -402\n",
      "Episode: 1194, Total Reward: -126\n",
      "Episode: 1195, Total Reward: -80\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 1196, Total Reward: -100360\n",
      "Episode: 1197, Total Reward: -354\n",
      "Episode: 1198, Total Reward: -38\n",
      "Episode: 1199, Total Reward: -48\n",
      "Episode: 1200, Total Reward: -80\n",
      "Episode: 1201, Total Reward: -28\n",
      "Episode: 1202, Total Reward: -194\n",
      "Episode: 1203, Total Reward: -76\n",
      "Episode: 1204, Total Reward: -102\n",
      "Episode: 1205, Total Reward: -92\n",
      "Episode: 1206, Total Reward: -144\n",
      "Episode: 1207, Total Reward: -80\n",
      "Episode: 1208, Total Reward: -76\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1209, Total Reward: -100258\n",
      "Episode: 1210, Total Reward: -42\n",
      "Episode: 1211, Total Reward: -414\n",
      "Episode: 1212, Total Reward: -372\n",
      "Episode: 1213, Total Reward: -206\n",
      "Episode: 1214, Total Reward: -48\n",
      "Episode: 1215, Total Reward: -48\n",
      "Episode: 1216, Total Reward: -78\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1217, Total Reward: -100418\n",
      "Episode: 1218, Total Reward: -38\n",
      "Episode: 1219, Total Reward: -264\n",
      "Episode: 1220, Total Reward: -358\n",
      "Episode: 1221, Total Reward: -340\n",
      "Episode: 1222, Total Reward: -212\n",
      "Episode: 1223, Total Reward: -126\n",
      "Episode: 1224, Total Reward: -48\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1225, Total Reward: -100084\n",
      "Episode: 1226, Total Reward: -330\n",
      "Episode: 1227, Total Reward: -76\n",
      "Episode: 1228, Total Reward: -282\n",
      "Episode: 1229, Total Reward: -76\n",
      "Episode: 1230, Total Reward: -150\n",
      "Episode: 1231, Total Reward: -76\n",
      "Episode: 1232, Total Reward: -262\n",
      "Episode: 1233, Total Reward: -106\n",
      "Episode: 1234, Total Reward: -76\n",
      "Episode: 1235, Total Reward: -38\n",
      "Episode: 1236, Total Reward: -274\n",
      "Episode: 1237, Total Reward: -76\n",
      "Episode: 1238, Total Reward: -380\n",
      "Episode: 1239, Total Reward: -206\n",
      "Episode: 1240, Total Reward: -78\n",
      "Episode: 1241, Total Reward: -76\n",
      "Episode: 1242, Total Reward: -42\n",
      "Episode: 1243, Total Reward: -126\n",
      "Episode: 1244, Total Reward: -206\n",
      "Episode: 1245, Total Reward: -38\n",
      "Episode: 1246, Total Reward: -186\n",
      "Episode: 1247, Total Reward: -38\n",
      "Episode: 1248, Total Reward: -52\n",
      "Episode: 1249, Total Reward: -186\n",
      "Episode: 1250, Total Reward: -90\n",
      "Episode: 1251, Total Reward: -52\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1252, Total Reward: -100030\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1253, Total Reward: -100080\n",
      "Episode: 1254, Total Reward: -266\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1255, Total Reward: -100076\n",
      "Episode: 1256, Total Reward: -76\n",
      "Episode: 1257, Total Reward: -122\n",
      "Episode: 1258, Total Reward: -40\n",
      "Episode: 1259, Total Reward: -48\n",
      "Episode: 1260, Total Reward: -242\n",
      "Episode: 1261, Total Reward: -38\n",
      "Episode: 1262, Total Reward: -48\n",
      "Episode: 1263, Total Reward: -38\n",
      "Episode: 1264, Total Reward: -288\n",
      "Episode: 1265, Total Reward: -290\n",
      "Episode: 1266, Total Reward: -40\n",
      "Episode: 1267, Total Reward: -48\n",
      "Episode: 1268, Total Reward: -92\n",
      "Episode: 1269, Total Reward: -52\n",
      "Episode: 1270, Total Reward: -48\n",
      "Episode: 1271, Total Reward: -56\n",
      "Episode: 1272, Total Reward: -128\n",
      "Episode: 1273, Total Reward: -268\n",
      "Episode: 1274, Total Reward: -38\n",
      "Episode: 1275, Total Reward: -42\n",
      "Episode: 1276, Total Reward: -128\n",
      "Episode: 1277, Total Reward: -42\n",
      "Episode: 1278, Total Reward: -224\n",
      "Episode: 1279, Total Reward: -52\n",
      "Episode: 1280, Total Reward: -174\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1281, Total Reward: -100150\n",
      "Episode: 1282, Total Reward: -48\n",
      "Episode: 1283, Total Reward: -40\n",
      "Episode: 1284, Total Reward: -76\n",
      "Episode: 1285, Total Reward: -38\n",
      "Episode: 1286, Total Reward: -44\n",
      "Episode: 1287, Total Reward: -128\n",
      "Episode: 1288, Total Reward: -292\n",
      "Episode: 1289, Total Reward: -40\n",
      "Episode: 1290, Total Reward: -172\n",
      "Episode: 1291, Total Reward: -52\n",
      "Episode: 1292, Total Reward: -48\n",
      "Episode: 1293, Total Reward: -48\n",
      "Episode: 1294, Total Reward: -186\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 1295, Total Reward: -100210\n",
      "Episode: 1296, Total Reward: -40\n",
      "Episode: 1297, Total Reward: -188\n",
      "Episode: 1298, Total Reward: -432\n",
      "Episode: 1299, Total Reward: -48\n",
      "Episode: 1300, Total Reward: -52\n",
      "Episode: 1301, Total Reward: -92\n",
      "Episode: 1302, Total Reward: -48\n",
      "Episode: 1303, Total Reward: -128\n",
      "Episode: 1304, Total Reward: -48\n",
      "Episode: 1305, Total Reward: -240\n",
      "Episode: 1306, Total Reward: -188\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1307, Total Reward: -100158\n",
      "Episode: 1308, Total Reward: -48\n",
      "Episode: 1309, Total Reward: -48\n",
      "Episode: 1310, Total Reward: -224\n",
      "Episode: 1311, Total Reward: -48\n",
      "Episode: 1312, Total Reward: -246\n",
      "Episode: 1313, Total Reward: -38\n",
      "Episode: 1314, Total Reward: -42\n",
      "Episode: 1315, Total Reward: -44\n",
      "Episode: 1316, Total Reward: -348\n",
      "Episode: 1317, Total Reward: -36\n",
      "Episode: 1318, Total Reward: -48\n",
      "Episode: 1319, Total Reward: -90\n",
      "Episode: 1320, Total Reward: -48\n",
      "Episode: 1321, Total Reward: -264\n",
      "Episode: 1322, Total Reward: -380\n",
      "Episode: 1323, Total Reward: -76\n",
      "Episode: 1324, Total Reward: -176\n",
      "Episode: 1325, Total Reward: -40\n",
      "Episode: 1326, Total Reward: -38\n",
      "Episode: 1327, Total Reward: -274\n",
      "Episode: 1328, Total Reward: -128\n",
      "Episode: 1329, Total Reward: -256\n",
      "Episode: 1330, Total Reward: -90\n",
      "Episode: 1331, Total Reward: -76\n",
      "Episode: 1332, Total Reward: -56\n",
      "Episode: 1333, Total Reward: -92\n",
      "Episode: 1334, Total Reward: -126\n",
      "Episode: 1335, Total Reward: -48\n",
      "Episode: 1336, Total Reward: -48\n",
      "Episode: 1337, Total Reward: -48\n",
      "Episode: 1338, Total Reward: -40\n",
      "Episode: 1339, Total Reward: -42\n",
      "Episode: 1340, Total Reward: -90\n",
      "Episode: 1341, Total Reward: -38\n",
      "Episode: 1342, Total Reward: -128\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1343, Total Reward: -100174\n",
      "Episode: 1344, Total Reward: -52\n",
      "Episode: 1345, Total Reward: -48\n",
      "Episode: 1346, Total Reward: -202\n",
      "Episode: 1347, Total Reward: -38\n",
      "Episode: 1348, Total Reward: -92\n",
      "Episode: 1349, Total Reward: -42\n",
      "Episode: 1350, Total Reward: -212\n",
      "Episode: 1351, Total Reward: -452\n",
      "Episode: 1352, Total Reward: -42\n",
      "Episode: 1353, Total Reward: -48\n",
      "Episode: 1354, Total Reward: -110\n",
      "Episode: 1355, Total Reward: -48\n",
      "Episode: 1356, Total Reward: -414\n",
      "Episode: 1357, Total Reward: -198\n",
      "Episode: 1358, Total Reward: -48\n",
      "Episode: 1359, Total Reward: -48\n",
      "Episode: 1360, Total Reward: -238\n",
      "Episode: 1361, Total Reward: -38\n",
      "Episode: 1362, Total Reward: -222\n",
      "Episode: 1363, Total Reward: -48\n",
      "Episode: 1364, Total Reward: -44\n",
      "Episode: 1365, Total Reward: -222\n",
      "Episode: 1366, Total Reward: -42\n",
      "Episode: 1367, Total Reward: -38\n",
      "Episode: 1368, Total Reward: -206\n",
      "Episode: 1369, Total Reward: -42\n",
      "Episode: 1370, Total Reward: -48\n",
      "Episode: 1371, Total Reward: -246\n",
      "Episode: 1372, Total Reward: -382\n",
      "Episode: 1373, Total Reward: -358\n",
      "Episode: 1374, Total Reward: -36\n",
      "Episode: 1375, Total Reward: -120\n",
      "Episode: 1376, Total Reward: -92\n",
      "Episode: 1377, Total Reward: -180\n",
      "Episode: 1378, Total Reward: -398\n",
      "Episode: 1379, Total Reward: -250\n",
      "Episode: 1380, Total Reward: -42\n",
      "Episode: 1381, Total Reward: -206\n",
      "Episode: 1382, Total Reward: -222\n",
      "Episode: 1383, Total Reward: -48\n",
      "Episode: 1384, Total Reward: -224\n",
      "Episode: 1385, Total Reward: -444\n",
      "Episode: 1386, Total Reward: -92\n",
      "Episode: 1387, Total Reward: -36\n",
      "Episode: 1388, Total Reward: -256\n",
      "Episode: 1389, Total Reward: -42\n",
      "Episode: 1390, Total Reward: -110\n",
      "Episode: 1391, Total Reward: -46\n",
      "Episode: 1392, Total Reward: -36\n",
      "Episode: 1393, Total Reward: -52\n",
      "Episode: 1394, Total Reward: -38\n",
      "Episode: 1395, Total Reward: -358\n",
      "Episode: 1396, Total Reward: -36\n",
      "Episode: 1397, Total Reward: -38\n",
      "Episode: 1398, Total Reward: -420\n",
      "Episode: 1399, Total Reward: -42\n",
      "Episode: 1400, Total Reward: -38\n",
      "Episode: 1401, Total Reward: -48\n",
      "Episode: 1402, Total Reward: -48\n",
      "Episode: 1403, Total Reward: -120\n",
      "Episode: 1404, Total Reward: -36\n",
      "Episode: 1405, Total Reward: -42\n",
      "Episode: 1406, Total Reward: -214\n",
      "Episode: 1407, Total Reward: -36\n",
      "Episode: 1408, Total Reward: -414\n",
      "Episode: 1409, Total Reward: -40\n",
      "Episode: 1410, Total Reward: -308\n",
      "Episode: 1411, Total Reward: -92\n",
      "Episode: 1412, Total Reward: -274\n",
      "Episode: 1413, Total Reward: -40\n",
      "Episode: 1414, Total Reward: -110\n",
      "Episode: 1415, Total Reward: -38\n",
      "Episode: 1416, Total Reward: -446\n",
      "Episode: 1417, Total Reward: -82\n",
      "Episode: 1418, Total Reward: -174\n",
      "Episode: 1419, Total Reward: -110\n",
      "Episode: 1420, Total Reward: -148\n",
      "Episode: 1421, Total Reward: -128\n",
      "Episode: 1422, Total Reward: -42\n",
      "Episode: 1423, Total Reward: -178\n",
      "Episode: 1424, Total Reward: -228\n",
      "Episode: 1425, Total Reward: -128\n",
      "Episode: 1426, Total Reward: -128\n",
      "Episode: 1427, Total Reward: -48\n",
      "Episode: 1428, Total Reward: -38\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1429, Total Reward: -100274\n",
      "Episode: 1430, Total Reward: -48\n",
      "Episode: 1431, Total Reward: -36\n",
      "Episode: 1432, Total Reward: -314\n",
      "Episode: 1433, Total Reward: -48\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1434, Total Reward: -100366\n",
      "Episode: 1435, Total Reward: -92\n",
      "Episode: 1436, Total Reward: -128\n",
      "Episode: 1437, Total Reward: -36\n",
      "Episode: 1438, Total Reward: -82\n",
      "Episode: 1439, Total Reward: -38\n",
      "Episode: 1440, Total Reward: -186\n",
      "Episode: 1441, Total Reward: -196\n",
      "Episode: 1442, Total Reward: -172\n",
      "Episode: 1443, Total Reward: -272\n",
      "Episode: 1444, Total Reward: -48\n",
      "Episode: 1445, Total Reward: -56\n",
      "Episode: 1446, Total Reward: -76\n",
      "Episode: 1447, Total Reward: -206\n",
      "Episode: 1448, Total Reward: -44\n",
      "Episode: 1449, Total Reward: -36\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1450, Total Reward: -100312\n",
      "Episode: 1451, Total Reward: -162\n",
      "Episode: 1452, Total Reward: -222\n",
      "Episode: 1453, Total Reward: -98\n",
      "Episode: 1454, Total Reward: -118\n",
      "Episode: 1455, Total Reward: -48\n",
      "Episode: 1456, Total Reward: -228\n",
      "Episode: 1457, Total Reward: -48\n",
      "Episode: 1458, Total Reward: -348\n",
      "Episode: 1459, Total Reward: -40\n",
      "Episode: 1460, Total Reward: -68\n",
      "Episode: 1461, Total Reward: -56\n",
      "Episode: 1462, Total Reward: -164\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1463, Total Reward: -100112\n",
      "Episode: 1464, Total Reward: -82\n",
      "Episode: 1465, Total Reward: -134\n",
      "Episode: 1466, Total Reward: -210\n",
      "Episode: 1467, Total Reward: -42\n",
      "Episode: 1468, Total Reward: -230\n",
      "Episode: 1469, Total Reward: -328\n",
      "Episode: 1470, Total Reward: -212\n",
      "Episode: 1471, Total Reward: -38\n",
      "Episode: 1472, Total Reward: -38\n",
      "Episode: 1473, Total Reward: -110\n",
      "Episode: 1474, Total Reward: -500\n",
      "Episode: 1475, Total Reward: -48\n",
      "Episode: 1476, Total Reward: -76\n",
      "Episode: 1477, Total Reward: -202\n",
      "Episode: 1478, Total Reward: -38\n",
      "Episode: 1479, Total Reward: -36\n",
      "Episode: 1480, Total Reward: -82\n",
      "Episode: 1481, Total Reward: -52\n",
      "Episode: 1482, Total Reward: -240\n",
      "Episode: 1483, Total Reward: -36\n",
      "Episode: 1484, Total Reward: -202\n",
      "Episode: 1485, Total Reward: -44\n",
      "Episode: 1486, Total Reward: -42\n",
      "Episode: 1487, Total Reward: -90\n",
      "Episode: 1488, Total Reward: -204\n",
      "Episode: 1489, Total Reward: -52\n",
      "Episode: 1490, Total Reward: -36\n",
      "Episode: 1491, Total Reward: -38\n",
      "Episode: 1492, Total Reward: -44\n",
      "Episode: 1493, Total Reward: -40\n",
      "Episode: 1494, Total Reward: -38\n",
      "Episode: 1495, Total Reward: -48\n",
      "Episode: 1496, Total Reward: -48\n",
      "Episode: 1497, Total Reward: -52\n",
      "Episode: 1498, Total Reward: -366\n",
      "Episode: 1499, Total Reward: -128\n",
      "Episode: 1500, Total Reward: -206\n",
      "Episode: 1501, Total Reward: -418\n",
      "Episode: 1502, Total Reward: -254\n",
      "Episode: 1503, Total Reward: -38\n",
      "Episode: 1504, Total Reward: -42\n",
      "Episode: 1505, Total Reward: -224\n",
      "Episode: 1506, Total Reward: -274\n",
      "Episode: 1507, Total Reward: -48\n",
      "Episode: 1508, Total Reward: -42\n",
      "Episode: 1509, Total Reward: -76\n",
      "Episode: 1510, Total Reward: -212\n",
      "Episode: 1511, Total Reward: -408\n",
      "Episode: 1512, Total Reward: -228\n",
      "Episode: 1513, Total Reward: -202\n",
      "Episode: 1514, Total Reward: -376\n",
      "Episode: 1515, Total Reward: -48\n",
      "Episode: 1516, Total Reward: -356\n",
      "Episode: 1517, Total Reward: -48\n",
      "Episode: 1518, Total Reward: -186\n",
      "Episode: 1519, Total Reward: -128\n",
      "Episode: 1520, Total Reward: -48\n",
      "Episode: 1521, Total Reward: -48\n",
      "Episode: 1522, Total Reward: -408\n",
      "Episode: 1523, Total Reward: -316\n",
      "Episode: 1524, Total Reward: -38\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1525, Total Reward: -100270\n",
      "Episode: 1526, Total Reward: -48\n",
      "Episode: 1527, Total Reward: -92\n",
      "Episode: 1528, Total Reward: -40\n",
      "Episode: 1529, Total Reward: -42\n",
      "Episode: 1530, Total Reward: -38\n",
      "Episode: 1531, Total Reward: -110\n",
      "Episode: 1532, Total Reward: -176\n",
      "Episode: 1533, Total Reward: -42\n",
      "Episode: 1534, Total Reward: -36\n",
      "Episode: 1535, Total Reward: -76\n",
      "Episode: 1536, Total Reward: -40\n",
      "Episode: 1537, Total Reward: -38\n",
      "Episode: 1538, Total Reward: -36\n",
      "Episode: 1539, Total Reward: -206\n",
      "Episode: 1540, Total Reward: -428\n",
      "Episode: 1541, Total Reward: -304\n",
      "Episode: 1542, Total Reward: -166\n",
      "Episode: 1543, Total Reward: -194\n",
      "Episode: 1544, Total Reward: -36\n",
      "Episode: 1545, Total Reward: -40\n",
      "Episode: 1546, Total Reward: -36\n",
      "Episode: 1547, Total Reward: -230\n",
      "Episode: 1548, Total Reward: -126\n",
      "Episode: 1549, Total Reward: -48\n",
      "Episode: 1550, Total Reward: -48\n",
      "Episode: 1551, Total Reward: -36\n",
      "Episode: 1552, Total Reward: -36\n",
      "Episode: 1553, Total Reward: -48\n",
      "Episode: 1554, Total Reward: -74\n",
      "Episode: 1555, Total Reward: -40\n",
      "Episode: 1556, Total Reward: -224\n",
      "Episode: 1557, Total Reward: -128\n",
      "Episode: 1558, Total Reward: -92\n",
      "Episode: 1559, Total Reward: -38\n",
      "Episode: 1560, Total Reward: -172\n",
      "Episode: 1561, Total Reward: -376\n",
      "Episode: 1562, Total Reward: -38\n",
      "Episode: 1563, Total Reward: -90\n",
      "Episode: 1564, Total Reward: -126\n",
      "Episode: 1565, Total Reward: -42\n",
      "Episode: 1566, Total Reward: -48\n",
      "Episode: 1567, Total Reward: -128\n",
      "Episode: 1568, Total Reward: -48\n",
      "Episode: 1569, Total Reward: -52\n",
      "Episode: 1570, Total Reward: -206\n",
      "Episode: 1571, Total Reward: -90\n",
      "Episode: 1572, Total Reward: -338\n",
      "Episode: 1573, Total Reward: -88\n",
      "Episode: 1574, Total Reward: -78\n",
      "Episode: 1575, Total Reward: -108\n",
      "Episode: 1576, Total Reward: -42\n",
      "Episode: 1577, Total Reward: -316\n",
      "Episode: 1578, Total Reward: -48\n",
      "Episode: 1579, Total Reward: -128\n",
      "Episode: 1580, Total Reward: -252\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1581, Total Reward: -100470\n",
      "Episode: 1582, Total Reward: -188\n",
      "Episode: 1583, Total Reward: -226\n",
      "Episode: 1584, Total Reward: -224\n",
      "Episode: 1585, Total Reward: -48\n",
      "Episode: 1586, Total Reward: -38\n",
      "Episode: 1587, Total Reward: -212\n",
      "Episode: 1588, Total Reward: -202\n",
      "Episode: 1589, Total Reward: -48\n",
      "Episode: 1590, Total Reward: -224\n",
      "Episode: 1591, Total Reward: -274\n",
      "Episode: 1592, Total Reward: -36\n",
      "Episode: 1593, Total Reward: -48\n",
      "Episode: 1594, Total Reward: -46\n",
      "Episode: 1595, Total Reward: -38\n",
      "Episode: 1596, Total Reward: -192\n",
      "Episode: 1597, Total Reward: -274\n",
      "Episode: 1598, Total Reward: -222\n",
      "Episode: 1599, Total Reward: -92\n",
      "Episode: 1600, Total Reward: -36\n",
      "Episode: 1601, Total Reward: -46\n",
      "Episode: 1602, Total Reward: -38\n",
      "Episode: 1603, Total Reward: -98\n",
      "Episode: 1604, Total Reward: -292\n",
      "Episode: 1605, Total Reward: -38\n",
      "Episode: 1606, Total Reward: -48\n",
      "Episode: 1607, Total Reward: -128\n",
      "Episode: 1608, Total Reward: -48\n",
      "Episode: 1609, Total Reward: -98\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1610, Total Reward: -100244\n",
      "Episode: 1611, Total Reward: -130\n",
      "Episode: 1612, Total Reward: -48\n",
      "Episode: 1613, Total Reward: -128\n",
      "Episode: 1614, Total Reward: -92\n",
      "Episode: 1615, Total Reward: -88\n",
      "Episode: 1616, Total Reward: -210\n",
      "Episode: 1617, Total Reward: -88\n",
      "Episode: 1618, Total Reward: -260\n",
      "Episode: 1619, Total Reward: -248\n",
      "Episode: 1620, Total Reward: -88\n",
      "Episode: 1621, Total Reward: -74\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1622, Total Reward: -100302\n",
      "Episode: 1623, Total Reward: -92\n",
      "Episode: 1624, Total Reward: -52\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1625, Total Reward: -100446\n",
      "Episode: 1626, Total Reward: -148\n",
      "Episode: 1627, Total Reward: -206\n",
      "Episode: 1628, Total Reward: -276\n",
      "Episode: 1629, Total Reward: -54\n",
      "Episode: 1630, Total Reward: -70\n",
      "Episode: 1631, Total Reward: -52\n",
      "Episode: 1632, Total Reward: -70\n",
      "Episode: 1633, Total Reward: -70\n",
      "Episode: 1634, Total Reward: -226\n",
      "Episode: 1635, Total Reward: -256\n",
      "Episode: 1636, Total Reward: -54\n",
      "Episode: 1637, Total Reward: -70\n",
      "Episode: 1638, Total Reward: -54\n",
      "Episode: 1639, Total Reward: -54\n",
      "Episode: 1640, Total Reward: -286\n",
      "Episode: 1641, Total Reward: -94\n",
      "Episode: 1642, Total Reward: -110\n",
      "Episode: 1643, Total Reward: -56\n",
      "Episode: 1644, Total Reward: -88\n",
      "Episode: 1645, Total Reward: -70\n",
      "Episode: 1646, Total Reward: -88\n",
      "Episode: 1647, Total Reward: -52\n",
      "Episode: 1648, Total Reward: -128\n",
      "Episode: 1649, Total Reward: -70\n",
      "Episode: 1650, Total Reward: -108\n",
      "Episode: 1651, Total Reward: -188\n",
      "Episode: 1652, Total Reward: -42\n",
      "Episode: 1653, Total Reward: -94\n",
      "Episode: 1654, Total Reward: -188\n",
      "Episode: 1655, Total Reward: -212\n",
      "Episode: 1656, Total Reward: -48\n",
      "Episode: 1657, Total Reward: -48\n",
      "Episode: 1658, Total Reward: -92\n",
      "Episode: 1659, Total Reward: -54\n",
      "Episode: 1660, Total Reward: -206\n",
      "Episode: 1661, Total Reward: -88\n",
      "Episode: 1662, Total Reward: -108\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1663, Total Reward: -100110\n",
      "Episode: 1664, Total Reward: -70\n",
      "Episode: 1665, Total Reward: -148\n",
      "Episode: 1666, Total Reward: -262\n",
      "Episode: 1667, Total Reward: -52\n",
      "Episode: 1668, Total Reward: -188\n",
      "Episode: 1669, Total Reward: -146\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1670, Total Reward: -100568\n",
      "Episode: 1671, Total Reward: -344\n",
      "Episode: 1672, Total Reward: -70\n",
      "Episode: 1673, Total Reward: -94\n",
      "Episode: 1674, Total Reward: -56\n",
      "Episode: 1675, Total Reward: -222\n",
      "Episode: 1676, Total Reward: -164\n",
      "Episode: 1677, Total Reward: -70\n",
      "Episode: 1678, Total Reward: -208\n",
      "Episode: 1679, Total Reward: -54\n",
      "Episode: 1680, Total Reward: -448\n",
      "Episode: 1681, Total Reward: -108\n",
      "Episode: 1682, Total Reward: -318\n",
      "Episode: 1683, Total Reward: -110\n",
      "Episode: 1684, Total Reward: -188\n",
      "Episode: 1685, Total Reward: -76\n",
      "Episode: 1686, Total Reward: -224\n",
      "Episode: 1687, Total Reward: -130\n",
      "Episode: 1688, Total Reward: -298\n",
      "Episode: 1689, Total Reward: -252\n",
      "Episode: 1690, Total Reward: -410\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1691, Total Reward: -100286\n",
      "Episode: 1692, Total Reward: -222\n",
      "Episode: 1693, Total Reward: -64\n",
      "Episode: 1694, Total Reward: -198\n",
      "Episode: 1695, Total Reward: -118\n",
      "Episode: 1696, Total Reward: -70\n",
      "Episode: 1697, Total Reward: -210\n",
      "Episode: 1698, Total Reward: -100\n",
      "Episode: 1699, Total Reward: -236\n",
      "Episode: 1700, Total Reward: -206\n",
      "Episode: 1701, Total Reward: -240\n",
      "Episode: 1702, Total Reward: -358\n",
      "Episode: 1703, Total Reward: -56\n",
      "Episode: 1704, Total Reward: -110\n",
      "Episode: 1705, Total Reward: -338\n",
      "Episode: 1706, Total Reward: -90\n",
      "Episode: 1707, Total Reward: -66\n",
      "Episode: 1708, Total Reward: -108\n",
      "Episode: 1709, Total Reward: -86\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1710, Total Reward: -100366\n",
      "Episode: 1711, Total Reward: -334\n",
      "Episode: 1712, Total Reward: -120\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 1713, Total Reward: -100346\n",
      "Episode: 1714, Total Reward: -130\n",
      "Episode: 1715, Total Reward: -88\n",
      "Episode: 1716, Total Reward: -368\n",
      "Episode: 1717, Total Reward: -120\n",
      "Episode: 1718, Total Reward: -112\n",
      "Episode: 1719, Total Reward: -166\n",
      "Episode: 1720, Total Reward: -278\n",
      "Episode: 1721, Total Reward: -176\n",
      "Episode: 1722, Total Reward: -112\n",
      "Episode: 1723, Total Reward: -100\n",
      "Episode: 1724, Total Reward: -444\n",
      "Episode: 1725, Total Reward: -136\n",
      "Episode: 1726, Total Reward: -122\n",
      "Episode: 1727, Total Reward: -158\n",
      "Episode: 1728, Total Reward: -112\n",
      "Episode: 1729, Total Reward: -70\n",
      "Episode: 1730, Total Reward: -70\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1731, Total Reward: -100074\n",
      "Episode: 1732, Total Reward: -110\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1733, Total Reward: -100340\n",
      "Episode: 1734, Total Reward: -100\n",
      "Episode: 1735, Total Reward: -458\n",
      "Episode: 1736, Total Reward: -116\n",
      "Episode: 1737, Total Reward: -128\n",
      "Episode: 1738, Total Reward: -108\n",
      "Episode: 1739, Total Reward: -250\n",
      "Episode: 1740, Total Reward: -130\n",
      "Episode: 1741, Total Reward: -162\n",
      "Episode: 1742, Total Reward: -476\n",
      "Episode: 1743, Total Reward: -116\n",
      "Episode: 1744, Total Reward: -422\n",
      "Episode: 1745, Total Reward: -100\n",
      "Episode: 1746, Total Reward: -100\n",
      "Episode: 1747, Total Reward: -434\n",
      "Episode: 1748, Total Reward: -112\n",
      "Episode: 1749, Total Reward: -244\n",
      "Episode: 1750, Total Reward: -182\n",
      "Episode: 1751, Total Reward: -364\n",
      "Episode: 1752, Total Reward: -112\n",
      "Episode: 1753, Total Reward: -182\n",
      "Episode: 1754, Total Reward: -400\n",
      "Episode: 1755, Total Reward: -104\n",
      "Episode: 1756, Total Reward: -216\n",
      "Episode: 1757, Total Reward: -108\n",
      "Episode: 1758, Total Reward: -112\n",
      "Episode: 1759, Total Reward: -238\n",
      "Episode: 1760, Total Reward: -88\n",
      "Episode: 1761, Total Reward: -120\n",
      "Episode: 1762, Total Reward: -100\n",
      "Episode: 1763, Total Reward: -104\n",
      "Episode: 1764, Total Reward: -278\n",
      "Episode: 1765, Total Reward: -252\n",
      "Episode: 1766, Total Reward: -136\n",
      "Episode: 1767, Total Reward: -100\n",
      "Episode: 1768, Total Reward: -160\n",
      "Episode: 1769, Total Reward: -378\n",
      "Episode: 1770, Total Reward: -464\n",
      "Episode: 1771, Total Reward: -116\n",
      "Episode: 1772, Total Reward: -136\n",
      "Episode: 1773, Total Reward: -182\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1774, Total Reward: -100128\n",
      "Episode: 1775, Total Reward: -112\n",
      "Episode: 1776, Total Reward: -100\n",
      "Episode: 1777, Total Reward: -110\n",
      "Episode: 1778, Total Reward: -110\n",
      "Episode: 1779, Total Reward: -108\n",
      "Episode: 1780, Total Reward: -178\n",
      "Episode: 1781, Total Reward: -74\n",
      "Episode: 1782, Total Reward: -206\n",
      "Episode: 1783, Total Reward: -112\n",
      "Episode: 1784, Total Reward: -136\n",
      "Episode: 1785, Total Reward: -196\n",
      "Episode: 1786, Total Reward: -136\n",
      "Episode: 1787, Total Reward: -86\n",
      "Episode: 1788, Total Reward: -86\n",
      "Episode: 1789, Total Reward: -300\n",
      "Episode: 1790, Total Reward: -136\n",
      "Episode: 1791, Total Reward: -122\n",
      "Episode: 1792, Total Reward: -112\n",
      "Episode: 1793, Total Reward: -122\n",
      "Episode: 1794, Total Reward: -170\n",
      "Episode: 1795, Total Reward: -112\n",
      "Episode: 1796, Total Reward: -106\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1797, Total Reward: -100142\n",
      "Episode: 1798, Total Reward: -174\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1799, Total Reward: -100138\n",
      "Episode: 1800, Total Reward: -140\n",
      "Episode: 1801, Total Reward: -92\n",
      "Episode: 1802, Total Reward: -154\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1803, Total Reward: -100072\n",
      "Episode: 1804, Total Reward: -186\n",
      "Episode: 1805, Total Reward: -108\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1806, Total Reward: -100164\n",
      "Episode: 1807, Total Reward: -120\n",
      "Episode: 1808, Total Reward: -100\n",
      "Episode: 1809, Total Reward: -100\n",
      "Episode: 1810, Total Reward: -384\n",
      "Episode: 1811, Total Reward: -122\n",
      "Episode: 1812, Total Reward: -524\n",
      "Episode: 1813, Total Reward: -44\n",
      "Episode: 1814, Total Reward: -96\n",
      "Episode: 1815, Total Reward: -126\n",
      "Episode: 1816, Total Reward: -100\n",
      "Episode: 1817, Total Reward: -74\n",
      "Episode: 1818, Total Reward: -100\n",
      "Episode: 1819, Total Reward: -122\n",
      "Episode: 1820, Total Reward: -100\n",
      "Episode: 1821, Total Reward: -178\n",
      "Episode: 1822, Total Reward: -100\n",
      "Episode: 1823, Total Reward: -92\n",
      "Episode: 1824, Total Reward: -334\n",
      "Episode: 1825, Total Reward: -224\n",
      "Episode: 1826, Total Reward: -108\n",
      "Episode: 1827, Total Reward: -118\n",
      "Episode: 1828, Total Reward: -76\n",
      "Episode: 1829, Total Reward: -88\n",
      "Episode: 1830, Total Reward: -118\n",
      "Episode: 1831, Total Reward: -100\n",
      "Episode: 1832, Total Reward: -272\n",
      "Episode: 1833, Total Reward: -126\n",
      "Episode: 1834, Total Reward: -112\n",
      "Episode: 1835, Total Reward: -116\n",
      "Episode: 1836, Total Reward: -176\n",
      "Episode: 1837, Total Reward: -178\n",
      "Episode: 1838, Total Reward: -136\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1839, Total Reward: -100380\n",
      "Episode: 1840, Total Reward: -90\n",
      "Episode: 1841, Total Reward: -86\n",
      "Episode: 1842, Total Reward: -100\n",
      "Episode: 1843, Total Reward: -112\n",
      "Episode: 1844, Total Reward: -90\n",
      "Episode: 1845, Total Reward: -466\n",
      "Episode: 1846, Total Reward: -80\n",
      "Episode: 1847, Total Reward: -100\n",
      "Episode: 1848, Total Reward: -86\n",
      "Episode: 1849, Total Reward: -100\n",
      "Episode: 1850, Total Reward: -260\n",
      "Episode: 1851, Total Reward: -368\n",
      "Episode: 1852, Total Reward: -248\n",
      "Episode: 1853, Total Reward: -100\n",
      "Episode: 1854, Total Reward: -120\n",
      "Episode: 1855, Total Reward: -90\n",
      "Episode: 1856, Total Reward: -100\n",
      "Episode: 1857, Total Reward: -208\n",
      "Episode: 1858, Total Reward: -256\n",
      "Episode: 1859, Total Reward: -100\n",
      "Episode: 1860, Total Reward: -100\n",
      "Episode: 1861, Total Reward: -100\n",
      "Episode: 1862, Total Reward: -100\n",
      "Episode: 1863, Total Reward: -176\n",
      "Episode: 1864, Total Reward: -208\n",
      "Episode: 1865, Total Reward: -126\n",
      "Episode: 1866, Total Reward: -230\n",
      "Episode: 1867, Total Reward: -190\n",
      "Episode: 1868, Total Reward: -100\n",
      "Episode: 1869, Total Reward: -226\n",
      "Episode: 1870, Total Reward: -210\n",
      "Episode: 1871, Total Reward: -126\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1872, Total Reward: -100286\n",
      "Episode: 1873, Total Reward: -342\n",
      "Episode: 1874, Total Reward: -90\n",
      "Episode: 1875, Total Reward: -208\n",
      "Episode: 1876, Total Reward: -112\n",
      "Episode: 1877, Total Reward: -422\n",
      "Episode: 1878, Total Reward: -100\n",
      "Episode: 1879, Total Reward: -86\n",
      "Episode: 1880, Total Reward: -90\n",
      "Episode: 1881, Total Reward: -92\n",
      "Episode: 1882, Total Reward: -86\n",
      "Episode: 1883, Total Reward: -788\n",
      "Episode: 1884, Total Reward: -178\n",
      "Episode: 1885, Total Reward: -90\n",
      "Episode: 1886, Total Reward: -112\n",
      "Episode: 1887, Total Reward: -92\n",
      "Episode: 1888, Total Reward: -142\n",
      "Episode: 1889, Total Reward: -424\n",
      "Episode: 1890, Total Reward: -422\n",
      "Episode: 1891, Total Reward: -92\n",
      "Episode: 1892, Total Reward: -408\n",
      "Episode: 1893, Total Reward: -582\n",
      "Episode: 1894, Total Reward: -70\n",
      "Episode: 1895, Total Reward: -100\n",
      "Episode: 1896, Total Reward: -150\n",
      "Episode: 1897, Total Reward: -80\n",
      "Episode: 1898, Total Reward: -260\n",
      "Episode: 1899, Total Reward: -112\n",
      "Episode: 1900, Total Reward: -234\n",
      "Episode: 1901, Total Reward: -492\n",
      "Episode: 1902, Total Reward: -228\n",
      "Episode: 1903, Total Reward: -100\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1904, Total Reward: -100048\n",
      "Episode: 1905, Total Reward: -120\n",
      "Episode: 1906, Total Reward: -200\n",
      "Episode: 1907, Total Reward: -112\n",
      "Episode: 1908, Total Reward: -90\n",
      "Episode: 1909, Total Reward: -124\n",
      "Episode: 1910, Total Reward: -228\n",
      "Episode: 1911, Total Reward: -432\n",
      "Episode: 1912, Total Reward: -256\n",
      "Episode: 1913, Total Reward: -100\n",
      "Episode: 1914, Total Reward: -212\n",
      "Episode: 1915, Total Reward: -166\n",
      "Episode: 1916, Total Reward: -444\n",
      "Episode: 1917, Total Reward: -140\n",
      "Episode: 1918, Total Reward: -90\n",
      "Episode: 1919, Total Reward: -136\n",
      "Episode: 1920, Total Reward: -112\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1921, Total Reward: -100088\n",
      "Episode: 1922, Total Reward: -120\n",
      "Episode: 1923, Total Reward: -256\n",
      "Episode: 1924, Total Reward: -476\n",
      "Episode: 1925, Total Reward: -282\n",
      "Episode: 1926, Total Reward: -100\n",
      "Episode: 1927, Total Reward: -100\n",
      "Episode: 1928, Total Reward: -274\n",
      "Episode: 1929, Total Reward: -254\n",
      "Episode: 1930, Total Reward: -270\n",
      "Episode: 1931, Total Reward: -94\n",
      "Episode: 1932, Total Reward: -86\n",
      "Episode: 1933, Total Reward: -176\n",
      "Episode: 1934, Total Reward: -288\n",
      "Episode: 1935, Total Reward: -156\n",
      "Episode: 1936, Total Reward: -236\n",
      "Episode: 1937, Total Reward: -256\n",
      "Episode: 1938, Total Reward: -182\n",
      "Episode: 1939, Total Reward: -164\n",
      "Episode: 1940, Total Reward: -120\n",
      "Episode: 1941, Total Reward: -112\n",
      "Episode: 1942, Total Reward: -256\n",
      "Episode: 1943, Total Reward: -112\n",
      "Episode: 1944, Total Reward: -108\n",
      "Episode: 1945, Total Reward: -86\n",
      "Episode: 1946, Total Reward: -94\n",
      "Episode: 1947, Total Reward: -138\n",
      "Episode: 1948, Total Reward: -176\n",
      "Episode: 1949, Total Reward: -86\n",
      "Episode: 1950, Total Reward: -76\n",
      "Episode: 1951, Total Reward: -372\n",
      "Episode: 1952, Total Reward: -86\n",
      "Episode: 1953, Total Reward: -236\n",
      "Episode: 1954, Total Reward: -92\n",
      "Episode: 1955, Total Reward: -156\n",
      "Episode: 1956, Total Reward: -450\n",
      "Episode: 1957, Total Reward: -124\n",
      "Episode: 1958, Total Reward: -100\n",
      "Episode: 1959, Total Reward: -390\n",
      "Episode: 1960, Total Reward: -100\n",
      "Episode: 1961, Total Reward: -300\n",
      "Episode: 1962, Total Reward: -256\n",
      "Episode: 1963, Total Reward: -90\n",
      "Episode: 1964, Total Reward: -78\n",
      "Episode: 1965, Total Reward: -92\n",
      "Episode: 1966, Total Reward: -100\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 1967, Total Reward: -100524\n",
      "Episode: 1968, Total Reward: -166\n",
      "Episode: 1969, Total Reward: -248\n",
      "Episode: 1970, Total Reward: -100\n",
      "Episode: 1971, Total Reward: -100\n",
      "Episode: 1972, Total Reward: -92\n",
      "Episode: 1973, Total Reward: -100\n",
      "Episode: 1974, Total Reward: -126\n",
      "Episode: 1975, Total Reward: -488\n",
      "Episode: 1976, Total Reward: -150\n",
      "Episode: 1977, Total Reward: -260\n",
      "Episode: 1978, Total Reward: -100\n",
      "Episode: 1979, Total Reward: -100\n",
      "Episode: 1980, Total Reward: -86\n",
      "Episode: 1981, Total Reward: -76\n",
      "Episode: 1982, Total Reward: -106\n",
      "Episode: 1983, Total Reward: -100\n",
      "Episode: 1984, Total Reward: -446\n",
      "Episode: 1985, Total Reward: -156\n",
      "Episode: 1986, Total Reward: -86\n",
      "Episode: 1987, Total Reward: -100\n",
      "Episode: 1988, Total Reward: -136\n",
      "Episode: 1989, Total Reward: -100\n",
      "Episode: 1990, Total Reward: -112\n",
      "Episode: 1991, Total Reward: -84\n",
      "Episode: 1992, Total Reward: -238\n",
      "Episode: 1993, Total Reward: -260\n",
      "Episode: 1994, Total Reward: -300\n",
      "Episode: 1995, Total Reward: -400\n",
      "Episode: 1996, Total Reward: -432\n",
      "Episode: 1997, Total Reward: -256\n",
      "Episode: 1998, Total Reward: -276\n",
      "Episode: 1999, Total Reward: -120\n",
      "Invalid Action: Invalid column: 0\n",
      "Episode: 2000, Total Reward: -100236\n",
      "Episode: 2001, Total Reward: -240\n",
      "Episode: 2002, Total Reward: -394\n",
      "Episode: 2003, Total Reward: -100\n",
      "Episode: 2004, Total Reward: -100\n",
      "Episode: 2005, Total Reward: -112\n",
      "Episode: 2006, Total Reward: -90\n",
      "Episode: 2007, Total Reward: -90\n",
      "Episode: 2008, Total Reward: -224\n",
      "Episode: 2009, Total Reward: -422\n",
      "Episode: 2010, Total Reward: -70\n",
      "Episode: 2011, Total Reward: -78\n",
      "Episode: 2012, Total Reward: -100\n",
      "Episode: 2013, Total Reward: -226\n",
      "Episode: 2014, Total Reward: -484\n",
      "Episode: 2015, Total Reward: -60\n",
      "Episode: 2016, Total Reward: -230\n",
      "Episode: 2017, Total Reward: -82\n",
      "Episode: 2018, Total Reward: -100\n",
      "Episode: 2019, Total Reward: -242\n",
      "Episode: 2020, Total Reward: -260\n",
      "Episode: 2021, Total Reward: -138\n",
      "Episode: 2022, Total Reward: -70\n",
      "Episode: 2023, Total Reward: -142\n",
      "Episode: 2024, Total Reward: -100\n",
      "Episode: 2025, Total Reward: -60\n",
      "Episode: 2026, Total Reward: -80\n",
      "Episode: 2027, Total Reward: -260\n",
      "Episode: 2028, Total Reward: -408\n",
      "Episode: 2029, Total Reward: -100\n",
      "Episode: 2030, Total Reward: -260\n",
      "Episode: 2031, Total Reward: -86\n",
      "Episode: 2032, Total Reward: -166\n",
      "Episode: 2033, Total Reward: -86\n",
      "Episode: 2034, Total Reward: -104\n",
      "Episode: 2035, Total Reward: -108\n",
      "Episode: 2036, Total Reward: -120\n",
      "Episode: 2037, Total Reward: -64\n",
      "Episode: 2038, Total Reward: -90\n",
      "Episode: 2039, Total Reward: -138\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 2040, Total Reward: -100130\n",
      "Episode: 2041, Total Reward: -70\n",
      "Episode: 2042, Total Reward: -100\n",
      "Episode: 2043, Total Reward: -234\n",
      "Episode: 2044, Total Reward: -300\n",
      "Episode: 2045, Total Reward: -90\n",
      "Episode: 2046, Total Reward: -90\n",
      "Episode: 2047, Total Reward: -384\n",
      "Episode: 2048, Total Reward: -70\n",
      "Episode: 2049, Total Reward: -236\n",
      "Episode: 2050, Total Reward: -136\n",
      "Episode: 2051, Total Reward: -100\n",
      "Episode: 2052, Total Reward: -112\n",
      "Episode: 2053, Total Reward: -74\n",
      "Episode: 2054, Total Reward: -90\n",
      "Episode: 2055, Total Reward: -86\n",
      "Episode: 2056, Total Reward: -296\n",
      "Episode: 2057, Total Reward: -90\n",
      "Episode: 2058, Total Reward: -308\n",
      "Episode: 2059, Total Reward: -120\n",
      "Episode: 2060, Total Reward: -70\n",
      "Episode: 2061, Total Reward: -462\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 2062, Total Reward: -100242\n",
      "Episode: 2063, Total Reward: -66\n",
      "Episode: 2064, Total Reward: -112\n",
      "Episode: 2065, Total Reward: -120\n",
      "Episode: 2066, Total Reward: -90\n",
      "Episode: 2067, Total Reward: -240\n",
      "Episode: 2068, Total Reward: -124\n",
      "Episode: 2069, Total Reward: -124\n",
      "Episode: 2070, Total Reward: -112\n",
      "Episode: 2071, Total Reward: -86\n",
      "Episode: 2072, Total Reward: -422\n",
      "Episode: 2073, Total Reward: -232\n",
      "Episode: 2074, Total Reward: -152\n",
      "Episode: 2075, Total Reward: -238\n",
      "Episode: 2076, Total Reward: -136\n",
      "Episode: 2077, Total Reward: -106\n",
      "Episode: 2078, Total Reward: -156\n",
      "Episode: 2079, Total Reward: -84\n",
      "Episode: 2080, Total Reward: -70\n",
      "Episode: 2081, Total Reward: -254\n",
      "Episode: 2082, Total Reward: -140\n",
      "Episode: 2083, Total Reward: -308\n",
      "Episode: 2084, Total Reward: -90\n",
      "Episode: 2085, Total Reward: -94\n",
      "Episode: 2086, Total Reward: -100\n",
      "Episode: 2087, Total Reward: -400\n",
      "Episode: 2088, Total Reward: -540\n",
      "Episode: 2089, Total Reward: -90\n",
      "Episode: 2090, Total Reward: -260\n",
      "Episode: 2091, Total Reward: -90\n",
      "Episode: 2092, Total Reward: -370\n",
      "Episode: 2093, Total Reward: -90\n",
      "Episode: 2094, Total Reward: -412\n",
      "Episode: 2095, Total Reward: -408\n",
      "Episode: 2096, Total Reward: -86\n",
      "Episode: 2097, Total Reward: -138\n",
      "Episode: 2098, Total Reward: -86\n",
      "Episode: 2099, Total Reward: -92\n",
      "Episode: 2100, Total Reward: -106\n",
      "Episode: 2101, Total Reward: -388\n",
      "Episode: 2102, Total Reward: -124\n",
      "Episode: 2103, Total Reward: -90\n",
      "Episode: 2104, Total Reward: -240\n",
      "Episode: 2105, Total Reward: -282\n",
      "Episode: 2106, Total Reward: -520\n",
      "Episode: 2107, Total Reward: -92\n",
      "Episode: 2108, Total Reward: -166\n",
      "Episode: 2109, Total Reward: -194\n",
      "Episode: 2110, Total Reward: -440\n",
      "Episode: 2111, Total Reward: -90\n",
      "Episode: 2112, Total Reward: -118\n",
      "Episode: 2113, Total Reward: -86\n",
      "Episode: 2114, Total Reward: -90\n",
      "Episode: 2115, Total Reward: -70\n",
      "Episode: 2116, Total Reward: -62\n",
      "Episode: 2117, Total Reward: -68\n",
      "Episode: 2118, Total Reward: -250\n",
      "Episode: 2119, Total Reward: -70\n",
      "Episode: 2120, Total Reward: -468\n",
      "Episode: 2121, Total Reward: -386\n",
      "Episode: 2122, Total Reward: -256\n",
      "Episode: 2123, Total Reward: -112\n",
      "Episode: 2124, Total Reward: -70\n",
      "Episode: 2125, Total Reward: -66\n",
      "Episode: 2126, Total Reward: -100\n",
      "Episode: 2127, Total Reward: -74\n",
      "Episode: 2128, Total Reward: -112\n",
      "Episode: 2129, Total Reward: -370\n",
      "Episode: 2130, Total Reward: -62\n",
      "Episode: 2131, Total Reward: -86\n",
      "Episode: 2132, Total Reward: -296\n",
      "Episode: 2133, Total Reward: -360\n",
      "Episode: 2134, Total Reward: -150\n",
      "Episode: 2135, Total Reward: -70\n",
      "Episode: 2136, Total Reward: -70\n",
      "Episode: 2137, Total Reward: -86\n",
      "Episode: 2138, Total Reward: -90\n",
      "Episode: 2139, Total Reward: -408\n",
      "Episode: 2140, Total Reward: -244\n",
      "Episode: 2141, Total Reward: -118\n",
      "Episode: 2142, Total Reward: -100\n",
      "Episode: 2143, Total Reward: -100\n",
      "Episode: 2144, Total Reward: -90\n",
      "Episode: 2145, Total Reward: -86\n",
      "Episode: 2146, Total Reward: -80\n",
      "Episode: 2147, Total Reward: -100\n",
      "Episode: 2148, Total Reward: -100\n",
      "Episode: 2149, Total Reward: -70\n",
      "Episode: 2150, Total Reward: -86\n",
      "Episode: 2151, Total Reward: -100\n",
      "Episode: 2152, Total Reward: -100\n",
      "Episode: 2153, Total Reward: -70\n",
      "Episode: 2154, Total Reward: -90\n",
      "Episode: 2155, Total Reward: -120\n",
      "Episode: 2156, Total Reward: -80\n",
      "Episode: 2157, Total Reward: -238\n",
      "Episode: 2158, Total Reward: -308\n",
      "Episode: 2159, Total Reward: -146\n",
      "Episode: 2160, Total Reward: -278\n",
      "Episode: 2161, Total Reward: -384\n",
      "Episode: 2162, Total Reward: -100\n",
      "Episode: 2163, Total Reward: -100\n",
      "Episode: 2164, Total Reward: -100\n",
      "Episode: 2165, Total Reward: -86\n",
      "Episode: 2166, Total Reward: -90\n",
      "Episode: 2167, Total Reward: -214\n",
      "Episode: 2168, Total Reward: -124\n",
      "Episode: 2169, Total Reward: -70\n",
      "Episode: 2170, Total Reward: -184\n",
      "Episode: 2171, Total Reward: -120\n",
      "Episode: 2172, Total Reward: -156\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 2173, Total Reward: -100146\n",
      "Episode: 2174, Total Reward: -242\n",
      "Episode: 2175, Total Reward: -428\n",
      "Episode: 2176, Total Reward: -128\n",
      "Episode: 2177, Total Reward: -276\n",
      "Episode: 2178, Total Reward: -100\n",
      "Episode: 2179, Total Reward: -100\n",
      "Episode: 2180, Total Reward: -212\n",
      "Episode: 2181, Total Reward: -412\n",
      "Episode: 2182, Total Reward: -100\n",
      "Episode: 2183, Total Reward: -172\n",
      "Episode: 2184, Total Reward: -140\n",
      "Episode: 2185, Total Reward: -86\n",
      "Episode: 2186, Total Reward: -100\n",
      "Episode: 2187, Total Reward: -446\n",
      "Episode: 2188, Total Reward: -114\n",
      "Episode: 2189, Total Reward: -100\n",
      "Episode: 2190, Total Reward: -322\n",
      "Episode: 2191, Total Reward: -454\n",
      "Episode: 2192, Total Reward: -92\n",
      "Episode: 2193, Total Reward: -90\n",
      "Episode: 2194, Total Reward: -100\n",
      "Episode: 2195, Total Reward: -270\n",
      "Episode: 2196, Total Reward: -108\n",
      "Episode: 2197, Total Reward: -112\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 2198, Total Reward: -100198\n",
      "Episode: 2199, Total Reward: -460\n",
      "Episode: 2200, Total Reward: -226\n",
      "Episode: 2201, Total Reward: -100\n",
      "Episode: 2202, Total Reward: -326\n",
      "Episode: 2203, Total Reward: -136\n",
      "Episode: 2204, Total Reward: -90\n",
      "Episode: 2205, Total Reward: -90\n",
      "Episode: 2206, Total Reward: -108\n",
      "Episode: 2207, Total Reward: -492\n",
      "Episode: 2208, Total Reward: -70\n",
      "Episode: 2209, Total Reward: -70\n",
      "Episode: 2210, Total Reward: -114\n",
      "Episode: 2211, Total Reward: -130\n",
      "Episode: 2212, Total Reward: -70\n",
      "Episode: 2213, Total Reward: -78\n",
      "Episode: 2214, Total Reward: -90\n",
      "Episode: 2215, Total Reward: -80\n",
      "Episode: 2216, Total Reward: -450\n",
      "Episode: 2217, Total Reward: -70\n",
      "Episode: 2218, Total Reward: -218\n",
      "Episode: 2219, Total Reward: -244\n",
      "Episode: 2220, Total Reward: -86\n",
      "Episode: 2221, Total Reward: -148\n",
      "Episode: 2222, Total Reward: -152\n",
      "Episode: 2223, Total Reward: -602\n",
      "Episode: 2224, Total Reward: -100\n",
      "Episode: 2225, Total Reward: -64\n",
      "Episode: 2226, Total Reward: -370\n",
      "Episode: 2227, Total Reward: -234\n",
      "Episode: 2228, Total Reward: -100\n",
      "Episode: 2229, Total Reward: -118\n",
      "Episode: 2230, Total Reward: -384\n",
      "Episode: 2231, Total Reward: -126\n",
      "Episode: 2232, Total Reward: -60\n",
      "Episode: 2233, Total Reward: -100\n",
      "Episode: 2234, Total Reward: -500\n",
      "Episode: 2235, Total Reward: -90\n",
      "Episode: 2236, Total Reward: -90\n",
      "Episode: 2237, Total Reward: -312\n",
      "Episode: 2238, Total Reward: -112\n",
      "Episode: 2239, Total Reward: -134\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2240, Total Reward: -100114\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 2241, Total Reward: -100264\n",
      "Episode: 2242, Total Reward: -300\n",
      "Episode: 2243, Total Reward: -282\n",
      "Episode: 2244, Total Reward: -70\n",
      "Episode: 2245, Total Reward: -412\n",
      "Episode: 2246, Total Reward: -290\n",
      "Episode: 2247, Total Reward: -100\n",
      "Episode: 2248, Total Reward: -436\n",
      "Episode: 2249, Total Reward: -100\n",
      "Episode: 2250, Total Reward: -248\n",
      "Episode: 2251, Total Reward: -86\n",
      "Episode: 2252, Total Reward: -118\n",
      "Episode: 2253, Total Reward: -100\n",
      "Episode: 2254, Total Reward: -80\n",
      "Episode: 2255, Total Reward: -114\n",
      "Episode: 2256, Total Reward: -74\n",
      "Episode: 2257, Total Reward: -90\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2258, Total Reward: -100088\n",
      "Episode: 2259, Total Reward: -64\n",
      "Episode: 2260, Total Reward: -112\n",
      "Episode: 2261, Total Reward: -394\n",
      "Episode: 2262, Total Reward: -90\n",
      "Episode: 2263, Total Reward: -90\n",
      "Episode: 2264, Total Reward: -108\n",
      "Episode: 2265, Total Reward: -66\n",
      "Episode: 2266, Total Reward: -38\n",
      "Episode: 2267, Total Reward: -300\n",
      "Episode: 2268, Total Reward: -70\n",
      "Episode: 2269, Total Reward: -560\n",
      "Episode: 2270, Total Reward: -356\n",
      "Episode: 2271, Total Reward: -92\n",
      "Episode: 2272, Total Reward: -82\n",
      "Episode: 2273, Total Reward: -256\n",
      "Episode: 2274, Total Reward: -274\n",
      "Episode: 2275, Total Reward: -244\n",
      "Episode: 2276, Total Reward: -150\n",
      "Episode: 2277, Total Reward: -70\n",
      "Episode: 2278, Total Reward: -86\n",
      "Episode: 2279, Total Reward: -282\n",
      "Episode: 2280, Total Reward: -106\n",
      "Episode: 2281, Total Reward: -88\n",
      "Episode: 2282, Total Reward: -138\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 2283, Total Reward: -99894\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2284, Total Reward: -100950\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 2285, Total Reward: -100332\n",
      "Episode: 2286, Total Reward: -672\n",
      "Episode: 2287, Total Reward: -54\n",
      "Episode: 2288, Total Reward: -178\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 2289, Total Reward: -100238\n",
      "Episode: 2290, Total Reward: -58\n",
      "Episode: 2291, Total Reward: -102\n",
      "Episode: 2292, Total Reward: -174\n",
      "Episode: 2293, Total Reward: 68\n",
      "Episode: 2294, Total Reward: -160\n",
      "Episode: 2295, Total Reward: -592\n",
      "Episode: 2296, Total Reward: -138\n",
      "Episode: 2297, Total Reward: -56\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 2298, Total Reward: -100200\n",
      "Episode: 2299, Total Reward: -58\n",
      "Episode: 2300, Total Reward: -632\n",
      "Episode: 2301, Total Reward: -90\n",
      "Episode: 2302, Total Reward: -84\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 2303, Total Reward: -100118\n",
      "Episode: 2304, Total Reward: -64\n",
      "Episode: 2305, Total Reward: -84\n",
      "Episode: 2306, Total Reward: -86\n",
      "Episode: 2307, Total Reward: -90\n",
      "Episode: 2308, Total Reward: -74\n",
      "Episode: 2309, Total Reward: -100\n",
      "Episode: 2310, Total Reward: -64\n",
      "Episode: 2311, Total Reward: -206\n",
      "Episode: 2312, Total Reward: -422\n",
      "Episode: 2313, Total Reward: -330\n",
      "Episode: 2314, Total Reward: -308\n",
      "Episode: 2315, Total Reward: -106\n",
      "Episode: 2316, Total Reward: -60\n",
      "Episode: 2317, Total Reward: -476\n",
      "Episode: 2318, Total Reward: -60\n",
      "Episode: 2319, Total Reward: -72\n",
      "Episode: 2320, Total Reward: -70\n",
      "Episode: 2321, Total Reward: -226\n",
      "Episode: 2322, Total Reward: -68\n",
      "Episode: 2323, Total Reward: -132\n",
      "Episode: 2324, Total Reward: -70\n",
      "Episode: 2325, Total Reward: -66\n",
      "Episode: 2326, Total Reward: -72\n",
      "Episode: 2327, Total Reward: -70\n",
      "Episode: 2328, Total Reward: -90\n",
      "Episode: 2329, Total Reward: -100\n",
      "Episode: 2330, Total Reward: -68\n",
      "Episode: 2331, Total Reward: -100\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 2332, Total Reward: -100272\n",
      "Episode: 2333, Total Reward: -60\n",
      "Episode: 2334, Total Reward: -384\n",
      "Episode: 2335, Total Reward: -70\n",
      "Episode: 2336, Total Reward: -64\n",
      "Episode: 2337, Total Reward: -414\n",
      "Episode: 2338, Total Reward: -58\n",
      "Episode: 2339, Total Reward: -70\n",
      "Episode: 2340, Total Reward: -496\n",
      "Episode: 2341, Total Reward: -112\n",
      "Episode: 2342, Total Reward: -72\n",
      "Episode: 2343, Total Reward: -164\n",
      "Episode: 2344, Total Reward: -118\n",
      "Episode: 2345, Total Reward: -366\n",
      "Episode: 2346, Total Reward: -64\n",
      "Episode: 2347, Total Reward: -496\n",
      "Episode: 2348, Total Reward: -98\n",
      "Episode: 2349, Total Reward: -236\n",
      "Episode: 2350, Total Reward: -136\n",
      "Episode: 2351, Total Reward: -90\n",
      "Episode: 2352, Total Reward: -128\n",
      "Episode: 2353, Total Reward: -152\n",
      "Episode: 2354, Total Reward: -138\n",
      "Episode: 2355, Total Reward: -70\n",
      "Episode: 2356, Total Reward: -246\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2357, Total Reward: -100494\n",
      "Episode: 2358, Total Reward: -28\n",
      "Episode: 2359, Total Reward: -446\n",
      "Episode: 2360, Total Reward: -18\n",
      "Episode: 2361, Total Reward: -542\n",
      "Episode: 2362, Total Reward: -250\n",
      "Episode: 2363, Total Reward: -64\n",
      "Episode: 2364, Total Reward: -70\n",
      "Episode: 2365, Total Reward: -60\n",
      "Episode: 2366, Total Reward: -60\n",
      "Episode: 2367, Total Reward: -70\n",
      "Episode: 2368, Total Reward: -78\n",
      "Episode: 2369, Total Reward: -106\n",
      "Episode: 2370, Total Reward: -136\n",
      "Episode: 2371, Total Reward: -62\n",
      "Episode: 2372, Total Reward: -70\n",
      "Episode: 2373, Total Reward: -62\n",
      "Episode: 2374, Total Reward: -66\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2375, Total Reward: -100422\n",
      "Episode: 2376, Total Reward: -56\n",
      "Episode: 2377, Total Reward: -196\n",
      "Episode: 2378, Total Reward: -214\n",
      "Episode: 2379, Total Reward: -168\n",
      "Episode: 2380, Total Reward: -60\n",
      "Episode: 2381, Total Reward: -66\n",
      "Episode: 2382, Total Reward: -62\n",
      "Episode: 2383, Total Reward: -70\n",
      "Episode: 2384, Total Reward: -1226\n",
      "Episode: 2385, Total Reward: -212\n",
      "Episode: 2386, Total Reward: -564\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 2387, Total Reward: -100090\n",
      "Episode: 2388, Total Reward: -130\n",
      "Episode: 2389, Total Reward: -322\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 2390, Total Reward: -100630\n",
      "Episode: 2391, Total Reward: -18\n",
      "Episode: 2392, Total Reward: -318\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2393, Total Reward: -100178\n",
      "Episode: 2394, Total Reward: -52\n",
      "Episode: 2395, Total Reward: -52\n",
      "Episode: 2396, Total Reward: -170\n",
      "Episode: 2397, Total Reward: -278\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2398, Total Reward: -99940\n",
      "Episode: 2399, Total Reward: 99964\n",
      "Episode: 2400, Total Reward: -32\n",
      "Episode: 2401, Total Reward: -290\n",
      "Episode: 2402, Total Reward: -102\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2403, Total Reward: -100066\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 2404, Total Reward: -100222\n",
      "Episode: 2405, Total Reward: -86\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2406, Total Reward: -100698\n",
      "Episode: 2407, Total Reward: -90\n",
      "Episode: 2408, Total Reward: -26\n",
      "Episode: 2409, Total Reward: -60\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2410, Total Reward: -100038\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2411, Total Reward: -100060\n",
      "Episode: 2412, Total Reward: -88\n",
      "Episode: 2413, Total Reward: -84\n",
      "Episode: 2414, Total Reward: -178\n",
      "Episode: 2415, Total Reward: -270\n",
      "Episode: 2416, Total Reward: -786\n",
      "Episode: 2417, Total Reward: -94\n",
      "Episode: 2418, Total Reward: -104\n",
      "Episode: 2419, Total Reward: -62\n",
      "Episode: 2420, Total Reward: -18\n",
      "Episode: 2421, Total Reward: -214\n",
      "Episode: 2422, Total Reward: -12\n",
      "Episode: 2423, Total Reward: -338\n",
      "Episode: 2424, Total Reward: -308\n",
      "Episode: 2425, Total Reward: -158\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2426, Total Reward: -100622\n",
      "Episode: 2427, Total Reward: -234\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2428, Total Reward: -100302\n",
      "Episode: 2429, Total Reward: -96\n",
      "Episode: 2430, Total Reward: -60\n",
      "Episode: 2431, Total Reward: 34\n",
      "Episode: 2432, Total Reward: -254\n",
      "Episode: 2433, Total Reward: -154\n",
      "Episode: 2434, Total Reward: -102\n",
      "Episode: 2435, Total Reward: -86\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2436, Total Reward: -100234\n",
      "Episode: 2437, Total Reward: -86\n",
      "Episode: 2438, Total Reward: -180\n",
      "Episode: 2439, Total Reward: -204\n",
      "Episode: 2440, Total Reward: -56\n",
      "Episode: 2441, Total Reward: -80\n",
      "Episode: 2442, Total Reward: -130\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2443, Total Reward: -100044\n",
      "Episode: 2444, Total Reward: -190\n",
      "Episode: 2445, Total Reward: -64\n",
      "Episode: 2446, Total Reward: -74\n",
      "Episode: 2447, Total Reward: -174\n",
      "Episode: 2448, Total Reward: -116\n",
      "Episode: 2449, Total Reward: -68\n",
      "Episode: 2450, Total Reward: -114\n",
      "Episode: 2451, Total Reward: -138\n",
      "Episode: 2452, Total Reward: -70\n",
      "Episode: 2453, Total Reward: -94\n",
      "Episode: 2454, Total Reward: -96\n",
      "Episode: 2455, Total Reward: -150\n",
      "Episode: 2456, Total Reward: -322\n",
      "Episode: 2457, Total Reward: -152\n",
      "Episode: 2458, Total Reward: -262\n",
      "Episode: 2459, Total Reward: -80\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2460, Total Reward: -100036\n",
      "Episode: 2461, Total Reward: -80\n",
      "Episode: 2462, Total Reward: -144\n",
      "Episode: 2463, Total Reward: -82\n",
      "Episode: 2464, Total Reward: -284\n",
      "Episode: 2465, Total Reward: -110\n",
      "Episode: 2466, Total Reward: -322\n",
      "Episode: 2467, Total Reward: -162\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2468, Total Reward: -100172\n",
      "Episode: 2469, Total Reward: -80\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2470, Total Reward: -100018\n",
      "Episode: 2471, Total Reward: -136\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2472, Total Reward: -100330\n",
      "Episode: 2473, Total Reward: -248\n",
      "Episode: 2474, Total Reward: -60\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2475, Total Reward: -100222\n",
      "Episode: 2476, Total Reward: -70\n",
      "Episode: 2477, Total Reward: -82\n",
      "Episode: 2478, Total Reward: -70\n",
      "Episode: 2479, Total Reward: -130\n",
      "Episode: 2480, Total Reward: -108\n",
      "Episode: 2481, Total Reward: -278\n",
      "Episode: 2482, Total Reward: -278\n",
      "Episode: 2483, Total Reward: -212\n",
      "Episode: 2484, Total Reward: -56\n",
      "Episode: 2485, Total Reward: -514\n",
      "Episode: 2486, Total Reward: -208\n",
      "Episode: 2487, Total Reward: -66\n",
      "Episode: 2488, Total Reward: -158\n",
      "Episode: 2489, Total Reward: -144\n",
      "Episode: 2490, Total Reward: -124\n",
      "Episode: 2491, Total Reward: -56\n",
      "Episode: 2492, Total Reward: -76\n",
      "Episode: 2493, Total Reward: -98\n",
      "Episode: 2494, Total Reward: -60\n",
      "Episode: 2495, Total Reward: -118\n",
      "Episode: 2496, Total Reward: -470\n",
      "Episode: 2497, Total Reward: -290\n",
      "Episode: 2498, Total Reward: -70\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2499, Total Reward: -100440\n",
      "Episode: 2500, Total Reward: -64\n",
      "Episode: 2501, Total Reward: -218\n",
      "Episode: 2502, Total Reward: -108\n",
      "Episode: 2503, Total Reward: -304\n",
      "Episode: 2504, Total Reward: -374\n",
      "Episode: 2505, Total Reward: -126\n",
      "Episode: 2506, Total Reward: -200\n",
      "Episode: 2507, Total Reward: -116\n",
      "Episode: 2508, Total Reward: -64\n",
      "Episode: 2509, Total Reward: -142\n",
      "Episode: 2510, Total Reward: -56\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2511, Total Reward: -100354\n",
      "Episode: 2512, Total Reward: -140\n",
      "Episode: 2513, Total Reward: -106\n",
      "Episode: 2514, Total Reward: -108\n",
      "Episode: 2515, Total Reward: -446\n",
      "Episode: 2516, Total Reward: -98\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2517, Total Reward: -100262\n",
      "Episode: 2518, Total Reward: -98\n",
      "Episode: 2519, Total Reward: -290\n",
      "Episode: 2520, Total Reward: -250\n",
      "Episode: 2521, Total Reward: -106\n",
      "Episode: 2522, Total Reward: -92\n",
      "Episode: 2523, Total Reward: -232\n",
      "Episode: 2524, Total Reward: -64\n",
      "Episode: 2525, Total Reward: -64\n",
      "Episode: 2526, Total Reward: -60\n",
      "Episode: 2527, Total Reward: -72\n",
      "Episode: 2528, Total Reward: -236\n",
      "Episode: 2529, Total Reward: -424\n",
      "Episode: 2530, Total Reward: -64\n",
      "Episode: 2531, Total Reward: -416\n",
      "Episode: 2532, Total Reward: -62\n",
      "Episode: 2533, Total Reward: -58\n",
      "Episode: 2534, Total Reward: -106\n",
      "Episode: 2535, Total Reward: -118\n",
      "Episode: 2536, Total Reward: -324\n",
      "Episode: 2537, Total Reward: -68\n",
      "Episode: 2538, Total Reward: -98\n",
      "Episode: 2539, Total Reward: -384\n",
      "Episode: 2540, Total Reward: -80\n",
      "Episode: 2541, Total Reward: -358\n",
      "Episode: 2542, Total Reward: -66\n",
      "Episode: 2543, Total Reward: -70\n",
      "Episode: 2544, Total Reward: -98\n",
      "Episode: 2545, Total Reward: -116\n",
      "Episode: 2546, Total Reward: -78\n",
      "Episode: 2547, Total Reward: -70\n",
      "Episode: 2548, Total Reward: -290\n",
      "Episode: 2549, Total Reward: -78\n",
      "Episode: 2550, Total Reward: -112\n",
      "Episode: 2551, Total Reward: -108\n",
      "Episode: 2552, Total Reward: -254\n",
      "Episode: 2553, Total Reward: -114\n",
      "Episode: 2554, Total Reward: -76\n",
      "Episode: 2555, Total Reward: -110\n",
      "Episode: 2556, Total Reward: -138\n",
      "Episode: 2557, Total Reward: -120\n",
      "Episode: 2558, Total Reward: -106\n",
      "Episode: 2559, Total Reward: -566\n",
      "Episode: 2560, Total Reward: -118\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2561, Total Reward: -100212\n",
      "Episode: 2562, Total Reward: -100\n",
      "Episode: 2563, Total Reward: -66\n",
      "Episode: 2564, Total Reward: -70\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2565, Total Reward: -100294\n",
      "Episode: 2566, Total Reward: -58\n",
      "Episode: 2567, Total Reward: -106\n",
      "Episode: 2568, Total Reward: -66\n",
      "Episode: 2569, Total Reward: -66\n",
      "Episode: 2570, Total Reward: -66\n",
      "Episode: 2571, Total Reward: -70\n",
      "Episode: 2572, Total Reward: -66\n",
      "Episode: 2573, Total Reward: -106\n",
      "Episode: 2574, Total Reward: -110\n",
      "Episode: 2575, Total Reward: -688\n",
      "Episode: 2576, Total Reward: -64\n",
      "Episode: 2577, Total Reward: -138\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2578, Total Reward: -100932\n",
      "Episode: 2579, Total Reward: -676\n",
      "Episode: 2580, Total Reward: -18\n",
      "Episode: 2581, Total Reward: -72\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2582, Total Reward: -100060\n",
      "Episode: 2583, Total Reward: -98\n",
      "Episode: 2584, Total Reward: -108\n",
      "Episode: 2585, Total Reward: -256\n",
      "Episode: 2586, Total Reward: -116\n",
      "Episode: 2587, Total Reward: -56\n",
      "Episode: 2588, Total Reward: -64\n",
      "Episode: 2589, Total Reward: -82\n",
      "Episode: 2590, Total Reward: -410\n",
      "Episode: 2591, Total Reward: -70\n",
      "Episode: 2592, Total Reward: -330\n",
      "Episode: 2593, Total Reward: -60\n",
      "Episode: 2594, Total Reward: -108\n",
      "Episode: 2595, Total Reward: -64\n",
      "Episode: 2596, Total Reward: -240\n",
      "Episode: 2597, Total Reward: -80\n",
      "Episode: 2598, Total Reward: -320\n",
      "Episode: 2599, Total Reward: -100\n",
      "Episode: 2600, Total Reward: -106\n",
      "Episode: 2601, Total Reward: -64\n",
      "Episode: 2602, Total Reward: -64\n",
      "Episode: 2603, Total Reward: -70\n",
      "Episode: 2604, Total Reward: -70\n",
      "Episode: 2605, Total Reward: -98\n",
      "Episode: 2606, Total Reward: -308\n",
      "Episode: 2607, Total Reward: -106\n",
      "Episode: 2608, Total Reward: -418\n",
      "Episode: 2609, Total Reward: -424\n",
      "Episode: 2610, Total Reward: -918\n",
      "Episode: 2611, Total Reward: -234\n",
      "Episode: 2612, Total Reward: -280\n",
      "Episode: 2613, Total Reward: -130\n",
      "Episode: 2614, Total Reward: -70\n",
      "Episode: 2615, Total Reward: -112\n",
      "Episode: 2616, Total Reward: -106\n",
      "Episode: 2617, Total Reward: -390\n",
      "Episode: 2618, Total Reward: -64\n",
      "Episode: 2619, Total Reward: -80\n",
      "Episode: 2620, Total Reward: -58\n",
      "Episode: 2621, Total Reward: -96\n",
      "Episode: 2622, Total Reward: -100\n",
      "Episode: 2623, Total Reward: -112\n",
      "Episode: 2624, Total Reward: -246\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2625, Total Reward: -100270\n",
      "Episode: 2626, Total Reward: -102\n",
      "Episode: 2627, Total Reward: -90\n",
      "Episode: 2628, Total Reward: -106\n",
      "Episode: 2629, Total Reward: -444\n",
      "Episode: 2630, Total Reward: -166\n",
      "Episode: 2631, Total Reward: -42\n",
      "Episode: 2632, Total Reward: -64\n",
      "Episode: 2633, Total Reward: -266\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2634, Total Reward: -100210\n",
      "Episode: 2635, Total Reward: -100\n",
      "Episode: 2636, Total Reward: -106\n",
      "Episode: 2637, Total Reward: -60\n",
      "Episode: 2638, Total Reward: -60\n",
      "Episode: 2639, Total Reward: -78\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2640, Total Reward: -100172\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2641, Total Reward: -100054\n",
      "Episode: 2642, Total Reward: -40\n",
      "Episode: 2643, Total Reward: -154\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2644, Total Reward: -100160\n",
      "Episode: 2645, Total Reward: -40\n",
      "Episode: 2646, Total Reward: -24\n",
      "Episode: 2647, Total Reward: -40\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2648, Total Reward: -100176\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2649, Total Reward: -100014\n",
      "Episode: 2650, Total Reward: -86\n",
      "Episode: 2651, Total Reward: -202\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2652, Total Reward: -100372\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2653, Total Reward: -100190\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2654, Total Reward: -100112\n",
      "Episode: 2655, Total Reward: -236\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2656, Total Reward: -100216\n",
      "Episode: 2657, Total Reward: -106\n",
      "Episode: 2658, Total Reward: -214\n",
      "Episode: 2659, Total Reward: -40\n",
      "Episode: 2660, Total Reward: -90\n",
      "Episode: 2661, Total Reward: -60\n",
      "Episode: 2662, Total Reward: -178\n",
      "Episode: 2663, Total Reward: -226\n",
      "Episode: 2664, Total Reward: -526\n",
      "Episode: 2665, Total Reward: -410\n",
      "Episode: 2666, Total Reward: -90\n",
      "Episode: 2667, Total Reward: -46\n",
      "Episode: 2668, Total Reward: -518\n",
      "Episode: 2669, Total Reward: -24\n",
      "Episode: 2670, Total Reward: -614\n",
      "Episode: 2671, Total Reward: -136\n",
      "Episode: 2672, Total Reward: -234\n",
      "Episode: 2673, Total Reward: -74\n",
      "Episode: 2674, Total Reward: -46\n",
      "Episode: 2675, Total Reward: -112\n",
      "Episode: 2676, Total Reward: -124\n",
      "Episode: 2677, Total Reward: -122\n",
      "Episode: 2678, Total Reward: -76\n",
      "Episode: 2679, Total Reward: -106\n",
      "Episode: 2680, Total Reward: -64\n",
      "Episode: 2681, Total Reward: -190\n",
      "Episode: 2682, Total Reward: -408\n",
      "Episode: 2683, Total Reward: -96\n",
      "Episode: 2684, Total Reward: -250\n",
      "Episode: 2685, Total Reward: -124\n",
      "Episode: 2686, Total Reward: -454\n",
      "Episode: 2687, Total Reward: -60\n",
      "Episode: 2688, Total Reward: -422\n",
      "Episode: 2689, Total Reward: -112\n",
      "Episode: 2690, Total Reward: -124\n",
      "Episode: 2691, Total Reward: -76\n",
      "Episode: 2692, Total Reward: -118\n",
      "Episode: 2693, Total Reward: -104\n",
      "Episode: 2694, Total Reward: -134\n",
      "Episode: 2695, Total Reward: -352\n",
      "Episode: 2696, Total Reward: -116\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2697, Total Reward: -100062\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 2698, Total Reward: -100128\n",
      "Episode: 2699, Total Reward: -124\n",
      "Episode: 2700, Total Reward: -112\n",
      "Episode: 2701, Total Reward: -78\n",
      "Episode: 2702, Total Reward: -156\n",
      "Episode: 2703, Total Reward: -62\n",
      "Episode: 2704, Total Reward: -100\n",
      "Episode: 2705, Total Reward: -348\n",
      "Episode: 2706, Total Reward: -108\n",
      "Episode: 2707, Total Reward: -74\n",
      "Episode: 2708, Total Reward: -86\n",
      "Episode: 2709, Total Reward: -472\n",
      "Episode: 2710, Total Reward: -160\n",
      "Episode: 2711, Total Reward: -174\n",
      "Episode: 2712, Total Reward: -90\n",
      "Episode: 2713, Total Reward: -120\n",
      "Episode: 2714, Total Reward: -236\n",
      "Episode: 2715, Total Reward: -60\n",
      "Episode: 2716, Total Reward: -274\n",
      "Episode: 2717, Total Reward: -160\n",
      "Episode: 2718, Total Reward: -106\n",
      "Episode: 2719, Total Reward: -438\n",
      "Episode: 2720, Total Reward: -204\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2721, Total Reward: -100170\n",
      "Episode: 2722, Total Reward: -98\n",
      "Episode: 2723, Total Reward: -440\n",
      "Episode: 2724, Total Reward: -60\n",
      "Episode: 2725, Total Reward: -128\n",
      "Episode: 2726, Total Reward: -172\n",
      "Episode: 2727, Total Reward: -460\n",
      "Episode: 2728, Total Reward: -148\n",
      "Episode: 2729, Total Reward: -106\n",
      "Episode: 2730, Total Reward: -194\n",
      "Episode: 2731, Total Reward: -98\n",
      "Episode: 2732, Total Reward: -86\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2733, Total Reward: -100130\n",
      "Episode: 2734, Total Reward: -98\n",
      "Episode: 2735, Total Reward: -90\n",
      "Episode: 2736, Total Reward: -468\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2737, Total Reward: -100486\n",
      "Episode: 2738, Total Reward: -70\n",
      "Episode: 2739, Total Reward: -70\n",
      "Episode: 2740, Total Reward: -134\n",
      "Episode: 2741, Total Reward: -526\n",
      "Episode: 2742, Total Reward: -266\n",
      "Episode: 2743, Total Reward: -100\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2744, Total Reward: -100432\n",
      "Episode: 2745, Total Reward: -362\n",
      "Episode: 2746, Total Reward: -100\n",
      "Episode: 2747, Total Reward: -70\n",
      "Episode: 2748, Total Reward: -136\n",
      "Episode: 2749, Total Reward: -100\n",
      "Episode: 2750, Total Reward: -100\n",
      "Episode: 2751, Total Reward: -240\n",
      "Episode: 2752, Total Reward: -248\n",
      "Episode: 2753, Total Reward: -148\n",
      "Episode: 2754, Total Reward: -68\n",
      "Episode: 2755, Total Reward: -74\n",
      "Episode: 2756, Total Reward: -90\n",
      "Episode: 2757, Total Reward: -408\n",
      "Episode: 2758, Total Reward: -454\n",
      "Episode: 2759, Total Reward: -46\n",
      "Episode: 2760, Total Reward: -74\n",
      "Episode: 2761, Total Reward: -216\n",
      "Episode: 2762, Total Reward: -156\n",
      "Episode: 2763, Total Reward: -70\n",
      "Episode: 2764, Total Reward: -60\n",
      "Episode: 2765, Total Reward: -72\n",
      "Episode: 2766, Total Reward: -94\n",
      "Episode: 2767, Total Reward: -106\n",
      "Episode: 2768, Total Reward: -50\n",
      "Episode: 2769, Total Reward: -76\n",
      "Episode: 2770, Total Reward: -94\n",
      "Episode: 2771, Total Reward: -52\n",
      "Episode: 2772, Total Reward: -792\n",
      "Episode: 2773, Total Reward: -510\n",
      "Episode: 2774, Total Reward: -428\n",
      "Episode: 2775, Total Reward: -154\n",
      "Episode: 2776, Total Reward: -504\n",
      "Episode: 2777, Total Reward: -152\n",
      "Episode: 2778, Total Reward: -236\n",
      "Episode: 2779, Total Reward: -136\n",
      "Episode: 2780, Total Reward: -144\n",
      "Episode: 2781, Total Reward: -196\n",
      "Episode: 2782, Total Reward: -232\n",
      "Episode: 2783, Total Reward: -50\n",
      "Episode: 2784, Total Reward: -144\n",
      "Episode: 2785, Total Reward: -50\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 2786, Total Reward: -100466\n",
      "Episode: 2787, Total Reward: -124\n",
      "Episode: 2788, Total Reward: -144\n",
      "Episode: 2789, Total Reward: -42\n",
      "Episode: 2790, Total Reward: -176\n",
      "Episode: 2791, Total Reward: -100\n",
      "Episode: 2792, Total Reward: -246\n",
      "Episode: 2793, Total Reward: -108\n",
      "Episode: 2794, Total Reward: -140\n",
      "Episode: 2795, Total Reward: -108\n",
      "Episode: 2796, Total Reward: -270\n",
      "Episode: 2797, Total Reward: -74\n",
      "Episode: 2798, Total Reward: -364\n",
      "Episode: 2799, Total Reward: -92\n",
      "Episode: 2800, Total Reward: -100\n",
      "Episode: 2801, Total Reward: -236\n",
      "Episode: 2802, Total Reward: -60\n",
      "Episode: 2803, Total Reward: -50\n",
      "Episode: 2804, Total Reward: -74\n",
      "Episode: 2805, Total Reward: -46\n",
      "Episode: 2806, Total Reward: -46\n",
      "Episode: 2807, Total Reward: -100\n",
      "Episode: 2808, Total Reward: -112\n",
      "Episode: 2809, Total Reward: -360\n",
      "Episode: 2810, Total Reward: -100\n",
      "Episode: 2811, Total Reward: -86\n",
      "Episode: 2812, Total Reward: -278\n",
      "Episode: 2813, Total Reward: -302\n",
      "Episode: 2814, Total Reward: -108\n",
      "Episode: 2815, Total Reward: -42\n",
      "Episode: 2816, Total Reward: -50\n",
      "Episode: 2817, Total Reward: -356\n",
      "Episode: 2818, Total Reward: -32\n",
      "Episode: 2819, Total Reward: -156\n",
      "Episode: 2820, Total Reward: 2\n",
      "Episode: 2821, Total Reward: -144\n",
      "Episode: 2822, Total Reward: -66\n",
      "Episode: 2823, Total Reward: -328\n",
      "Episode: 2824, Total Reward: -432\n",
      "Episode: 2825, Total Reward: -244\n",
      "Episode: 2826, Total Reward: -152\n",
      "Episode: 2827, Total Reward: -60\n",
      "Episode: 2828, Total Reward: -192\n",
      "Episode: 2829, Total Reward: -102\n",
      "Episode: 2830, Total Reward: -592\n",
      "Episode: 2831, Total Reward: -368\n",
      "Episode: 2832, Total Reward: -74\n",
      "Episode: 2833, Total Reward: -94\n",
      "Episode: 2834, Total Reward: -70\n",
      "Episode: 2835, Total Reward: -124\n",
      "Episode: 2836, Total Reward: -106\n",
      "Episode: 2837, Total Reward: -120\n",
      "Episode: 2838, Total Reward: -50\n",
      "Episode: 2839, Total Reward: -190\n",
      "Episode: 2840, Total Reward: -394\n",
      "Episode: 2841, Total Reward: -268\n",
      "Episode: 2842, Total Reward: -106\n",
      "Episode: 2843, Total Reward: -108\n",
      "Episode: 2844, Total Reward: -74\n",
      "Episode: 2845, Total Reward: -394\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2846, Total Reward: -100192\n",
      "Episode: 2847, Total Reward: -298\n",
      "Episode: 2848, Total Reward: -64\n",
      "Episode: 2849, Total Reward: -378\n",
      "Episode: 2850, Total Reward: -64\n",
      "Episode: 2851, Total Reward: -250\n",
      "Episode: 2852, Total Reward: -124\n",
      "Episode: 2853, Total Reward: -64\n",
      "Episode: 2854, Total Reward: -100\n",
      "Episode: 2855, Total Reward: -92\n",
      "Episode: 2856, Total Reward: -106\n",
      "Episode: 2857, Total Reward: -228\n",
      "Episode: 2858, Total Reward: -60\n",
      "Episode: 2859, Total Reward: -58\n",
      "Episode: 2860, Total Reward: -430\n",
      "Episode: 2861, Total Reward: -260\n",
      "Episode: 2862, Total Reward: -334\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2863, Total Reward: -100008\n",
      "Episode: 2864, Total Reward: -50\n",
      "Episode: 2865, Total Reward: -182\n",
      "Episode: 2866, Total Reward: -288\n",
      "Episode: 2867, Total Reward: -384\n",
      "Episode: 2868, Total Reward: -154\n",
      "Episode: 2869, Total Reward: -74\n",
      "Episode: 2870, Total Reward: -236\n",
      "Episode: 2871, Total Reward: -232\n",
      "Episode: 2872, Total Reward: -396\n",
      "Episode: 2873, Total Reward: -424\n",
      "Episode: 2874, Total Reward: -100\n",
      "Episode: 2875, Total Reward: -120\n",
      "Episode: 2876, Total Reward: -492\n",
      "Episode: 2877, Total Reward: -238\n",
      "Episode: 2878, Total Reward: -114\n",
      "Episode: 2879, Total Reward: -58\n",
      "Episode: 2880, Total Reward: -98\n",
      "Episode: 2881, Total Reward: -104\n",
      "Episode: 2882, Total Reward: -104\n",
      "Episode: 2883, Total Reward: -174\n",
      "Episode: 2884, Total Reward: -66\n",
      "Episode: 2885, Total Reward: -74\n",
      "Episode: 2886, Total Reward: -166\n",
      "Episode: 2887, Total Reward: -430\n",
      "Episode: 2888, Total Reward: -186\n",
      "Episode: 2889, Total Reward: -312\n",
      "Episode: 2890, Total Reward: -66\n",
      "Episode: 2891, Total Reward: -66\n",
      "Episode: 2892, Total Reward: -170\n",
      "Episode: 2893, Total Reward: -100\n",
      "Episode: 2894, Total Reward: -196\n",
      "Episode: 2895, Total Reward: -50\n",
      "Episode: 2896, Total Reward: -54\n",
      "Episode: 2897, Total Reward: -368\n",
      "Episode: 2898, Total Reward: -54\n",
      "Episode: 2899, Total Reward: -226\n",
      "Episode: 2900, Total Reward: -240\n",
      "Episode: 2901, Total Reward: -114\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2902, Total Reward: -99980\n",
      "Episode: 2903, Total Reward: -126\n",
      "Episode: 2904, Total Reward: -62\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2905, Total Reward: -99964\n",
      "Episode: 2906, Total Reward: -222\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2907, Total Reward: -100066\n",
      "Episode: 2908, Total Reward: -10\n",
      "Episode: 2909, Total Reward: -230\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2910, Total Reward: -99922\n",
      "Episode: 2911, Total Reward: -34\n",
      "Episode: 2912, Total Reward: -134\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2913, Total Reward: -100032\n",
      "Episode: 2914, Total Reward: -396\n",
      "Episode: 2915, Total Reward: -100\n",
      "Episode: 2916, Total Reward: 0\n",
      "Episode: 2917, Total Reward: -154\n",
      "Episode: 2918, Total Reward: -206\n",
      "Episode: 2919, Total Reward: -292\n",
      "Episode: 2920, Total Reward: -448\n",
      "Episode: 2921, Total Reward: -150\n",
      "Episode: 2922, Total Reward: -20\n",
      "Episode: 2923, Total Reward: -4\n",
      "Episode: 2924, Total Reward: -134\n",
      "Episode: 2925, Total Reward: -86\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2926, Total Reward: -99956\n",
      "Episode: 2927, Total Reward: -192\n",
      "Episode: 2928, Total Reward: -444\n",
      "Episode: 2929, Total Reward: -144\n",
      "Episode: 2930, Total Reward: -90\n",
      "Episode: 2931, Total Reward: -446\n",
      "Episode: 2932, Total Reward: -86\n",
      "Episode: 2933, Total Reward: -170\n",
      "Episode: 2934, Total Reward: -66\n",
      "Episode: 2935, Total Reward: -526\n",
      "Episode: 2936, Total Reward: -404\n",
      "Episode: 2937, Total Reward: -218\n",
      "Episode: 2938, Total Reward: -134\n",
      "Episode: 2939, Total Reward: -100\n",
      "Episode: 2940, Total Reward: -364\n",
      "Episode: 2941, Total Reward: -72\n",
      "Episode: 2942, Total Reward: -100\n",
      "Episode: 2943, Total Reward: -720\n",
      "Episode: 2944, Total Reward: -114\n",
      "Episode: 2945, Total Reward: -232\n",
      "Episode: 2946, Total Reward: -264\n",
      "Episode: 2947, Total Reward: -100\n",
      "Episode: 2948, Total Reward: -4\n",
      "Episode: 2949, Total Reward: -132\n",
      "Episode: 2950, Total Reward: -166\n",
      "Episode: 2951, Total Reward: -100\n",
      "Episode: 2952, Total Reward: -246\n",
      "Episode: 2953, Total Reward: -120\n",
      "Episode: 2954, Total Reward: -296\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2955, Total Reward: -99964\n",
      "Episode: 2956, Total Reward: -84\n",
      "Episode: 2957, Total Reward: -238\n",
      "Episode: 2958, Total Reward: -414\n",
      "Episode: 2959, Total Reward: -100\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2960, Total Reward: -100172\n",
      "Episode: 2961, Total Reward: -250\n",
      "Episode: 2962, Total Reward: -182\n",
      "Episode: 2963, Total Reward: -416\n",
      "Episode: 2964, Total Reward: -156\n",
      "Episode: 2965, Total Reward: -108\n",
      "Episode: 2966, Total Reward: -212\n",
      "Episode: 2967, Total Reward: -444\n",
      "Episode: 2968, Total Reward: -144\n",
      "Episode: 2969, Total Reward: -194\n",
      "Episode: 2970, Total Reward: -140\n",
      "Episode: 2971, Total Reward: -114\n",
      "Episode: 2972, Total Reward: -230\n",
      "Episode: 2973, Total Reward: -306\n",
      "Episode: 2974, Total Reward: -180\n",
      "Episode: 2975, Total Reward: -134\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2976, Total Reward: -100072\n",
      "Episode: 2977, Total Reward: -354\n",
      "Episode: 2978, Total Reward: -108\n",
      "Episode: 2979, Total Reward: -96\n",
      "Episode: 2980, Total Reward: -212\n",
      "Episode: 2981, Total Reward: -118\n",
      "Episode: 2982, Total Reward: -148\n",
      "Episode: 2983, Total Reward: -354\n",
      "Episode: 2984, Total Reward: -308\n",
      "Episode: 2985, Total Reward: -130\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 2986, Total Reward: -100076\n",
      "Episode: 2987, Total Reward: -116\n",
      "Episode: 2988, Total Reward: 100174\n",
      "Episode: 2989, Total Reward: -362\n",
      "Episode: 2990, Total Reward: -252\n",
      "Episode: 2991, Total Reward: -108\n",
      "Episode: 2992, Total Reward: -100\n",
      "Episode: 2993, Total Reward: -232\n",
      "Episode: 2994, Total Reward: 99864\n",
      "Episode: 2995, Total Reward: -140\n",
      "Episode: 2996, Total Reward: -86\n",
      "Episode: 2997, Total Reward: -32\n",
      "Episode: 2998, Total Reward: -170\n",
      "Episode: 2999, Total Reward: -112\n",
      "Episode: 3000, Total Reward: -236\n",
      "Episode: 3001, Total Reward: -114\n",
      "Episode: 3002, Total Reward: -172\n",
      "Episode: 3003, Total Reward: -100\n",
      "Episode: 3004, Total Reward: -86\n",
      "Episode: 3005, Total Reward: -100\n",
      "Episode: 3006, Total Reward: -130\n",
      "Episode: 3007, Total Reward: -130\n",
      "Episode: 3008, Total Reward: -214\n",
      "Episode: 3009, Total Reward: -104\n",
      "Episode: 3010, Total Reward: -86\n",
      "Episode: 3011, Total Reward: -162\n",
      "Episode: 3012, Total Reward: -168\n",
      "Episode: 3013, Total Reward: -416\n",
      "Episode: 3014, Total Reward: -102\n",
      "Episode: 3015, Total Reward: -716\n",
      "Episode: 3016, Total Reward: -118\n",
      "Episode: 3017, Total Reward: -448\n",
      "Episode: 3018, Total Reward: -50\n",
      "Episode: 3019, Total Reward: -682\n",
      "Episode: 3020, Total Reward: -150\n",
      "Episode: 3021, Total Reward: -298\n",
      "Episode: 3022, Total Reward: -128\n",
      "Episode: 3023, Total Reward: -148\n",
      "Episode: 3024, Total Reward: -416\n",
      "Episode: 3025, Total Reward: -128\n",
      "Episode: 3026, Total Reward: -142\n",
      "Episode: 3027, Total Reward: -86\n",
      "Episode: 3028, Total Reward: -36\n",
      "Episode: 3029, Total Reward: -422\n",
      "Episode: 3030, Total Reward: -158\n",
      "Episode: 3031, Total Reward: -38\n",
      "Episode: 3032, Total Reward: -118\n",
      "Episode: 3033, Total Reward: -90\n",
      "Episode: 3034, Total Reward: -86\n",
      "Episode: 3035, Total Reward: -100\n",
      "Episode: 3036, Total Reward: -180\n",
      "Episode: 3037, Total Reward: -272\n",
      "Episode: 3038, Total Reward: -140\n",
      "Episode: 3039, Total Reward: -106\n",
      "Episode: 3040, Total Reward: -182\n",
      "Episode: 3041, Total Reward: -218\n",
      "Episode: 3042, Total Reward: -112\n",
      "Episode: 3043, Total Reward: -112\n",
      "Episode: 3044, Total Reward: -146\n",
      "Episode: 3045, Total Reward: -114\n",
      "Episode: 3046, Total Reward: -102\n",
      "Episode: 3047, Total Reward: -106\n",
      "Episode: 3048, Total Reward: -382\n",
      "Episode: 3049, Total Reward: -90\n",
      "Episode: 3050, Total Reward: -192\n",
      "Episode: 3051, Total Reward: -86\n",
      "Episode: 3052, Total Reward: -396\n",
      "Episode: 3053, Total Reward: -100\n",
      "Episode: 3054, Total Reward: -104\n",
      "Episode: 3055, Total Reward: -70\n",
      "Episode: 3056, Total Reward: -60\n",
      "Episode: 3057, Total Reward: -174\n",
      "Episode: 3058, Total Reward: -86\n",
      "Episode: 3059, Total Reward: -196\n",
      "Episode: 3060, Total Reward: -46\n",
      "Episode: 3061, Total Reward: -112\n",
      "Episode: 3062, Total Reward: -374\n",
      "Episode: 3063, Total Reward: -268\n",
      "Episode: 3064, Total Reward: -142\n",
      "Episode: 3065, Total Reward: -120\n",
      "Episode: 3066, Total Reward: -998\n",
      "Episode: 3067, Total Reward: -142\n",
      "Episode: 3068, Total Reward: -100\n",
      "Episode: 3069, Total Reward: -590\n",
      "Episode: 3070, Total Reward: -100\n",
      "Episode: 3071, Total Reward: -132\n",
      "Episode: 3072, Total Reward: -74\n",
      "Episode: 3073, Total Reward: -298\n",
      "Episode: 3074, Total Reward: -74\n",
      "Episode: 3075, Total Reward: -274\n",
      "Episode: 3076, Total Reward: -300\n",
      "Episode: 3077, Total Reward: -278\n",
      "Episode: 3078, Total Reward: -128\n",
      "Episode: 3079, Total Reward: -80\n",
      "Episode: 3080, Total Reward: -274\n",
      "Episode: 3081, Total Reward: -102\n",
      "Episode: 3082, Total Reward: -282\n",
      "Episode: 3083, Total Reward: -148\n",
      "Episode: 3084, Total Reward: -410\n",
      "Episode: 3085, Total Reward: -42\n",
      "Episode: 3086, Total Reward: -90\n",
      "Episode: 3087, Total Reward: -100\n",
      "Episode: 3088, Total Reward: -252\n",
      "Episode: 3089, Total Reward: -86\n",
      "Episode: 3090, Total Reward: -306\n",
      "Episode: 3091, Total Reward: -204\n",
      "Episode: 3092, Total Reward: -82\n",
      "Episode: 3093, Total Reward: -244\n",
      "Episode: 3094, Total Reward: -332\n",
      "Episode: 3095, Total Reward: -162\n",
      "Episode: 3096, Total Reward: -112\n",
      "Episode: 3097, Total Reward: -246\n",
      "Episode: 3098, Total Reward: -150\n",
      "Episode: 3099, Total Reward: -60\n",
      "Episode: 3100, Total Reward: -106\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 3101, Total Reward: -100298\n",
      "Episode: 3102, Total Reward: -140\n",
      "Episode: 3103, Total Reward: -140\n",
      "Episode: 3104, Total Reward: -86\n",
      "Episode: 3105, Total Reward: -116\n",
      "Episode: 3106, Total Reward: -100\n",
      "Episode: 3107, Total Reward: -526\n",
      "Episode: 3108, Total Reward: -170\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 3109, Total Reward: -100474\n",
      "Episode: 3110, Total Reward: -280\n",
      "Episode: 3111, Total Reward: -136\n",
      "Episode: 3112, Total Reward: -100\n",
      "Episode: 3113, Total Reward: -112\n",
      "Episode: 3114, Total Reward: -440\n",
      "Episode: 3115, Total Reward: -162\n",
      "Episode: 3116, Total Reward: -282\n",
      "Episode: 3117, Total Reward: -352\n",
      "Episode: 3118, Total Reward: -254\n",
      "Episode: 3119, Total Reward: -300\n",
      "Episode: 3120, Total Reward: -46\n",
      "Episode: 3121, Total Reward: -658\n",
      "Episode: 3122, Total Reward: -106\n",
      "Episode: 3123, Total Reward: -90\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 3124, Total Reward: -100786\n",
      "Episode: 3125, Total Reward: -146\n",
      "Episode: 3126, Total Reward: -456\n",
      "Episode: 3127, Total Reward: -200\n",
      "Episode: 3128, Total Reward: -140\n",
      "Episode: 3129, Total Reward: -176\n",
      "Episode: 3130, Total Reward: -192\n",
      "Episode: 3131, Total Reward: -106\n",
      "Episode: 3132, Total Reward: -166\n",
      "Episode: 3133, Total Reward: -140\n",
      "Episode: 3134, Total Reward: -354\n",
      "Episode: 3135, Total Reward: -114\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 3136, Total Reward: -100398\n",
      "Episode: 3137, Total Reward: -86\n",
      "Episode: 3138, Total Reward: -302\n",
      "Episode: 3139, Total Reward: -352\n",
      "Episode: 3140, Total Reward: -188\n",
      "Episode: 3141, Total Reward: -70\n",
      "Episode: 3142, Total Reward: -662\n",
      "Episode: 3143, Total Reward: -100\n",
      "Episode: 3144, Total Reward: -136\n",
      "Episode: 3145, Total Reward: -136\n",
      "Episode: 3146, Total Reward: -296\n",
      "Episode: 3147, Total Reward: -164\n",
      "Episode: 3148, Total Reward: -92\n",
      "Episode: 3149, Total Reward: -136\n",
      "Episode: 3150, Total Reward: -32\n",
      "Episode: 3151, Total Reward: -90\n",
      "Episode: 3152, Total Reward: -114\n",
      "Episode: 3153, Total Reward: -70\n",
      "Episode: 3154, Total Reward: -100\n",
      "Episode: 3155, Total Reward: -274\n",
      "Episode: 3156, Total Reward: -106\n",
      "Episode: 3157, Total Reward: -384\n",
      "Episode: 3158, Total Reward: -148\n",
      "Episode: 3159, Total Reward: -46\n",
      "Episode: 3160, Total Reward: -134\n",
      "Episode: 3161, Total Reward: -112\n",
      "Episode: 3162, Total Reward: -1532\n",
      "Episode: 3163, Total Reward: -100\n",
      "Episode: 3164, Total Reward: -84\n",
      "Episode: 3165, Total Reward: -64\n",
      "Episode: 3166, Total Reward: -216\n",
      "Episode: 3167, Total Reward: -130\n",
      "Episode: 3168, Total Reward: -98\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 3169, Total Reward: -100554\n",
      "Episode: 3170, Total Reward: -162\n",
      "Episode: 3171, Total Reward: -316\n",
      "Episode: 3172, Total Reward: -126\n",
      "Episode: 3173, Total Reward: -136\n",
      "Episode: 3174, Total Reward: -216\n",
      "Episode: 3175, Total Reward: -256\n",
      "Episode: 3176, Total Reward: -90\n",
      "Episode: 3177, Total Reward: -108\n",
      "Episode: 3178, Total Reward: -80\n",
      "Episode: 3179, Total Reward: -260\n",
      "Episode: 3180, Total Reward: -46\n",
      "Episode: 3181, Total Reward: -296\n",
      "Episode: 3182, Total Reward: -156\n",
      "Episode: 3183, Total Reward: -46\n",
      "Episode: 3184, Total Reward: -414\n",
      "Episode: 3185, Total Reward: -132\n",
      "Episode: 3186, Total Reward: -296\n",
      "Episode: 3187, Total Reward: -242\n",
      "Episode: 3188, Total Reward: -86\n",
      "Episode: 3189, Total Reward: -90\n",
      "Episode: 3190, Total Reward: -108\n",
      "Episode: 3191, Total Reward: -100\n",
      "Episode: 3192, Total Reward: -404\n",
      "Episode: 3193, Total Reward: -86\n",
      "Episode: 3194, Total Reward: -100\n",
      "Episode: 3195, Total Reward: -394\n",
      "Episode: 3196, Total Reward: -90\n",
      "Episode: 3197, Total Reward: -254\n",
      "Episode: 3198, Total Reward: -162\n",
      "Episode: 3199, Total Reward: -454\n",
      "Episode: 3200, Total Reward: -90\n",
      "Episode: 3201, Total Reward: -140\n",
      "Episode: 3202, Total Reward: -90\n",
      "Episode: 3203, Total Reward: -144\n",
      "Episode: 3204, Total Reward: -240\n",
      "Episode: 3205, Total Reward: -100\n",
      "Episode: 3206, Total Reward: -472\n",
      "Episode: 3207, Total Reward: -168\n",
      "Episode: 3208, Total Reward: -182\n",
      "Episode: 3209, Total Reward: -146\n",
      "Episode: 3210, Total Reward: -90\n",
      "Episode: 3211, Total Reward: -112\n",
      "Episode: 3212, Total Reward: -400\n",
      "Episode: 3213, Total Reward: -140\n",
      "Episode: 3214, Total Reward: -108\n",
      "Episode: 3215, Total Reward: -90\n",
      "Episode: 3216, Total Reward: -106\n",
      "Episode: 3217, Total Reward: -100\n",
      "Episode: 3218, Total Reward: -156\n",
      "Episode: 3219, Total Reward: -128\n",
      "Episode: 3220, Total Reward: -42\n",
      "Episode: 3221, Total Reward: -100\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 3222, Total Reward: -99974\n",
      "Episode: 3223, Total Reward: -146\n",
      "Episode: 3224, Total Reward: -140\n",
      "Episode: 3225, Total Reward: -100\n",
      "Episode: 3226, Total Reward: -90\n",
      "Episode: 3227, Total Reward: -100\n",
      "Episode: 3228, Total Reward: -100\n",
      "Episode: 3229, Total Reward: -100\n",
      "Episode: 3230, Total Reward: -404\n",
      "Episode: 3231, Total Reward: -558\n",
      "Episode: 3232, Total Reward: -100\n",
      "Episode: 3233, Total Reward: -188\n",
      "Episode: 3234, Total Reward: -68\n",
      "Episode: 3235, Total Reward: -92\n",
      "Episode: 3236, Total Reward: -130\n",
      "Episode: 3237, Total Reward: -100\n",
      "Episode: 3238, Total Reward: -90\n",
      "Episode: 3239, Total Reward: -124\n",
      "Episode: 3240, Total Reward: -100\n",
      "Episode: 3241, Total Reward: -100\n",
      "Episode: 3242, Total Reward: -124\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 3243, Total Reward: -100146\n",
      "Episode: 3244, Total Reward: -152\n",
      "Episode: 3245, Total Reward: -114\n",
      "Episode: 3246, Total Reward: -200\n",
      "Episode: 3247, Total Reward: -136\n",
      "Episode: 3248, Total Reward: -108\n",
      "Episode: 3249, Total Reward: -240\n",
      "Episode: 3250, Total Reward: -164\n",
      "Episode: 3251, Total Reward: -168\n",
      "Episode: 3252, Total Reward: -164\n",
      "Episode: 3253, Total Reward: -154\n",
      "Episode: 3254, Total Reward: -100\n",
      "Episode: 3255, Total Reward: -92\n",
      "Episode: 3256, Total Reward: -104\n",
      "Episode: 3257, Total Reward: -100\n",
      "Episode: 3258, Total Reward: -140\n",
      "Episode: 3259, Total Reward: -86\n",
      "Episode: 3260, Total Reward: -104\n",
      "Episode: 3261, Total Reward: -136\n",
      "Episode: 3262, Total Reward: -100\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 3263, Total Reward: -100562\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 3264, Total Reward: -100854\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 3265, Total Reward: -100160\n",
      "Episode: 3266, Total Reward: -114\n",
      "Episode: 3267, Total Reward: -168\n",
      "Episode: 3268, Total Reward: -324\n",
      "Episode: 3269, Total Reward: -100\n",
      "Episode: 3270, Total Reward: -114\n",
      "Episode: 3271, Total Reward: -168\n",
      "Episode: 3272, Total Reward: -268\n",
      "Episode: 3273, Total Reward: -148\n",
      "Episode: 3274, Total Reward: -210\n",
      "Episode: 3275, Total Reward: -436\n",
      "Episode: 3276, Total Reward: -100\n",
      "Episode: 3277, Total Reward: -106\n",
      "Episode: 3278, Total Reward: -100\n",
      "Episode: 3279, Total Reward: -694\n",
      "Episode: 3280, Total Reward: -80\n",
      "Episode: 3281, Total Reward: -100\n",
      "Episode: 3282, Total Reward: -106\n",
      "Episode: 3283, Total Reward: -206\n",
      "Episode: 3284, Total Reward: -154\n",
      "Episode: 3285, Total Reward: -184\n",
      "Episode: 3286, Total Reward: -100\n",
      "Episode: 3287, Total Reward: -272\n",
      "Episode: 3288, Total Reward: -438\n",
      "Episode: 3289, Total Reward: -122\n",
      "Episode: 3290, Total Reward: -150\n",
      "Episode: 3291, Total Reward: -30\n",
      "Episode: 3292, Total Reward: -452\n",
      "Episode: 3293, Total Reward: -104\n",
      "Episode: 3294, Total Reward: -84\n",
      "Episode: 3295, Total Reward: -204\n",
      "Episode: 3296, Total Reward: -22\n",
      "Episode: 3297, Total Reward: -22\n",
      "Episode: 3298, Total Reward: -132\n",
      "Episode: 3299, Total Reward: -154\n",
      "Episode: 3300, Total Reward: -140\n",
      "Episode: 3301, Total Reward: -164\n",
      "Episode: 3302, Total Reward: -230\n",
      "Episode: 3303, Total Reward: -172\n",
      "Episode: 3304, Total Reward: -168\n",
      "Episode: 3305, Total Reward: -302\n",
      "Episode: 3306, Total Reward: -198\n",
      "Episode: 3307, Total Reward: -112\n",
      "Episode: 3308, Total Reward: -168\n",
      "Episode: 3309, Total Reward: -140\n",
      "Episode: 3310, Total Reward: -136\n",
      "Episode: 3311, Total Reward: -140\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 3312, Total Reward: -100860\n",
      "Episode: 3313, Total Reward: -104\n",
      "Episode: 3314, Total Reward: -412\n",
      "Episode: 3315, Total Reward: -178\n",
      "Episode: 3316, Total Reward: -242\n",
      "Episode: 3317, Total Reward: -210\n",
      "Episode: 3318, Total Reward: -104\n",
      "Episode: 3319, Total Reward: -100\n",
      "Episode: 3320, Total Reward: -100\n",
      "Episode: 3321, Total Reward: -128\n",
      "Episode: 3322, Total Reward: -104\n",
      "Episode: 3323, Total Reward: -120\n",
      "Episode: 3324, Total Reward: -400\n",
      "Episode: 3325, Total Reward: -326\n",
      "Episode: 3326, Total Reward: -228\n",
      "Episode: 3327, Total Reward: -106\n",
      "Episode: 3328, Total Reward: -272\n",
      "Episode: 3329, Total Reward: -352\n",
      "Episode: 3330, Total Reward: -84\n",
      "Episode: 3331, Total Reward: -168\n",
      "Episode: 3332, Total Reward: -90\n",
      "Episode: 3333, Total Reward: -140\n",
      "Episode: 3334, Total Reward: -100\n",
      "Episode: 3335, Total Reward: -180\n",
      "Episode: 3336, Total Reward: -100\n",
      "Episode: 3337, Total Reward: -100\n",
      "Episode: 3338, Total Reward: -86\n",
      "Episode: 3339, Total Reward: -86\n",
      "Episode: 3340, Total Reward: -104\n",
      "Episode: 3341, Total Reward: -128\n",
      "Episode: 3342, Total Reward: -778\n",
      "Episode: 3343, Total Reward: -100\n",
      "Episode: 3344, Total Reward: -100\n",
      "Episode: 3345, Total Reward: -166\n",
      "Episode: 3346, Total Reward: -100\n",
      "Episode: 3347, Total Reward: -100\n",
      "Episode: 3348, Total Reward: -90\n",
      "Episode: 3349, Total Reward: -278\n",
      "Episode: 3350, Total Reward: -140\n",
      "Episode: 3351, Total Reward: -154\n",
      "Episode: 3352, Total Reward: -168\n",
      "Episode: 3353, Total Reward: -100\n",
      "Episode: 3354, Total Reward: -452\n",
      "Episode: 3355, Total Reward: -176\n",
      "Episode: 3356, Total Reward: -100\n",
      "Episode: 3357, Total Reward: -172\n",
      "Episode: 3358, Total Reward: -32\n",
      "Episode: 3359, Total Reward: -140\n",
      "Episode: 3360, Total Reward: -128\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 3361, Total Reward: -100512\n",
      "Episode: 3362, Total Reward: -120\n",
      "Episode: 3363, Total Reward: -232\n",
      "Episode: 3364, Total Reward: -420\n",
      "Episode: 3365, Total Reward: -112\n",
      "Episode: 3366, Total Reward: -130\n",
      "Episode: 3367, Total Reward: -448\n",
      "Episode: 3368, Total Reward: -120\n",
      "Episode: 3369, Total Reward: -112\n",
      "Episode: 3370, Total Reward: -106\n",
      "Episode: 3371, Total Reward: -180\n",
      "Episode: 3372, Total Reward: -124\n",
      "Episode: 3373, Total Reward: -154\n",
      "Episode: 3374, Total Reward: -172\n",
      "Episode: 3375, Total Reward: -108\n",
      "Episode: 3376, Total Reward: -534\n",
      "Episode: 3377, Total Reward: -240\n",
      "Episode: 3378, Total Reward: -408\n",
      "Episode: 3379, Total Reward: -112\n",
      "Episode: 3380, Total Reward: -206\n",
      "Episode: 3381, Total Reward: -246\n",
      "Episode: 3382, Total Reward: -436\n",
      "Episode: 3383, Total Reward: -134\n",
      "Episode: 3384, Total Reward: -626\n",
      "Episode: 3385, Total Reward: -140\n",
      "Episode: 3386, Total Reward: -106\n",
      "Episode: 3387, Total Reward: -172\n",
      "Episode: 3388, Total Reward: -560\n",
      "Episode: 3389, Total Reward: -36\n",
      "Episode: 3390, Total Reward: -118\n",
      "Episode: 3391, Total Reward: -136\n",
      "Episode: 3392, Total Reward: -104\n",
      "Episode: 3393, Total Reward: -536\n",
      "Episode: 3394, Total Reward: -180\n",
      "Episode: 3395, Total Reward: -100\n",
      "Episode: 3396, Total Reward: -428\n",
      "Episode: 3397, Total Reward: -140\n",
      "Episode: 3398, Total Reward: -140\n",
      "Episode: 3399, Total Reward: -38\n",
      "Episode: 3400, Total Reward: -106\n",
      "Episode: 3401, Total Reward: -584\n",
      "Episode: 3402, Total Reward: 99756\n",
      "Episode: 3403, Total Reward: -40\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 3404, Total Reward: -100602\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 3405, Total Reward: -100230\n",
      "Episode: 3406, Total Reward: -116\n",
      "Episode: 3407, Total Reward: -206\n",
      "Episode: 3408, Total Reward: -106\n",
      "Episode: 3409, Total Reward: -100\n",
      "Episode: 3410, Total Reward: -126\n",
      "Episode: 3411, Total Reward: -122\n",
      "Episode: 3412, Total Reward: -38\n",
      "Episode: 3413, Total Reward: -154\n",
      "Episode: 3414, Total Reward: -138\n",
      "Episode: 3415, Total Reward: -374\n",
      "Episode: 3416, Total Reward: -168\n",
      "Episode: 3417, Total Reward: -140\n",
      "Episode: 3418, Total Reward: -190\n",
      "Episode: 3419, Total Reward: -250\n",
      "Episode: 3420, Total Reward: -210\n",
      "Episode: 3421, Total Reward: -452\n",
      "Episode: 3422, Total Reward: -108\n",
      "Episode: 3423, Total Reward: -164\n",
      "Episode: 3424, Total Reward: -176\n",
      "Episode: 3425, Total Reward: -514\n",
      "Episode: 3426, Total Reward: -200\n",
      "Episode: 3427, Total Reward: -168\n",
      "Episode: 3428, Total Reward: -310\n",
      "Episode: 3429, Total Reward: -120\n",
      "Episode: 3430, Total Reward: -204\n",
      "Episode: 3431, Total Reward: -150\n",
      "Episode: 3432, Total Reward: -104\n",
      "Episode: 3433, Total Reward: -100\n",
      "Episode: 3434, Total Reward: -278\n",
      "Episode: 3435, Total Reward: -140\n",
      "Episode: 3436, Total Reward: -746\n",
      "Episode: 3437, Total Reward: -296\n",
      "Episode: 3438, Total Reward: -104\n",
      "Episode: 3439, Total Reward: -104\n",
      "Episode: 3440, Total Reward: -298\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 3441, Total Reward: -100316\n",
      "Episode: 3442, Total Reward: -186\n",
      "Episode: 3443, Total Reward: -486\n",
      "Episode: 3444, Total Reward: -176\n",
      "Episode: 3445, Total Reward: -136\n",
      "Episode: 3446, Total Reward: -108\n",
      "Episode: 3447, Total Reward: -100\n",
      "Episode: 3448, Total Reward: -134\n",
      "Episode: 3449, Total Reward: -24\n",
      "Episode: 3450, Total Reward: -42\n",
      "Episode: 3451, Total Reward: -222\n",
      "Episode: 3452, Total Reward: -80\n",
      "Episode: 3453, Total Reward: -78\n",
      "Episode: 3454, Total Reward: -412\n",
      "Episode: 3455, Total Reward: -312\n",
      "Episode: 3456, Total Reward: -80\n",
      "Episode: 3457, Total Reward: -100\n",
      "Invalid Action: Invalid column: 6\n",
      "Episode: 3458, Total Reward: -100720\n",
      "Episode: 3459, Total Reward: -86\n",
      "Episode: 3460, Total Reward: -140\n",
      "Episode: 3461, Total Reward: -116\n",
      "Episode: 3462, Total Reward: -128\n",
      "Episode: 3463, Total Reward: -128\n",
      "Episode: 3464, Total Reward: -94\n",
      "Episode: 3465, Total Reward: -136\n",
      "Episode: 3466, Total Reward: -100\n",
      "Episode: 3467, Total Reward: -128\n",
      "Episode: 3468, Total Reward: -168\n",
      "Episode: 3469, Total Reward: -106\n",
      "Episode: 3470, Total Reward: -218\n",
      "Episode: 3471, Total Reward: -92\n",
      "Episode: 3472, Total Reward: -100\n",
      "Episode: 3473, Total Reward: -100\n",
      "Episode: 3474, Total Reward: -100\n",
      "Episode: 3475, Total Reward: -100\n",
      "Episode: 3476, Total Reward: -140\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 3477, Total Reward: -101006\n",
      "Episode: 3478, Total Reward: -108\n",
      "Episode: 3479, Total Reward: -232\n",
      "Episode: 3480, Total Reward: -250\n",
      "Episode: 3481, Total Reward: -176\n",
      "Episode: 3482, Total Reward: -488\n",
      "Episode: 3483, Total Reward: -78\n",
      "Episode: 3484, Total Reward: -332\n",
      "Episode: 3485, Total Reward: -100\n",
      "Episode: 3486, Total Reward: -114\n",
      "Episode: 3487, Total Reward: -424\n",
      "Episode: 3488, Total Reward: -412\n",
      "Episode: 3489, Total Reward: -140\n",
      "Episode: 3490, Total Reward: -100\n",
      "Episode: 3491, Total Reward: -154\n",
      "Episode: 3492, Total Reward: -128\n",
      "Episode: 3493, Total Reward: -156\n",
      "Episode: 3494, Total Reward: -100\n",
      "Episode: 3495, Total Reward: -256\n",
      "Episode: 3496, Total Reward: -100\n",
      "Episode: 3497, Total Reward: -124\n",
      "Episode: 3498, Total Reward: -112\n",
      "Episode: 3499, Total Reward: -112\n",
      "Episode: 3500, Total Reward: -108\n",
      "Episode: 3501, Total Reward: -100\n",
      "Episode: 3502, Total Reward: -124\n",
      "Episode: 3503, Total Reward: -450\n",
      "Episode: 3504, Total Reward: -120\n",
      "Episode: 3505, Total Reward: -330\n",
      "Episode: 3506, Total Reward: -230\n",
      "Episode: 3507, Total Reward: -164\n",
      "Episode: 3508, Total Reward: -186\n",
      "Episode: 3509, Total Reward: -136\n",
      "Episode: 3510, Total Reward: -40\n",
      "Episode: 3511, Total Reward: -78\n",
      "Episode: 3512, Total Reward: -168\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 3513, Total Reward: -100104\n",
      "Episode: 3514, Total Reward: -100\n",
      "Episode: 3515, Total Reward: -436\n",
      "Episode: 3516, Total Reward: -100\n",
      "Episode: 3517, Total Reward: -176\n",
      "Episode: 3518, Total Reward: -286\n",
      "Episode: 3519, Total Reward: -258\n",
      "Episode: 3520, Total Reward: -176\n",
      "Episode: 3521, Total Reward: -136\n",
      "Episode: 3522, Total Reward: -502\n",
      "Episode: 3523, Total Reward: -272\n",
      "Episode: 3524, Total Reward: -194\n",
      "Episode: 3525, Total Reward: -246\n",
      "Episode: 3526, Total Reward: -102\n",
      "Episode: 3527, Total Reward: -36\n",
      "Episode: 3528, Total Reward: -36\n",
      "Episode: 3529, Total Reward: -38\n",
      "Episode: 3530, Total Reward: -80\n",
      "Episode: 3531, Total Reward: -32\n",
      "Episode: 3532, Total Reward: -406\n",
      "Episode: 3533, Total Reward: -74\n",
      "Episode: 3534, Total Reward: -36\n",
      "Episode: 3535, Total Reward: -80\n",
      "Episode: 3536, Total Reward: -80\n",
      "Episode: 3537, Total Reward: -106\n",
      "Episode: 3538, Total Reward: -38\n",
      "Episode: 3539, Total Reward: -402\n",
      "Episode: 3540, Total Reward: -48\n",
      "Episode: 3541, Total Reward: -344\n",
      "Episode: 3542, Total Reward: -194\n",
      "Episode: 3543, Total Reward: -42\n",
      "Episode: 3544, Total Reward: -164\n",
      "Episode: 3545, Total Reward: -158\n",
      "Episode: 3546, Total Reward: -132\n",
      "Episode: 3547, Total Reward: -42\n",
      "Episode: 3548, Total Reward: -220\n",
      "Episode: 3549, Total Reward: -360\n",
      "Episode: 3550, Total Reward: -38\n",
      "Episode: 3551, Total Reward: -150\n",
      "Episode: 3552, Total Reward: -108\n",
      "Episode: 3553, Total Reward: -162\n",
      "Episode: 3554, Total Reward: -250\n",
      "Episode: 3555, Total Reward: -268\n",
      "Episode: 3556, Total Reward: -170\n",
      "Episode: 3557, Total Reward: -306\n",
      "Episode: 3558, Total Reward: -232\n",
      "Episode: 3559, Total Reward: -200\n",
      "Episode: 3560, Total Reward: -100\n",
      "Episode: 3561, Total Reward: -112\n",
      "Episode: 3562, Total Reward: -154\n",
      "Episode: 3563, Total Reward: -844\n",
      "Episode: 3564, Total Reward: -84\n",
      "Episode: 3565, Total Reward: -100\n",
      "Episode: 3566, Total Reward: -206\n",
      "Episode: 3567, Total Reward: -150\n",
      "Episode: 3568, Total Reward: -100\n",
      "Episode: 3569, Total Reward: -186\n",
      "Episode: 3570, Total Reward: -164\n",
      "Episode: 3571, Total Reward: -144\n",
      "Episode: 3572, Total Reward: -364\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 3573, Total Reward: -100924\n",
      "Episode: 3574, Total Reward: -100\n",
      "Episode: 3575, Total Reward: -242\n",
      "Episode: 3576, Total Reward: -120\n",
      "Episode: 3577, Total Reward: -104\n",
      "Episode: 3578, Total Reward: -210\n",
      "Episode: 3579, Total Reward: -176\n",
      "Episode: 3580, Total Reward: -120\n",
      "Episode: 3581, Total Reward: -128\n",
      "Episode: 3582, Total Reward: -100\n",
      "Episode: 3583, Total Reward: -108\n",
      "Episode: 3584, Total Reward: -112\n",
      "Episode: 3585, Total Reward: -108\n",
      "Episode: 3586, Total Reward: -478\n",
      "Episode: 3587, Total Reward: -210\n",
      "Episode: 3588, Total Reward: -134\n",
      "Episode: 3589, Total Reward: -208\n",
      "Episode: 3590, Total Reward: -656\n",
      "Episode: 3591, Total Reward: -414\n",
      "Episode: 3592, Total Reward: -266\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 3593, Total Reward: -100078\n",
      "Episode: 3594, Total Reward: -84\n",
      "Episode: 3595, Total Reward: -104\n",
      "Episode: 3596, Total Reward: -100\n",
      "Episode: 3597, Total Reward: -180\n",
      "Episode: 3598, Total Reward: -80\n",
      "Episode: 3599, Total Reward: -74\n",
      "Episode: 3600, Total Reward: -40\n",
      "Episode: 3601, Total Reward: -82\n",
      "Episode: 3602, Total Reward: -136\n",
      "Episode: 3603, Total Reward: -140\n",
      "Episode: 3604, Total Reward: -184\n",
      "Episode: 3605, Total Reward: -154\n",
      "Episode: 3606, Total Reward: -436\n",
      "Episode: 3607, Total Reward: -120\n",
      "Episode: 3608, Total Reward: -100\n",
      "Episode: 3609, Total Reward: -124\n",
      "Episode: 3610, Total Reward: -200\n",
      "Episode: 3611, Total Reward: -120\n",
      "Episode: 3612, Total Reward: -112\n",
      "Episode: 3613, Total Reward: -140\n",
      "Episode: 3614, Total Reward: -432\n",
      "Episode: 3615, Total Reward: -146\n",
      "Episode: 3616, Total Reward: -106\n",
      "Episode: 3617, Total Reward: -66\n",
      "Episode: 3618, Total Reward: -62\n",
      "Episode: 3619, Total Reward: -38\n",
      "Episode: 3620, Total Reward: -38\n",
      "Episode: 3621, Total Reward: -136\n",
      "Episode: 3622, Total Reward: -192\n",
      "Episode: 3623, Total Reward: -42\n",
      "Episode: 3624, Total Reward: -126\n",
      "Episode: 3625, Total Reward: -154\n",
      "Episode: 3626, Total Reward: -62\n",
      "Episode: 3627, Total Reward: -36\n",
      "Episode: 3628, Total Reward: -130\n",
      "Episode: 3629, Total Reward: -162\n",
      "Episode: 3630, Total Reward: -38\n",
      "Episode: 3631, Total Reward: -22\n",
      "Episode: 3632, Total Reward: -228\n",
      "Episode: 3633, Total Reward: -138\n",
      "Episode: 3634, Total Reward: -278\n",
      "Episode: 3635, Total Reward: -80\n",
      "Episode: 3636, Total Reward: -104\n",
      "Episode: 3637, Total Reward: -184\n",
      "Episode: 3638, Total Reward: -150\n",
      "Episode: 3639, Total Reward: -398\n",
      "Episode: 3640, Total Reward: -34\n",
      "Episode: 3641, Total Reward: -126\n",
      "Episode: 3642, Total Reward: -210\n",
      "Episode: 3643, Total Reward: -108\n",
      "Episode: 3644, Total Reward: -40\n",
      "Episode: 3645, Total Reward: -62\n",
      "Episode: 3646, Total Reward: -120\n",
      "Episode: 3647, Total Reward: -20\n",
      "Episode: 3648, Total Reward: -406\n",
      "Episode: 3649, Total Reward: -158\n",
      "Episode: 3650, Total Reward: -62\n",
      "Episode: 3651, Total Reward: -64\n",
      "Episode: 3652, Total Reward: -78\n",
      "Episode: 3653, Total Reward: -560\n",
      "Episode: 3654, Total Reward: -60\n",
      "Episode: 3655, Total Reward: -328\n",
      "Episode: 3656, Total Reward: -116\n",
      "Episode: 3657, Total Reward: -156\n",
      "Episode: 3658, Total Reward: -408\n",
      "Episode: 3659, Total Reward: -114\n",
      "Episode: 3660, Total Reward: -212\n",
      "Episode: 3661, Total Reward: -102\n",
      "Episode: 3662, Total Reward: -62\n",
      "Episode: 3663, Total Reward: -258\n",
      "Episode: 3664, Total Reward: -122\n",
      "Episode: 3665, Total Reward: -214\n",
      "Episode: 3666, Total Reward: -270\n",
      "Episode: 3667, Total Reward: -36\n",
      "Episode: 3668, Total Reward: -74\n",
      "Episode: 3669, Total Reward: -94\n",
      "Episode: 3670, Total Reward: -12\n",
      "Episode: 3671, Total Reward: -208\n",
      "Episode: 3672, Total Reward: -24\n",
      "Episode: 3673, Total Reward: -170\n",
      "Episode: 3674, Total Reward: -186\n",
      "Episode: 3675, Total Reward: -60\n",
      "Episode: 3676, Total Reward: -130\n",
      "Episode: 3677, Total Reward: -98\n",
      "Episode: 3678, Total Reward: -448\n",
      "Episode: 3679, Total Reward: -76\n",
      "Episode: 3680, Total Reward: -62\n",
      "Episode: 3681, Total Reward: -62\n",
      "Episode: 3682, Total Reward: -116\n",
      "Episode: 3683, Total Reward: -252\n",
      "Episode: 3684, Total Reward: -62\n",
      "Episode: 3685, Total Reward: -62\n",
      "Episode: 3686, Total Reward: -62\n",
      "Episode: 3687, Total Reward: -80\n",
      "Episode: 3688, Total Reward: -158\n",
      "Episode: 3689, Total Reward: -706\n",
      "Episode: 3690, Total Reward: -108\n",
      "Episode: 3691, Total Reward: -300\n",
      "Episode: 3692, Total Reward: -228\n",
      "Episode: 3693, Total Reward: -320\n",
      "Episode: 3694, Total Reward: -40\n",
      "Episode: 3695, Total Reward: -230\n",
      "Episode: 3696, Total Reward: -106\n",
      "Episode: 3697, Total Reward: -180\n",
      "Episode: 3698, Total Reward: -252\n",
      "Episode: 3699, Total Reward: -32\n",
      "Episode: 3700, Total Reward: -164\n",
      "Episode: 3701, Total Reward: -36\n",
      "Episode: 3702, Total Reward: -270\n",
      "Episode: 3703, Total Reward: -44\n",
      "Episode: 3704, Total Reward: -434\n",
      "Episode: 3705, Total Reward: -106\n",
      "Episode: 3706, Total Reward: -66\n",
      "Episode: 3707, Total Reward: -68\n",
      "Episode: 3708, Total Reward: -164\n",
      "Episode: 3709, Total Reward: -184\n",
      "Episode: 3710, Total Reward: -72\n",
      "Episode: 3711, Total Reward: -192\n",
      "Episode: 3712, Total Reward: -194\n",
      "Episode: 3713, Total Reward: -84\n",
      "Episode: 3714, Total Reward: -204\n",
      "Episode: 3715, Total Reward: -136\n",
      "Episode: 3716, Total Reward: -106\n",
      "Episode: 3717, Total Reward: -108\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 3718, Total Reward: -100300\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 3719, Total Reward: -100588\n",
      "Episode: 3720, Total Reward: -288\n",
      "Episode: 3721, Total Reward: -164\n",
      "Episode: 3722, Total Reward: -542\n",
      "Episode: 3723, Total Reward: -106\n",
      "Episode: 3724, Total Reward: -134\n",
      "Episode: 3725, Total Reward: -164\n",
      "Episode: 3726, Total Reward: -250\n",
      "Episode: 3727, Total Reward: -106\n",
      "Episode: 3728, Total Reward: -160\n",
      "Episode: 3729, Total Reward: -568\n",
      "Episode: 3730, Total Reward: -308\n",
      "Episode: 3731, Total Reward: -486\n",
      "Episode: 3732, Total Reward: -98\n",
      "Episode: 3733, Total Reward: -192\n",
      "Episode: 3734, Total Reward: -122\n",
      "Episode: 3735, Total Reward: -386\n",
      "Episode: 3736, Total Reward: -314\n",
      "Episode: 3737, Total Reward: -422\n",
      "Episode: 3738, Total Reward: -230\n",
      "Episode: 3739, Total Reward: -46\n",
      "Episode: 3740, Total Reward: -444\n",
      "Episode: 3741, Total Reward: -236\n",
      "Episode: 3742, Total Reward: -384\n",
      "Episode: 3743, Total Reward: -354\n",
      "Episode: 3744, Total Reward: -118\n",
      "Episode: 3745, Total Reward: -146\n",
      "Episode: 3746, Total Reward: -188\n",
      "Episode: 3747, Total Reward: -52\n",
      "Episode: 3748, Total Reward: -384\n",
      "Episode: 3749, Total Reward: -38\n",
      "Episode: 3750, Total Reward: -44\n",
      "Episode: 3751, Total Reward: -234\n",
      "Episode: 3752, Total Reward: -188\n",
      "Episode: 3753, Total Reward: -38\n",
      "Episode: 3754, Total Reward: -36\n",
      "Episode: 3755, Total Reward: -42\n",
      "Episode: 3756, Total Reward: -110\n",
      "Episode: 3757, Total Reward: -134\n",
      "Episode: 3758, Total Reward: -314\n",
      "Episode: 3759, Total Reward: -38\n",
      "Episode: 3760, Total Reward: -610\n",
      "Episode: 3761, Total Reward: -52\n",
      "Episode: 3762, Total Reward: -398\n",
      "Episode: 3763, Total Reward: -128\n",
      "Episode: 3764, Total Reward: -202\n",
      "Episode: 3765, Total Reward: -62\n",
      "Episode: 3766, Total Reward: -382\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 3767, Total Reward: -100298\n",
      "Episode: 3768, Total Reward: -170\n",
      "Episode: 3769, Total Reward: -530\n",
      "Episode: 3770, Total Reward: -260\n",
      "Episode: 3771, Total Reward: -162\n",
      "Episode: 3772, Total Reward: -524\n",
      "Episode: 3773, Total Reward: -256\n",
      "Episode: 3774, Total Reward: -196\n",
      "Episode: 3775, Total Reward: -106\n",
      "Episode: 3776, Total Reward: -136\n",
      "Episode: 3777, Total Reward: -104\n",
      "Episode: 3778, Total Reward: -210\n",
      "Episode: 3779, Total Reward: -300\n",
      "Episode: 3780, Total Reward: -134\n",
      "Episode: 3781, Total Reward: -142\n",
      "Episode: 3782, Total Reward: -264\n",
      "Episode: 3783, Total Reward: -112\n",
      "Episode: 3784, Total Reward: -104\n",
      "Episode: 3785, Total Reward: -446\n",
      "Episode: 3786, Total Reward: -108\n",
      "Episode: 3787, Total Reward: -186\n",
      "Episode: 3788, Total Reward: -72\n",
      "Episode: 3789, Total Reward: -94\n",
      "Episode: 3790, Total Reward: -696\n",
      "Episode: 3791, Total Reward: -310\n",
      "Episode: 3792, Total Reward: -138\n",
      "Episode: 3793, Total Reward: -118\n",
      "Episode: 3794, Total Reward: -216\n",
      "Episode: 3795, Total Reward: -154\n",
      "Episode: 3796, Total Reward: -108\n",
      "Episode: 3797, Total Reward: -116\n",
      "Episode: 3798, Total Reward: -446\n",
      "Episode: 3799, Total Reward: -106\n",
      "Episode: 3800, Total Reward: -254\n",
      "Episode: 3801, Total Reward: -180\n",
      "Episode: 3802, Total Reward: -164\n",
      "Episode: 3803, Total Reward: -258\n",
      "Episode: 3804, Total Reward: -206\n",
      "Episode: 3805, Total Reward: -96\n",
      "Episode: 3806, Total Reward: -244\n",
      "Episode: 3807, Total Reward: -416\n",
      "Episode: 3808, Total Reward: -612\n",
      "Episode: 3809, Total Reward: -324\n",
      "Episode: 3810, Total Reward: -192\n",
      "Episode: 3811, Total Reward: -284\n",
      "Episode: 3812, Total Reward: -252\n",
      "Episode: 3813, Total Reward: -214\n",
      "Episode: 3814, Total Reward: -130\n",
      "Episode: 3815, Total Reward: -72\n",
      "Episode: 3816, Total Reward: -106\n",
      "Episode: 3817, Total Reward: -482\n",
      "Episode: 3818, Total Reward: -220\n",
      "Episode: 3819, Total Reward: -252\n",
      "Episode: 3820, Total Reward: -140\n",
      "Episode: 3821, Total Reward: -100\n",
      "Episode: 3822, Total Reward: -120\n",
      "Episode: 3823, Total Reward: -100\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 3824, Total Reward: -100392\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 3825, Total Reward: -100156\n",
      "Episode: 3826, Total Reward: -118\n",
      "Episode: 3827, Total Reward: -100\n",
      "Episode: 3828, Total Reward: -158\n",
      "Episode: 3829, Total Reward: -108\n",
      "Episode: 3830, Total Reward: -100\n",
      "Episode: 3831, Total Reward: -100\n",
      "Episode: 3832, Total Reward: -210\n",
      "Episode: 3833, Total Reward: -92\n",
      "Episode: 3834, Total Reward: -100\n",
      "Episode: 3835, Total Reward: -128\n",
      "Episode: 3836, Total Reward: -258\n",
      "Episode: 3837, Total Reward: -226\n",
      "Episode: 3838, Total Reward: -122\n",
      "Episode: 3839, Total Reward: -128\n",
      "Episode: 3840, Total Reward: -108\n",
      "Episode: 3841, Total Reward: -108\n",
      "Episode: 3842, Total Reward: -100\n",
      "Episode: 3843, Total Reward: -124\n",
      "Episode: 3844, Total Reward: -166\n",
      "Episode: 3845, Total Reward: -128\n",
      "Episode: 3846, Total Reward: -100\n",
      "Episode: 3847, Total Reward: -222\n",
      "Episode: 3848, Total Reward: -100\n",
      "Invalid Action: Invalid column: 1\n",
      "Episode: 3849, Total Reward: -100454\n",
      "Episode: 3850, Total Reward: -100\n",
      "Episode: 3851, Total Reward: -258\n",
      "Episode: 3852, Total Reward: -116\n",
      "Episode: 3853, Total Reward: -236\n",
      "Episode: 3854, Total Reward: -420\n",
      "Episode: 3855, Total Reward: -132\n",
      "Episode: 3856, Total Reward: -100\n",
      "Episode: 3857, Total Reward: -370\n",
      "Episode: 3858, Total Reward: -184\n",
      "Episode: 3859, Total Reward: -182\n",
      "Episode: 3860, Total Reward: -194\n",
      "Episode: 3861, Total Reward: -162\n",
      "Episode: 3862, Total Reward: -112\n",
      "Episode: 3863, Total Reward: -124\n",
      "Episode: 3864, Total Reward: -38\n",
      "Episode: 3865, Total Reward: -124\n",
      "Episode: 3866, Total Reward: -144\n",
      "Episode: 3867, Total Reward: -290\n",
      "Episode: 3868, Total Reward: -140\n",
      "Episode: 3869, Total Reward: -62\n",
      "Episode: 3870, Total Reward: -352\n",
      "Episode: 3871, Total Reward: -100\n",
      "Episode: 3872, Total Reward: -74\n",
      "Episode: 3873, Total Reward: -410\n",
      "Episode: 3874, Total Reward: -132\n",
      "Episode: 3875, Total Reward: -38\n",
      "Episode: 3876, Total Reward: -46\n",
      "Episode: 3877, Total Reward: -80\n",
      "Episode: 3878, Total Reward: -48\n",
      "Episode: 3879, Total Reward: -60\n",
      "Episode: 3880, Total Reward: -62\n",
      "Episode: 3881, Total Reward: -62\n",
      "Episode: 3882, Total Reward: -172\n",
      "Episode: 3883, Total Reward: -52\n",
      "Episode: 3884, Total Reward: -122\n",
      "Episode: 3885, Total Reward: -120\n",
      "Episode: 3886, Total Reward: -392\n",
      "Episode: 3887, Total Reward: -62\n",
      "Episode: 3888, Total Reward: -146\n",
      "Episode: 3889, Total Reward: -38\n",
      "Episode: 3890, Total Reward: -58\n",
      "Episode: 3891, Total Reward: -36\n",
      "Episode: 3892, Total Reward: -26\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 3893, Total Reward: -100270\n",
      "Episode: 3894, Total Reward: -52\n",
      "Episode: 3895, Total Reward: -144\n",
      "Episode: 3896, Total Reward: -504\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 3897, Total Reward: -99998\n",
      "Episode: 3898, Total Reward: -220\n",
      "Episode: 3899, Total Reward: -442\n",
      "Episode: 3900, Total Reward: -106\n",
      "Episode: 3901, Total Reward: -194\n",
      "Episode: 3902, Total Reward: -180\n",
      "Episode: 3903, Total Reward: -100\n",
      "Episode: 3904, Total Reward: -220\n",
      "Episode: 3905, Total Reward: -44\n",
      "Episode: 3906, Total Reward: -244\n",
      "Episode: 3907, Total Reward: -132\n",
      "Episode: 3908, Total Reward: -242\n",
      "Episode: 3909, Total Reward: -470\n",
      "Episode: 3910, Total Reward: -108\n",
      "Episode: 3911, Total Reward: -100\n",
      "Episode: 3912, Total Reward: -142\n",
      "Episode: 3913, Total Reward: -28\n",
      "Episode: 3914, Total Reward: -92\n",
      "Episode: 3915, Total Reward: -106\n",
      "Episode: 3916, Total Reward: -152\n",
      "Episode: 3917, Total Reward: -44\n",
      "Episode: 3918, Total Reward: -168\n",
      "Episode: 3919, Total Reward: -172\n",
      "Episode: 3920, Total Reward: -78\n",
      "Episode: 3921, Total Reward: -104\n",
      "Episode: 3922, Total Reward: -152\n",
      "Episode: 3923, Total Reward: -84\n",
      "Episode: 3924, Total Reward: -64\n",
      "Episode: 3925, Total Reward: -92\n",
      "Episode: 3926, Total Reward: -74\n",
      "Episode: 3927, Total Reward: -262\n",
      "Episode: 3928, Total Reward: -284\n",
      "Episode: 3929, Total Reward: -140\n",
      "Episode: 3930, Total Reward: -142\n",
      "Episode: 3931, Total Reward: -330\n",
      "Episode: 3932, Total Reward: -726\n",
      "Episode: 3933, Total Reward: -108\n",
      "Episode: 3934, Total Reward: -302\n",
      "Episode: 3935, Total Reward: -144\n",
      "Episode: 3936, Total Reward: -424\n",
      "Episode: 3937, Total Reward: -284\n",
      "Episode: 3938, Total Reward: -454\n",
      "Episode: 3939, Total Reward: -106\n",
      "Episode: 3940, Total Reward: -106\n",
      "Episode: 3941, Total Reward: -86\n",
      "Episode: 3942, Total Reward: -86\n",
      "Episode: 3943, Total Reward: -100\n",
      "Episode: 3944, Total Reward: -104\n",
      "Episode: 3945, Total Reward: -82\n",
      "Episode: 3946, Total Reward: -112\n",
      "Episode: 3947, Total Reward: -138\n",
      "Episode: 3948, Total Reward: -26\n",
      "Episode: 3949, Total Reward: -36\n",
      "Episode: 3950, Total Reward: -34\n",
      "Episode: 3951, Total Reward: -36\n",
      "Episode: 3952, Total Reward: -26\n",
      "Episode: 3953, Total Reward: 2\n",
      "Episode: 3954, Total Reward: -76\n",
      "Episode: 3955, Total Reward: -26\n",
      "Episode: 3956, Total Reward: -212\n",
      "Episode: 3957, Total Reward: -66\n",
      "Episode: 3958, Total Reward: -394\n",
      "Episode: 3959, Total Reward: -106\n",
      "Episode: 3960, Total Reward: -144\n",
      "Episode: 3961, Total Reward: -114\n",
      "Episode: 3962, Total Reward: -230\n",
      "Episode: 3963, Total Reward: -36\n",
      "Episode: 3964, Total Reward: -66\n",
      "Episode: 3965, Total Reward: -68\n",
      "Episode: 3966, Total Reward: -470\n",
      "Episode: 3967, Total Reward: -90\n",
      "Episode: 3968, Total Reward: -66\n",
      "Episode: 3969, Total Reward: -66\n",
      "Episode: 3970, Total Reward: -224\n",
      "Episode: 3971, Total Reward: -182\n",
      "Episode: 3972, Total Reward: -58\n",
      "Episode: 3973, Total Reward: -26\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 3974, Total Reward: -100018\n",
      "Episode: 3975, Total Reward: -38\n",
      "Episode: 3976, Total Reward: -26\n",
      "Episode: 3977, Total Reward: -26\n",
      "Episode: 3978, Total Reward: -116\n",
      "Episode: 3979, Total Reward: -38\n",
      "Episode: 3980, Total Reward: -44\n",
      "Episode: 3981, Total Reward: -64\n",
      "Episode: 3982, Total Reward: -44\n",
      "Episode: 3983, Total Reward: -42\n",
      "Episode: 3984, Total Reward: -38\n",
      "Episode: 3985, Total Reward: -36\n",
      "Episode: 3986, Total Reward: 2\n",
      "Episode: 3987, Total Reward: -26\n",
      "Episode: 3988, Total Reward: -58\n",
      "Episode: 3989, Total Reward: -38\n",
      "Episode: 3990, Total Reward: -644\n",
      "Episode: 3991, Total Reward: -90\n",
      "Episode: 3992, Total Reward: -88\n",
      "Episode: 3993, Total Reward: -112\n",
      "Episode: 3994, Total Reward: -42\n",
      "Episode: 3995, Total Reward: -362\n",
      "Episode: 3996, Total Reward: -198\n",
      "Episode: 3997, Total Reward: -106\n",
      "Episode: 3998, Total Reward: -106\n",
      "Episode: 3999, Total Reward: -186\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4000, Total Reward: -100312\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 4001, Total Reward: -100326\n",
      "Episode: 4002, Total Reward: -90\n",
      "Episode: 4003, Total Reward: -132\n",
      "Episode: 4004, Total Reward: -210\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4005, Total Reward: -100346\n",
      "Episode: 4006, Total Reward: -52\n",
      "Episode: 4007, Total Reward: -64\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 4008, Total Reward: -100254\n",
      "Episode: 4009, Total Reward: -38\n",
      "Episode: 4010, Total Reward: -112\n",
      "Episode: 4011, Total Reward: -36\n",
      "Episode: 4012, Total Reward: -88\n",
      "Episode: 4013, Total Reward: -422\n",
      "Episode: 4014, Total Reward: -76\n",
      "Episode: 4015, Total Reward: -122\n",
      "Episode: 4016, Total Reward: -84\n",
      "Episode: 4017, Total Reward: -266\n",
      "Episode: 4018, Total Reward: -114\n",
      "Episode: 4019, Total Reward: -108\n",
      "Episode: 4020, Total Reward: -494\n",
      "Episode: 4021, Total Reward: -112\n",
      "Episode: 4022, Total Reward: -224\n",
      "Episode: 4023, Total Reward: -184\n",
      "Episode: 4024, Total Reward: -206\n",
      "Episode: 4025, Total Reward: -36\n",
      "Episode: 4026, Total Reward: -332\n",
      "Episode: 4027, Total Reward: -38\n",
      "Episode: 4028, Total Reward: -168\n",
      "Episode: 4029, Total Reward: -74\n",
      "Episode: 4030, Total Reward: -44\n",
      "Episode: 4031, Total Reward: 99346\n",
      "Episode: 4032, Total Reward: -140\n",
      "Episode: 4033, Total Reward: 99842\n",
      "Episode: 4034, Total Reward: -82\n",
      "Episode: 4035, Total Reward: -126\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 4036, Total Reward: -100224\n",
      "Episode: 4037, Total Reward: 0\n",
      "Episode: 4038, Total Reward: -140\n",
      "Episode: 4039, Total Reward: -586\n",
      "Episode: 4040, Total Reward: -238\n",
      "Episode: 4041, Total Reward: -380\n",
      "Episode: 4042, Total Reward: -240\n",
      "Episode: 4043, Total Reward: -160\n",
      "Episode: 4044, Total Reward: -114\n",
      "Episode: 4045, Total Reward: -308\n",
      "Episode: 4046, Total Reward: -224\n",
      "Episode: 4047, Total Reward: -356\n",
      "Episode: 4048, Total Reward: -272\n",
      "Episode: 4049, Total Reward: -274\n",
      "Episode: 4050, Total Reward: -300\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4051, Total Reward: -100518\n",
      "Episode: 4052, Total Reward: -788\n",
      "Episode: 4053, Total Reward: -106\n",
      "Episode: 4054, Total Reward: -112\n",
      "Episode: 4055, Total Reward: -106\n",
      "Episode: 4056, Total Reward: -246\n",
      "Episode: 4057, Total Reward: -292\n",
      "Episode: 4058, Total Reward: -106\n",
      "Episode: 4059, Total Reward: -112\n",
      "Episode: 4060, Total Reward: -152\n",
      "Episode: 4061, Total Reward: -492\n",
      "Episode: 4062, Total Reward: -162\n",
      "Episode: 4063, Total Reward: -444\n",
      "Episode: 4064, Total Reward: -216\n",
      "Episode: 4065, Total Reward: -140\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4066, Total Reward: -100166\n",
      "Episode: 4067, Total Reward: -144\n",
      "Episode: 4068, Total Reward: -698\n",
      "Episode: 4069, Total Reward: -378\n",
      "Episode: 4070, Total Reward: -104\n",
      "Episode: 4071, Total Reward: -116\n",
      "Episode: 4072, Total Reward: -88\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 4073, Total Reward: -100092\n",
      "Episode: 4074, Total Reward: -264\n",
      "Episode: 4075, Total Reward: -298\n",
      "Episode: 4076, Total Reward: -140\n",
      "Episode: 4077, Total Reward: -184\n",
      "Episode: 4078, Total Reward: -628\n",
      "Episode: 4079, Total Reward: -290\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4080, Total Reward: -100772\n",
      "Episode: 4081, Total Reward: -476\n",
      "Episode: 4082, Total Reward: -600\n",
      "Episode: 4083, Total Reward: -172\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4084, Total Reward: -100366\n",
      "Episode: 4085, Total Reward: -196\n",
      "Episode: 4086, Total Reward: -232\n",
      "Episode: 4087, Total Reward: -394\n",
      "Episode: 4088, Total Reward: -150\n",
      "Episode: 4089, Total Reward: -144\n",
      "Episode: 4090, Total Reward: -142\n",
      "Episode: 4091, Total Reward: -414\n",
      "Episode: 4092, Total Reward: -108\n",
      "Episode: 4093, Total Reward: -288\n",
      "Episode: 4094, Total Reward: -38\n",
      "Episode: 4095, Total Reward: -36\n",
      "Episode: 4096, Total Reward: -132\n",
      "Episode: 4097, Total Reward: -36\n",
      "Episode: 4098, Total Reward: -204\n",
      "Episode: 4099, Total Reward: -766\n",
      "Episode: 4100, Total Reward: -302\n",
      "Episode: 4101, Total Reward: -114\n",
      "Episode: 4102, Total Reward: -478\n",
      "Episode: 4103, Total Reward: -26\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 4104, Total Reward: -100302\n",
      "Episode: 4105, Total Reward: -108\n",
      "Episode: 4106, Total Reward: -130\n",
      "Episode: 4107, Total Reward: -140\n",
      "Episode: 4108, Total Reward: -142\n",
      "Episode: 4109, Total Reward: 99768\n",
      "Episode: 4110, Total Reward: 100066\n",
      "Episode: 4111, Total Reward: 4\n",
      "Episode: 4112, Total Reward: -418\n",
      "Episode: 4113, Total Reward: -560\n",
      "Episode: 4114, Total Reward: -92\n",
      "Episode: 4115, Total Reward: -38\n",
      "Episode: 4116, Total Reward: -56\n",
      "Episode: 4117, Total Reward: -42\n",
      "Episode: 4118, Total Reward: 99962\n",
      "Episode: 4119, Total Reward: -200\n",
      "Episode: 4120, Total Reward: -42\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4121, Total Reward: -100572\n",
      "Episode: 4122, Total Reward: -112\n",
      "Episode: 4123, Total Reward: -48\n",
      "Episode: 4124, Total Reward: -172\n",
      "Episode: 4125, Total Reward: -38\n",
      "Episode: 4126, Total Reward: -94\n",
      "Episode: 4127, Total Reward: -332\n",
      "Episode: 4128, Total Reward: -438\n",
      "Episode: 4129, Total Reward: -438\n",
      "Episode: 4130, Total Reward: -110\n",
      "Episode: 4131, Total Reward: -42\n",
      "Episode: 4132, Total Reward: -74\n",
      "Episode: 4133, Total Reward: -96\n",
      "Episode: 4134, Total Reward: -112\n",
      "Invalid Action: Invalid column: 4\n",
      "Episode: 4135, Total Reward: -100160\n",
      "Episode: 4136, Total Reward: -36\n",
      "Episode: 4137, Total Reward: -444\n",
      "Episode: 4138, Total Reward: -142\n",
      "Episode: 4139, Total Reward: -150\n",
      "Episode: 4140, Total Reward: -290\n",
      "Episode: 4141, Total Reward: -36\n",
      "Episode: 4142, Total Reward: -122\n",
      "Episode: 4143, Total Reward: -250\n",
      "Episode: 4144, Total Reward: -188\n",
      "Episode: 4145, Total Reward: -38\n",
      "Episode: 4146, Total Reward: -74\n",
      "Episode: 4147, Total Reward: -166\n",
      "Episode: 4148, Total Reward: -84\n",
      "Episode: 4149, Total Reward: -22\n",
      "Episode: 4150, Total Reward: -166\n",
      "Episode: 4151, Total Reward: -74\n",
      "Episode: 4152, Total Reward: -82\n",
      "Episode: 4153, Total Reward: -400\n",
      "Episode: 4154, Total Reward: -226\n",
      "Episode: 4155, Total Reward: -22\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4156, Total Reward: -99932\n",
      "Episode: 4157, Total Reward: -722\n",
      "Episode: 4158, Total Reward: 100118\n",
      "Episode: 4159, Total Reward: -42\n",
      "Episode: 4160, Total Reward: -866\n",
      "Episode: 4161, Total Reward: -164\n",
      "Episode: 4162, Total Reward: -48\n",
      "Episode: 4163, Total Reward: -36\n",
      "Episode: 4164, Total Reward: -94\n",
      "Episode: 4165, Total Reward: -128\n",
      "Episode: 4166, Total Reward: -542\n",
      "Episode: 4167, Total Reward: 99946\n",
      "Episode: 4168, Total Reward: -80\n",
      "Episode: 4169, Total Reward: -20\n",
      "Episode: 4170, Total Reward: -40\n",
      "Episode: 4171, Total Reward: -252\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4172, Total Reward: -100656\n",
      "Episode: 4173, Total Reward: -74\n",
      "Episode: 4174, Total Reward: -142\n",
      "Episode: 4175, Total Reward: -142\n",
      "Episode: 4176, Total Reward: -134\n",
      "Episode: 4177, Total Reward: -260\n",
      "Episode: 4178, Total Reward: -146\n",
      "Episode: 4179, Total Reward: -130\n",
      "Episode: 4180, Total Reward: -332\n",
      "Episode: 4181, Total Reward: -128\n",
      "Episode: 4182, Total Reward: -142\n",
      "Episode: 4183, Total Reward: -366\n",
      "Episode: 4184, Total Reward: -412\n",
      "Episode: 4185, Total Reward: -548\n",
      "Episode: 4186, Total Reward: -274\n",
      "Episode: 4187, Total Reward: -166\n",
      "Episode: 4188, Total Reward: 99982\n",
      "Episode: 4189, Total Reward: 100020\n",
      "Episode: 4190, Total Reward: -240\n",
      "Episode: 4191, Total Reward: -374\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4192, Total Reward: -100140\n",
      "Episode: 4193, Total Reward: -42\n",
      "Episode: 4194, Total Reward: -118\n",
      "Episode: 4195, Total Reward: 14\n",
      "Episode: 4196, Total Reward: -288\n",
      "Episode: 4197, Total Reward: -42\n",
      "Episode: 4198, Total Reward: 99872\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4199, Total Reward: -100522\n",
      "Episode: 4200, Total Reward: -188\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4201, Total Reward: -100112\n",
      "Episode: 4202, Total Reward: -440\n",
      "Episode: 4203, Total Reward: -138\n",
      "Episode: 4204, Total Reward: -260\n",
      "Episode: 4205, Total Reward: 82\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4206, Total Reward: -99962\n",
      "Episode: 4207, Total Reward: -12\n",
      "Episode: 4208, Total Reward: -26\n",
      "Episode: 4209, Total Reward: -38\n",
      "Episode: 4210, Total Reward: -38\n",
      "Episode: 4211, Total Reward: -210\n",
      "Episode: 4212, Total Reward: 106\n",
      "Episode: 4213, Total Reward: -84\n",
      "Episode: 4214, Total Reward: -624\n",
      "Episode: 4215, Total Reward: -194\n",
      "Episode: 4216, Total Reward: -644\n",
      "Episode: 4217, Total Reward: -66\n",
      "Episode: 4218, Total Reward: -46\n",
      "Episode: 4219, Total Reward: -46\n",
      "Episode: 4220, Total Reward: -194\n",
      "Episode: 4221, Total Reward: -120\n",
      "Episode: 4222, Total Reward: -212\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4223, Total Reward: -100520\n",
      "Episode: 4224, Total Reward: -204\n",
      "Episode: 4225, Total Reward: -98\n",
      "Episode: 4226, Total Reward: -72\n",
      "Episode: 4227, Total Reward: -116\n",
      "Episode: 4228, Total Reward: -92\n",
      "Episode: 4229, Total Reward: -100\n",
      "Episode: 4230, Total Reward: -74\n",
      "Episode: 4231, Total Reward: -64\n",
      "Episode: 4232, Total Reward: -100\n",
      "Episode: 4233, Total Reward: -66\n",
      "Episode: 4234, Total Reward: -472\n",
      "Episode: 4235, Total Reward: -142\n",
      "Episode: 4236, Total Reward: -144\n",
      "Episode: 4237, Total Reward: -60\n",
      "Episode: 4238, Total Reward: -100\n",
      "Episode: 4239, Total Reward: -46\n",
      "Episode: 4240, Total Reward: -64\n",
      "Episode: 4241, Total Reward: -74\n",
      "Episode: 4242, Total Reward: -66\n",
      "Episode: 4243, Total Reward: -112\n",
      "Episode: 4244, Total Reward: -76\n",
      "Episode: 4245, Total Reward: -130\n",
      "Episode: 4246, Total Reward: -646\n",
      "Episode: 4247, Total Reward: -44\n",
      "Episode: 4248, Total Reward: -100\n",
      "Episode: 4249, Total Reward: -604\n",
      "Episode: 4250, Total Reward: -270\n",
      "Episode: 4251, Total Reward: -60\n",
      "Episode: 4252, Total Reward: -144\n",
      "Episode: 4253, Total Reward: -100\n",
      "Episode: 4254, Total Reward: -112\n",
      "Episode: 4255, Total Reward: -64\n",
      "Episode: 4256, Total Reward: -112\n",
      "Episode: 4257, Total Reward: -138\n",
      "Episode: 4258, Total Reward: -108\n",
      "Episode: 4259, Total Reward: -662\n",
      "Episode: 4260, Total Reward: -44\n",
      "Episode: 4261, Total Reward: -206\n",
      "Episode: 4262, Total Reward: -132\n",
      "Episode: 4263, Total Reward: -114\n",
      "Episode: 4264, Total Reward: -76\n",
      "Episode: 4265, Total Reward: -92\n",
      "Episode: 4266, Total Reward: -510\n",
      "Episode: 4267, Total Reward: -112\n",
      "Episode: 4268, Total Reward: -72\n",
      "Episode: 4269, Total Reward: -72\n",
      "Episode: 4270, Total Reward: -210\n",
      "Episode: 4271, Total Reward: -100\n",
      "Episode: 4272, Total Reward: -118\n",
      "Episode: 4273, Total Reward: -114\n",
      "Episode: 4274, Total Reward: -398\n",
      "Episode: 4275, Total Reward: -578\n",
      "Episode: 4276, Total Reward: -60\n",
      "Episode: 4277, Total Reward: -122\n",
      "Episode: 4278, Total Reward: -72\n",
      "Episode: 4279, Total Reward: -238\n",
      "Episode: 4280, Total Reward: -70\n",
      "Episode: 4281, Total Reward: -222\n",
      "Episode: 4282, Total Reward: -762\n",
      "Episode: 4283, Total Reward: -172\n",
      "Episode: 4284, Total Reward: -278\n",
      "Episode: 4285, Total Reward: -44\n",
      "Episode: 4286, Total Reward: -184\n",
      "Episode: 4287, Total Reward: -218\n",
      "Episode: 4288, Total Reward: -182\n",
      "Episode: 4289, Total Reward: -72\n",
      "Episode: 4290, Total Reward: -72\n",
      "Episode: 4291, Total Reward: -220\n",
      "Episode: 4292, Total Reward: -436\n",
      "Episode: 4293, Total Reward: -474\n",
      "Episode: 4294, Total Reward: -72\n",
      "Episode: 4295, Total Reward: -176\n",
      "Episode: 4296, Total Reward: -234\n",
      "Episode: 4297, Total Reward: -120\n",
      "Episode: 4298, Total Reward: -138\n",
      "Episode: 4299, Total Reward: -434\n",
      "Episode: 4300, Total Reward: -106\n",
      "Episode: 4301, Total Reward: -84\n",
      "Episode: 4302, Total Reward: -130\n",
      "Episode: 4303, Total Reward: -64\n",
      "Episode: 4304, Total Reward: -528\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4305, Total Reward: -100518\n",
      "Episode: 4306, Total Reward: -440\n",
      "Episode: 4307, Total Reward: -92\n",
      "Episode: 4308, Total Reward: -100\n",
      "Episode: 4309, Total Reward: -46\n",
      "Episode: 4310, Total Reward: -202\n",
      "Episode: 4311, Total Reward: -124\n",
      "Episode: 4312, Total Reward: -44\n",
      "Episode: 4313, Total Reward: -124\n",
      "Episode: 4314, Total Reward: -64\n",
      "Episode: 4315, Total Reward: -398\n",
      "Episode: 4316, Total Reward: -64\n",
      "Episode: 4317, Total Reward: -112\n",
      "Episode: 4318, Total Reward: -60\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4319, Total Reward: -100450\n",
      "Episode: 4320, Total Reward: -102\n",
      "Episode: 4321, Total Reward: -456\n",
      "Episode: 4322, Total Reward: -60\n",
      "Episode: 4323, Total Reward: -600\n",
      "Episode: 4324, Total Reward: -72\n",
      "Episode: 4325, Total Reward: -466\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4326, Total Reward: -100464\n",
      "Episode: 4327, Total Reward: -44\n",
      "Episode: 4328, Total Reward: -76\n",
      "Episode: 4329, Total Reward: -132\n",
      "Episode: 4330, Total Reward: -80\n",
      "Episode: 4331, Total Reward: -92\n",
      "Episode: 4332, Total Reward: -72\n",
      "Episode: 4333, Total Reward: -100\n",
      "Episode: 4334, Total Reward: -170\n",
      "Episode: 4335, Total Reward: -48\n",
      "Episode: 4336, Total Reward: -100\n",
      "Episode: 4337, Total Reward: -310\n",
      "Episode: 4338, Total Reward: -468\n",
      "Episode: 4339, Total Reward: -100\n",
      "Episode: 4340, Total Reward: -150\n",
      "Episode: 4341, Total Reward: -218\n",
      "Episode: 4342, Total Reward: -102\n",
      "Episode: 4343, Total Reward: -162\n",
      "Episode: 4344, Total Reward: -42\n",
      "Episode: 4345, Total Reward: -726\n",
      "Episode: 4346, Total Reward: 100030\n",
      "Episode: 4347, Total Reward: -70\n",
      "Episode: 4348, Total Reward: -76\n",
      "Episode: 4349, Total Reward: -112\n",
      "Episode: 4350, Total Reward: -108\n",
      "Episode: 4351, Total Reward: -98\n",
      "Episode: 4352, Total Reward: -64\n",
      "Episode: 4353, Total Reward: -100\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4354, Total Reward: -99960\n",
      "Episode: 4355, Total Reward: -256\n",
      "Episode: 4356, Total Reward: -106\n",
      "Episode: 4357, Total Reward: -60\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4358, Total Reward: -100694\n",
      "Episode: 4359, Total Reward: -66\n",
      "Episode: 4360, Total Reward: -132\n",
      "Episode: 4361, Total Reward: -54\n",
      "Episode: 4362, Total Reward: -130\n",
      "Episode: 4363, Total Reward: -100\n",
      "Episode: 4364, Total Reward: -208\n",
      "Episode: 4365, Total Reward: -110\n",
      "Episode: 4366, Total Reward: -74\n",
      "Episode: 4367, Total Reward: -64\n",
      "Episode: 4368, Total Reward: -410\n",
      "Episode: 4369, Total Reward: 99370\n",
      "Episode: 4370, Total Reward: -184\n",
      "Episode: 4371, Total Reward: -206\n",
      "Episode: 4372, Total Reward: -84\n",
      "Episode: 4373, Total Reward: -44\n",
      "Episode: 4374, Total Reward: -44\n",
      "Episode: 4375, Total Reward: -348\n",
      "Episode: 4376, Total Reward: -92\n",
      "Episode: 4377, Total Reward: -94\n",
      "Episode: 4378, Total Reward: -260\n",
      "Episode: 4379, Total Reward: -82\n",
      "Episode: 4380, Total Reward: -72\n",
      "Episode: 4381, Total Reward: -60\n",
      "Episode: 4382, Total Reward: -60\n",
      "Episode: 4383, Total Reward: -130\n",
      "Episode: 4384, Total Reward: -432\n",
      "Episode: 4385, Total Reward: -72\n",
      "Episode: 4386, Total Reward: -116\n",
      "Episode: 4387, Total Reward: -92\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4388, Total Reward: -100988\n",
      "Episode: 4389, Total Reward: -82\n",
      "Episode: 4390, Total Reward: -46\n",
      "Episode: 4391, Total Reward: -414\n",
      "Episode: 4392, Total Reward: -100\n",
      "Episode: 4393, Total Reward: -70\n",
      "Episode: 4394, Total Reward: -278\n",
      "Episode: 4395, Total Reward: -100\n",
      "Episode: 4396, Total Reward: -98\n",
      "Episode: 4397, Total Reward: -92\n",
      "Episode: 4398, Total Reward: -80\n",
      "Episode: 4399, Total Reward: -274\n",
      "Episode: 4400, Total Reward: -342\n",
      "Episode: 4401, Total Reward: -72\n",
      "Episode: 4402, Total Reward: -84\n",
      "Episode: 4403, Total Reward: -114\n",
      "Episode: 4404, Total Reward: -226\n",
      "Episode: 4405, Total Reward: -60\n",
      "Episode: 4406, Total Reward: -106\n",
      "Episode: 4407, Total Reward: -72\n",
      "Episode: 4408, Total Reward: -96\n",
      "Episode: 4409, Total Reward: -110\n",
      "Episode: 4410, Total Reward: -90\n",
      "Episode: 4411, Total Reward: -146\n",
      "Episode: 4412, Total Reward: -192\n",
      "Episode: 4413, Total Reward: -124\n",
      "Episode: 4414, Total Reward: 99906\n",
      "Episode: 4415, Total Reward: -90\n",
      "Episode: 4416, Total Reward: -186\n",
      "Episode: 4417, Total Reward: -70\n",
      "Episode: 4418, Total Reward: -292\n",
      "Episode: 4419, Total Reward: -480\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4420, Total Reward: -100262\n",
      "Episode: 4421, Total Reward: -182\n",
      "Episode: 4422, Total Reward: -76\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4423, Total Reward: -100082\n",
      "Episode: 4424, Total Reward: -100\n",
      "Episode: 4425, Total Reward: -124\n",
      "Episode: 4426, Total Reward: -90\n",
      "Episode: 4427, Total Reward: -50\n",
      "Episode: 4428, Total Reward: -22\n",
      "Episode: 4429, Total Reward: -202\n",
      "Episode: 4430, Total Reward: -212\n",
      "Episode: 4431, Total Reward: -706\n",
      "Episode: 4432, Total Reward: -60\n",
      "Episode: 4433, Total Reward: -44\n",
      "Episode: 4434, Total Reward: -444\n",
      "Episode: 4435, Total Reward: -184\n",
      "Episode: 4436, Total Reward: -56\n",
      "Episode: 4437, Total Reward: -556\n",
      "Episode: 4438, Total Reward: -48\n",
      "Episode: 4439, Total Reward: -320\n",
      "Episode: 4440, Total Reward: -354\n",
      "Episode: 4441, Total Reward: -158\n",
      "Episode: 4442, Total Reward: 99848\n",
      "Episode: 4443, Total Reward: 99814\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4444, Total Reward: -99988\n",
      "Episode: 4445, Total Reward: -174\n",
      "Episode: 4446, Total Reward: -60\n",
      "Episode: 4447, Total Reward: -488\n",
      "Episode: 4448, Total Reward: -52\n",
      "Episode: 4449, Total Reward: -320\n",
      "Episode: 4450, Total Reward: 99816\n",
      "Episode: 4451, Total Reward: -100\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4452, Total Reward: -100126\n",
      "Episode: 4453, Total Reward: -52\n",
      "Episode: 4454, Total Reward: -60\n",
      "Episode: 4455, Total Reward: -62\n",
      "Episode: 4456, Total Reward: -354\n",
      "Episode: 4457, Total Reward: -290\n",
      "Episode: 4458, Total Reward: -152\n",
      "Episode: 4459, Total Reward: -64\n",
      "Episode: 4460, Total Reward: -240\n",
      "Episode: 4461, Total Reward: -86\n",
      "Episode: 4462, Total Reward: -72\n",
      "Episode: 4463, Total Reward: -90\n",
      "Episode: 4464, Total Reward: -98\n",
      "Episode: 4465, Total Reward: -66\n",
      "Episode: 4466, Total Reward: -60\n",
      "Episode: 4467, Total Reward: -64\n",
      "Episode: 4468, Total Reward: -66\n",
      "Episode: 4469, Total Reward: -60\n",
      "Episode: 4470, Total Reward: -60\n",
      "Episode: 4471, Total Reward: -228\n",
      "Episode: 4472, Total Reward: -342\n",
      "Episode: 4473, Total Reward: -66\n",
      "Episode: 4474, Total Reward: -156\n",
      "Episode: 4475, Total Reward: -32\n",
      "Episode: 4476, Total Reward: -44\n",
      "Episode: 4477, Total Reward: 100124\n",
      "Episode: 4478, Total Reward: -102\n",
      "Episode: 4479, Total Reward: -18\n",
      "Episode: 4480, Total Reward: -232\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4481, Total Reward: -100096\n",
      "Episode: 4482, Total Reward: 99824\n",
      "Episode: 4483, Total Reward: -104\n",
      "Episode: 4484, Total Reward: -214\n",
      "Episode: 4485, Total Reward: -158\n",
      "Episode: 4486, Total Reward: -300\n",
      "Episode: 4487, Total Reward: -66\n",
      "Episode: 4488, Total Reward: -80\n",
      "Episode: 4489, Total Reward: -160\n",
      "Episode: 4490, Total Reward: -76\n",
      "Episode: 4491, Total Reward: -302\n",
      "Episode: 4492, Total Reward: -278\n",
      "Episode: 4493, Total Reward: -188\n",
      "Episode: 4494, Total Reward: -48\n",
      "Episode: 4495, Total Reward: -30\n",
      "Episode: 4496, Total Reward: -156\n",
      "Episode: 4497, Total Reward: 100146\n",
      "Episode: 4498, Total Reward: 99372\n",
      "Episode: 4499, Total Reward: -460\n",
      "Episode: 4500, Total Reward: -314\n",
      "Episode: 4501, Total Reward: -210\n",
      "Episode: 4502, Total Reward: -518\n",
      "Episode: 4503, Total Reward: -308\n",
      "Episode: 4504, Total Reward: -278\n",
      "Episode: 4505, Total Reward: -192\n",
      "Episode: 4506, Total Reward: -188\n",
      "Episode: 4507, Total Reward: -328\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4508, Total Reward: -100270\n",
      "Episode: 4509, Total Reward: -320\n",
      "Episode: 4510, Total Reward: -170\n",
      "Episode: 4511, Total Reward: -46\n",
      "Episode: 4512, Total Reward: 100064\n",
      "Episode: 4513, Total Reward: -154\n",
      "Episode: 4514, Total Reward: -418\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4515, Total Reward: -99842\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4516, Total Reward: -100234\n",
      "Episode: 4517, Total Reward: -42\n",
      "Episode: 4518, Total Reward: -126\n",
      "Episode: 4519, Total Reward: -296\n",
      "Episode: 4520, Total Reward: -248\n",
      "Episode: 4521, Total Reward: -550\n",
      "Episode: 4522, Total Reward: -178\n",
      "Episode: 4523, Total Reward: -56\n",
      "Episode: 4524, Total Reward: -796\n",
      "Episode: 4525, Total Reward: -142\n",
      "Episode: 4526, Total Reward: -54\n",
      "Episode: 4527, Total Reward: -246\n",
      "Episode: 4528, Total Reward: -300\n",
      "Episode: 4529, Total Reward: -44\n",
      "Episode: 4530, Total Reward: -364\n",
      "Episode: 4531, Total Reward: -498\n",
      "Episode: 4532, Total Reward: -112\n",
      "Episode: 4533, Total Reward: -56\n",
      "Episode: 4534, Total Reward: -56\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4535, Total Reward: -100234\n",
      "Episode: 4536, Total Reward: 99852\n",
      "Episode: 4537, Total Reward: -382\n",
      "Episode: 4538, Total Reward: -44\n",
      "Episode: 4539, Total Reward: -162\n",
      "Episode: 4540, Total Reward: -134\n",
      "Episode: 4541, Total Reward: -280\n",
      "Episode: 4542, Total Reward: -272\n",
      "Episode: 4543, Total Reward: -250\n",
      "Episode: 4544, Total Reward: -248\n",
      "Episode: 4545, Total Reward: -314\n",
      "Episode: 4546, Total Reward: -704\n",
      "Episode: 4547, Total Reward: -38\n",
      "Episode: 4548, Total Reward: -56\n",
      "Episode: 4549, Total Reward: -128\n",
      "Episode: 4550, Total Reward: -386\n",
      "Episode: 4551, Total Reward: -540\n",
      "Episode: 4552, Total Reward: -140\n",
      "Episode: 4553, Total Reward: -238\n",
      "Episode: 4554, Total Reward: -320\n",
      "Episode: 4555, Total Reward: -110\n",
      "Episode: 4556, Total Reward: -238\n",
      "Episode: 4557, Total Reward: -306\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4558, Total Reward: -100284\n",
      "Episode: 4559, Total Reward: -174\n",
      "Episode: 4560, Total Reward: -86\n",
      "Episode: 4561, Total Reward: -190\n",
      "Episode: 4562, Total Reward: -164\n",
      "Episode: 4563, Total Reward: 99948\n",
      "Episode: 4564, Total Reward: 99824\n",
      "Episode: 4565, Total Reward: -110\n",
      "Episode: 4566, Total Reward: 8\n",
      "Episode: 4567, Total Reward: -342\n",
      "Episode: 4568, Total Reward: 100098\n",
      "Episode: 4569, Total Reward: -676\n",
      "Episode: 4570, Total Reward: 99758\n",
      "Episode: 4571, Total Reward: -192\n",
      "Episode: 4572, Total Reward: -170\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4573, Total Reward: -99868\n",
      "Episode: 4574, Total Reward: -338\n",
      "Episode: 4575, Total Reward: -16\n",
      "Episode: 4576, Total Reward: -276\n",
      "Episode: 4577, Total Reward: 99906\n",
      "Episode: 4578, Total Reward: 99840\n",
      "Episode: 4579, Total Reward: 100018\n",
      "Episode: 4580, Total Reward: 99882\n",
      "Episode: 4581, Total Reward: -56\n",
      "Episode: 4582, Total Reward: -544\n",
      "Episode: 4583, Total Reward: -20\n",
      "Episode: 4584, Total Reward: -320\n",
      "Episode: 4585, Total Reward: -56\n",
      "Episode: 4586, Total Reward: -118\n",
      "Episode: 4587, Total Reward: -18\n",
      "Episode: 4588, Total Reward: -128\n",
      "Episode: 4589, Total Reward: -64\n",
      "Episode: 4590, Total Reward: -52\n",
      "Episode: 4591, Total Reward: 10\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4592, Total Reward: -100358\n",
      "Episode: 4593, Total Reward: -30\n",
      "Episode: 4594, Total Reward: -270\n",
      "Episode: 4595, Total Reward: -252\n",
      "Episode: 4596, Total Reward: -42\n",
      "Episode: 4597, Total Reward: -102\n",
      "Episode: 4598, Total Reward: -242\n",
      "Episode: 4599, Total Reward: -150\n",
      "Episode: 4600, Total Reward: -78\n",
      "Episode: 4601, Total Reward: -80\n",
      "Episode: 4602, Total Reward: -108\n",
      "Episode: 4603, Total Reward: -436\n",
      "Episode: 4604, Total Reward: -140\n",
      "Episode: 4605, Total Reward: -138\n",
      "Episode: 4606, Total Reward: -90\n",
      "Episode: 4607, Total Reward: 99814\n",
      "Episode: 4608, Total Reward: -68\n",
      "Episode: 4609, Total Reward: -90\n",
      "Episode: 4610, Total Reward: -332\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4611, Total Reward: -100142\n",
      "Episode: 4612, Total Reward: -68\n",
      "Episode: 4613, Total Reward: 99704\n",
      "Episode: 4614, Total Reward: -90\n",
      "Episode: 4615, Total Reward: -310\n",
      "Episode: 4616, Total Reward: -68\n",
      "Episode: 4617, Total Reward: -150\n",
      "Episode: 4618, Total Reward: -360\n",
      "Episode: 4619, Total Reward: -252\n",
      "Episode: 4620, Total Reward: -550\n",
      "Episode: 4621, Total Reward: -502\n",
      "Episode: 4622, Total Reward: -340\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4623, Total Reward: -100330\n",
      "Episode: 4624, Total Reward: -90\n",
      "Episode: 4625, Total Reward: -52\n",
      "Episode: 4626, Total Reward: -90\n",
      "Episode: 4627, Total Reward: -90\n",
      "Episode: 4628, Total Reward: -70\n",
      "Episode: 4629, Total Reward: -28\n",
      "Episode: 4630, Total Reward: -134\n",
      "Episode: 4631, Total Reward: 100172\n",
      "Episode: 4632, Total Reward: -126\n",
      "Episode: 4633, Total Reward: -196\n",
      "Episode: 4634, Total Reward: -108\n",
      "Episode: 4635, Total Reward: -76\n",
      "Episode: 4636, Total Reward: -306\n",
      "Episode: 4637, Total Reward: -46\n",
      "Episode: 4638, Total Reward: -126\n",
      "Episode: 4639, Total Reward: 99848\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4640, Total Reward: -100192\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4641, Total Reward: -100148\n",
      "Episode: 4642, Total Reward: -70\n",
      "Episode: 4643, Total Reward: -56\n",
      "Episode: 4644, Total Reward: -106\n",
      "Episode: 4645, Total Reward: -114\n",
      "Episode: 4646, Total Reward: -24\n",
      "Episode: 4647, Total Reward: -8\n",
      "Episode: 4648, Total Reward: -42\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4649, Total Reward: -100202\n",
      "Episode: 4650, Total Reward: -144\n",
      "Episode: 4651, Total Reward: 99968\n",
      "Episode: 4652, Total Reward: -178\n",
      "Episode: 4653, Total Reward: -106\n",
      "Episode: 4654, Total Reward: -30\n",
      "Episode: 4655, Total Reward: -350\n",
      "Episode: 4656, Total Reward: -286\n",
      "Episode: 4657, Total Reward: -132\n",
      "Episode: 4658, Total Reward: -86\n",
      "Episode: 4659, Total Reward: -90\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4660, Total Reward: -100056\n",
      "Episode: 4661, Total Reward: -134\n",
      "Episode: 4662, Total Reward: -216\n",
      "Episode: 4663, Total Reward: -142\n",
      "Episode: 4664, Total Reward: -60\n",
      "Episode: 4665, Total Reward: -186\n",
      "Episode: 4666, Total Reward: -90\n",
      "Episode: 4667, Total Reward: -386\n",
      "Episode: 4668, Total Reward: -102\n",
      "Episode: 4669, Total Reward: -220\n",
      "Episode: 4670, Total Reward: -168\n",
      "Episode: 4671, Total Reward: -56\n",
      "Episode: 4672, Total Reward: -98\n",
      "Episode: 4673, Total Reward: -94\n",
      "Episode: 4674, Total Reward: -156\n",
      "Episode: 4675, Total Reward: -162\n",
      "Episode: 4676, Total Reward: -48\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4677, Total Reward: -100184\n",
      "Episode: 4678, Total Reward: -168\n",
      "Episode: 4679, Total Reward: -80\n",
      "Episode: 4680, Total Reward: -576\n",
      "Episode: 4681, Total Reward: -50\n",
      "Episode: 4682, Total Reward: -98\n",
      "Episode: 4683, Total Reward: -396\n",
      "Episode: 4684, Total Reward: -32\n",
      "Episode: 4685, Total Reward: -204\n",
      "Episode: 4686, Total Reward: -90\n",
      "Episode: 4687, Total Reward: -150\n",
      "Episode: 4688, Total Reward: -266\n",
      "Episode: 4689, Total Reward: -166\n",
      "Episode: 4690, Total Reward: -26\n",
      "Episode: 4691, Total Reward: -90\n",
      "Episode: 4692, Total Reward: -286\n",
      "Episode: 4693, Total Reward: -48\n",
      "Episode: 4694, Total Reward: -306\n",
      "Episode: 4695, Total Reward: -54\n",
      "Episode: 4696, Total Reward: -42\n",
      "Episode: 4697, Total Reward: -52\n",
      "Episode: 4698, Total Reward: -302\n",
      "Episode: 4699, Total Reward: -168\n",
      "Episode: 4700, Total Reward: -246\n",
      "Episode: 4701, Total Reward: -90\n",
      "Episode: 4702, Total Reward: -60\n",
      "Episode: 4703, Total Reward: -18\n",
      "Episode: 4704, Total Reward: -486\n",
      "Episode: 4705, Total Reward: -230\n",
      "Episode: 4706, Total Reward: -152\n",
      "Episode: 4707, Total Reward: -30\n",
      "Episode: 4708, Total Reward: -164\n",
      "Episode: 4709, Total Reward: -60\n",
      "Episode: 4710, Total Reward: -258\n",
      "Episode: 4711, Total Reward: -222\n",
      "Episode: 4712, Total Reward: -80\n",
      "Episode: 4713, Total Reward: -56\n",
      "Episode: 4714, Total Reward: -18\n",
      "Episode: 4715, Total Reward: -242\n",
      "Episode: 4716, Total Reward: -130\n",
      "Episode: 4717, Total Reward: -108\n",
      "Episode: 4718, Total Reward: -80\n",
      "Episode: 4719, Total Reward: -130\n",
      "Episode: 4720, Total Reward: -152\n",
      "Episode: 4721, Total Reward: -110\n",
      "Episode: 4722, Total Reward: -90\n",
      "Episode: 4723, Total Reward: -146\n",
      "Episode: 4724, Total Reward: -52\n",
      "Episode: 4725, Total Reward: -116\n",
      "Episode: 4726, Total Reward: -302\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4727, Total Reward: -100380\n",
      "Episode: 4728, Total Reward: -34\n",
      "Episode: 4729, Total Reward: -20\n",
      "Episode: 4730, Total Reward: -284\n",
      "Episode: 4731, Total Reward: -38\n",
      "Episode: 4732, Total Reward: -34\n",
      "Episode: 4733, Total Reward: -258\n",
      "Episode: 4734, Total Reward: -84\n",
      "Episode: 4735, Total Reward: -148\n",
      "Episode: 4736, Total Reward: -342\n",
      "Episode: 4737, Total Reward: -60\n",
      "Episode: 4738, Total Reward: -60\n",
      "Episode: 4739, Total Reward: -228\n",
      "Episode: 4740, Total Reward: -168\n",
      "Episode: 4741, Total Reward: -30\n",
      "Episode: 4742, Total Reward: -464\n",
      "Episode: 4743, Total Reward: -66\n",
      "Episode: 4744, Total Reward: -90\n",
      "Episode: 4745, Total Reward: -90\n",
      "Episode: 4746, Total Reward: -134\n",
      "Episode: 4747, Total Reward: -332\n",
      "Episode: 4748, Total Reward: -60\n",
      "Episode: 4749, Total Reward: -190\n",
      "Episode: 4750, Total Reward: -18\n",
      "Episode: 4751, Total Reward: -42\n",
      "Episode: 4752, Total Reward: -52\n",
      "Episode: 4753, Total Reward: -36\n",
      "Episode: 4754, Total Reward: -90\n",
      "Episode: 4755, Total Reward: -172\n",
      "Episode: 4756, Total Reward: -136\n",
      "Episode: 4757, Total Reward: -90\n",
      "Episode: 4758, Total Reward: -60\n",
      "Episode: 4759, Total Reward: -196\n",
      "Episode: 4760, Total Reward: -46\n",
      "Episode: 4761, Total Reward: 99894\n",
      "Episode: 4762, Total Reward: -56\n",
      "Episode: 4763, Total Reward: -74\n",
      "Episode: 4764, Total Reward: -168\n",
      "Episode: 4765, Total Reward: -456\n",
      "Episode: 4766, Total Reward: -210\n",
      "Episode: 4767, Total Reward: -602\n",
      "Episode: 4768, Total Reward: -148\n",
      "Episode: 4769, Total Reward: -128\n",
      "Episode: 4770, Total Reward: -138\n",
      "Episode: 4771, Total Reward: -422\n",
      "Episode: 4772, Total Reward: -234\n",
      "Episode: 4773, Total Reward: -106\n",
      "Episode: 4774, Total Reward: -106\n",
      "Episode: 4775, Total Reward: -34\n",
      "Episode: 4776, Total Reward: -32\n",
      "Episode: 4777, Total Reward: -208\n",
      "Episode: 4778, Total Reward: -250\n",
      "Episode: 4779, Total Reward: -52\n",
      "Episode: 4780, Total Reward: -108\n",
      "Episode: 4781, Total Reward: -50\n",
      "Episode: 4782, Total Reward: -104\n",
      "Episode: 4783, Total Reward: -54\n",
      "Episode: 4784, Total Reward: -108\n",
      "Episode: 4785, Total Reward: -154\n",
      "Episode: 4786, Total Reward: -434\n",
      "Episode: 4787, Total Reward: -406\n",
      "Episode: 4788, Total Reward: -130\n",
      "Episode: 4789, Total Reward: -46\n",
      "Episode: 4790, Total Reward: -162\n",
      "Episode: 4791, Total Reward: -254\n",
      "Episode: 4792, Total Reward: 99960\n",
      "Episode: 4793, Total Reward: -30\n",
      "Episode: 4794, Total Reward: -150\n",
      "Episode: 4795, Total Reward: -150\n",
      "Episode: 4796, Total Reward: -402\n",
      "Episode: 4797, Total Reward: -54\n",
      "Episode: 4798, Total Reward: -154\n",
      "Episode: 4799, Total Reward: -348\n",
      "Episode: 4800, Total Reward: -76\n",
      "Episode: 4801, Total Reward: -108\n",
      "Episode: 4802, Total Reward: -52\n",
      "Episode: 4803, Total Reward: -60\n",
      "Episode: 4804, Total Reward: -88\n",
      "Episode: 4805, Total Reward: -154\n",
      "Episode: 4806, Total Reward: -50\n",
      "Episode: 4807, Total Reward: -54\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4808, Total Reward: -100202\n",
      "Episode: 4809, Total Reward: -148\n",
      "Episode: 4810, Total Reward: -54\n",
      "Episode: 4811, Total Reward: -84\n",
      "Episode: 4812, Total Reward: -312\n",
      "Episode: 4813, Total Reward: -152\n",
      "Episode: 4814, Total Reward: -90\n",
      "Episode: 4815, Total Reward: -80\n",
      "Episode: 4816, Total Reward: -60\n",
      "Episode: 4817, Total Reward: -50\n",
      "Episode: 4818, Total Reward: -274\n",
      "Episode: 4819, Total Reward: -60\n",
      "Episode: 4820, Total Reward: -62\n",
      "Episode: 4821, Total Reward: -164\n",
      "Episode: 4822, Total Reward: -108\n",
      "Episode: 4823, Total Reward: -66\n",
      "Episode: 4824, Total Reward: -106\n",
      "Episode: 4825, Total Reward: -212\n",
      "Episode: 4826, Total Reward: -144\n",
      "Episode: 4827, Total Reward: -60\n",
      "Episode: 4828, Total Reward: -12\n",
      "Episode: 4829, Total Reward: -80\n",
      "Episode: 4830, Total Reward: -54\n",
      "Episode: 4831, Total Reward: -62\n",
      "Episode: 4832, Total Reward: 0\n",
      "Episode: 4833, Total Reward: -50\n",
      "Episode: 4834, Total Reward: -60\n",
      "Episode: 4835, Total Reward: -150\n",
      "Episode: 4836, Total Reward: -276\n",
      "Episode: 4837, Total Reward: -510\n",
      "Episode: 4838, Total Reward: -432\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4839, Total Reward: -99972\n",
      "Episode: 4840, Total Reward: -380\n",
      "Episode: 4841, Total Reward: -18\n",
      "Episode: 4842, Total Reward: 0\n",
      "Episode: 4843, Total Reward: -146\n",
      "Episode: 4844, Total Reward: 34\n",
      "Episode: 4845, Total Reward: -8\n",
      "Episode: 4846, Total Reward: -92\n",
      "Episode: 4847, Total Reward: -28\n",
      "Episode: 4848, Total Reward: -102\n",
      "Episode: 4849, Total Reward: -188\n",
      "Episode: 4850, Total Reward: 99852\n",
      "Episode: 4851, Total Reward: -2\n",
      "Episode: 4852, Total Reward: -312\n",
      "Episode: 4853, Total Reward: 99890\n",
      "Episode: 4854, Total Reward: -284\n",
      "Episode: 4855, Total Reward: 2\n",
      "Episode: 4856, Total Reward: -264\n",
      "Episode: 4857, Total Reward: -132\n",
      "Episode: 4858, Total Reward: -28\n",
      "Episode: 4859, Total Reward: -274\n",
      "Episode: 4860, Total Reward: 2\n",
      "Episode: 4861, Total Reward: 24\n",
      "Episode: 4862, Total Reward: -228\n",
      "Episode: 4863, Total Reward: -28\n",
      "Episode: 4864, Total Reward: -78\n",
      "Episode: 4865, Total Reward: -174\n",
      "Episode: 4866, Total Reward: -26\n",
      "Episode: 4867, Total Reward: -38\n",
      "Episode: 4868, Total Reward: 100024\n",
      "Episode: 4869, Total Reward: -46\n",
      "Episode: 4870, Total Reward: -22\n",
      "Episode: 4871, Total Reward: -68\n",
      "Episode: 4872, Total Reward: -58\n",
      "Episode: 4873, Total Reward: -152\n",
      "Episode: 4874, Total Reward: 99858\n",
      "Episode: 4875, Total Reward: -284\n",
      "Episode: 4876, Total Reward: -44\n",
      "Episode: 4877, Total Reward: -46\n",
      "Episode: 4878, Total Reward: -544\n",
      "Episode: 4879, Total Reward: -292\n",
      "Episode: 4880, Total Reward: -70\n",
      "Episode: 4881, Total Reward: -52\n",
      "Episode: 4882, Total Reward: 99850\n",
      "Episode: 4883, Total Reward: -168\n",
      "Invalid Action: Invalid column: 2\n",
      "Episode: 4884, Total Reward: -100548\n",
      "Episode: 4885, Total Reward: 0\n",
      "Episode: 4886, Total Reward: -134\n",
      "Episode: 4887, Total Reward: -188\n",
      "Episode: 4888, Total Reward: -154\n",
      "Episode: 4889, Total Reward: -132\n",
      "Episode: 4890, Total Reward: -88\n",
      "Invalid Action: Invalid column: 3\n",
      "Episode: 4891, Total Reward: -100554\n",
      "Episode: 4892, Total Reward: -236\n",
      "Episode: 4893, Total Reward: -90\n",
      "Episode: 4894, Total Reward: -52\n",
      "Episode: 4895, Total Reward: -58\n",
      "Episode: 4896, Total Reward: -264\n",
      "Episode: 4897, Total Reward: -434\n",
      "Episode: 4898, Total Reward: 99822\n",
      "Episode: 4899, Total Reward: -56\n",
      "Episode: 4900, Total Reward: -34\n",
      "Episode: 4901, Total Reward: -38\n",
      "Episode: 4902, Total Reward: -82\n",
      "Episode: 4903, Total Reward: -134\n",
      "Episode: 4904, Total Reward: -330\n",
      "Episode: 4905, Total Reward: -240\n",
      "Episode: 4906, Total Reward: -182\n",
      "Episode: 4907, Total Reward: -106\n",
      "Episode: 4908, Total Reward: -120\n",
      "Episode: 4909, Total Reward: -594\n",
      "Episode: 4910, Total Reward: -82\n",
      "Episode: 4911, Total Reward: -56\n",
      "Episode: 4912, Total Reward: -34\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4913, Total Reward: -100298\n",
      "Episode: 4914, Total Reward: -144\n",
      "Episode: 4915, Total Reward: -48\n",
      "Episode: 4916, Total Reward: -202\n",
      "Episode: 4917, Total Reward: -568\n",
      "Episode: 4918, Total Reward: -78\n",
      "Episode: 4919, Total Reward: -100\n",
      "Episode: 4920, Total Reward: -122\n",
      "Episode: 4921, Total Reward: -312\n",
      "Episode: 4922, Total Reward: -78\n",
      "Episode: 4923, Total Reward: -274\n",
      "Episode: 4924, Total Reward: -274\n",
      "Episode: 4925, Total Reward: 100070\n",
      "Episode: 4926, Total Reward: -294\n",
      "Episode: 4927, Total Reward: -144\n",
      "Episode: 4928, Total Reward: -464\n",
      "Episode: 4929, Total Reward: -56\n",
      "Episode: 4930, Total Reward: -196\n",
      "Episode: 4931, Total Reward: -100\n",
      "Episode: 4932, Total Reward: -70\n",
      "Episode: 4933, Total Reward: -60\n",
      "Episode: 4934, Total Reward: -82\n",
      "Episode: 4935, Total Reward: 2\n",
      "Episode: 4936, Total Reward: -106\n",
      "Invalid Action: Invalid column: 5\n",
      "Episode: 4937, Total Reward: -100076\n",
      "Episode: 4938, Total Reward: -644\n",
      "Episode: 4939, Total Reward: -46\n",
      "Episode: 4940, Total Reward: -254\n",
      "Episode: 4941, Total Reward: -130\n",
      "Episode: 4942, Total Reward: -228\n",
      "Episode: 4943, Total Reward: -18\n",
      "Episode: 4944, Total Reward: -454\n",
      "Episode: 4945, Total Reward: -40\n",
      "Episode: 4946, Total Reward: -66\n",
      "Episode: 4947, Total Reward: -412\n",
      "Episode: 4948, Total Reward: -64\n",
      "Episode: 4949, Total Reward: -44\n",
      "Episode: 4950, Total Reward: -264\n",
      "Episode: 4951, Total Reward: -2\n",
      "Episode: 4952, Total Reward: -420\n",
      "Episode: 4953, Total Reward: -22\n",
      "Episode: 4954, Total Reward: -2\n",
      "Episode: 4955, Total Reward: -28\n",
      "Episode: 4956, Total Reward: -2\n",
      "Episode: 4957, Total Reward: -78\n",
      "Episode: 4958, Total Reward: -18\n",
      "Episode: 4959, Total Reward: -12\n",
      "Episode: 4960, Total Reward: -64\n",
      "Episode: 4961, Total Reward: -244\n",
      "Episode: 4962, Total Reward: -218\n",
      "Episode: 4963, Total Reward: -568\n",
      "Episode: 4964, Total Reward: -128\n",
      "Episode: 4965, Total Reward: -82\n",
      "Episode: 4966, Total Reward: -34\n",
      "Episode: 4967, Total Reward: -118\n",
      "Episode: 4968, Total Reward: -190\n",
      "Episode: 4969, Total Reward: -300\n",
      "Episode: 4970, Total Reward: -76\n",
      "Episode: 4971, Total Reward: -144\n",
      "Episode: 4972, Total Reward: -50\n",
      "Episode: 4973, Total Reward: -40\n",
      "Episode: 4974, Total Reward: -60\n",
      "Episode: 4975, Total Reward: -154\n",
      "Episode: 4976, Total Reward: -194\n",
      "Episode: 4977, Total Reward: 46\n",
      "Episode: 4978, Total Reward: -82\n",
      "Episode: 4979, Total Reward: -172\n",
      "Episode: 4980, Total Reward: 10\n",
      "Episode: 4981, Total Reward: 99962\n",
      "Episode: 4982, Total Reward: -272\n",
      "Episode: 4983, Total Reward: -184\n",
      "Episode: 4984, Total Reward: -64\n",
      "Episode: 4985, Total Reward: -96\n",
      "Episode: 4986, Total Reward: -52\n",
      "Episode: 4987, Total Reward: -106\n",
      "Episode: 4988, Total Reward: -158\n",
      "Episode: 4989, Total Reward: -52\n",
      "Episode: 4990, Total Reward: -70\n",
      "Episode: 4991, Total Reward: -40\n",
      "Episode: 4992, Total Reward: -372\n",
      "Episode: 4993, Total Reward: -272\n",
      "Episode: 4994, Total Reward: -94\n",
      "Episode: 4995, Total Reward: -72\n",
      "Episode: 4996, Total Reward: -140\n",
      "Episode: 4997, Total Reward: -68\n",
      "Episode: 4998, Total Reward: -72\n",
      "Episode: 4999, Total Reward: -156\n",
      "Episode: 5000, Total Reward: -74\n",
      "Episodes won: 49, percentage: 0.0098\n",
      "Invalid actions: 682, percentage: 0.1364\n",
      "Saving model.pt (whole model, includes file path)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Initialize environment and agent with Experience Replay Buffer\n",
    "env = make(\"connectx\", debug=True)\n",
    "\n",
    "agent = DeepQLearner(env.configuration)\n",
    "\n",
    "# Training agent in first position (player 1) against the default random agent.\n",
    "trainer = env.train([None, \"negamax\"])\n",
    "\n",
    "obs = trainer.reset()\n",
    "print(f\"Obs: {obs}\")\n",
    "mark = obs.mark\n",
    "\n",
    "# Train the DQN agent with Experience Replay Buffer\n",
    "batch_size = 64\n",
    "num_episodes = 5000\n",
    "wins = 0\n",
    "invalids = 0\n",
    "rewards = []\n",
    "for episode in range(num_episodes):\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    #env.render()\n",
    "    while not done:\n",
    "        #print(f\"Obs: {obs}\")\n",
    "        # print(f\"Board: {board}\")\n",
    "        action = agent.act(obs.board)\n",
    "        #print(f\"Action: {action}\")\n",
    "        next_obs, reward, done, _ = trainer.step(action)\n",
    "        #print(f\"Original reward: {reward}\")\n",
    "        #print(f\"Next obs: {next_obs}\")\n",
    "\n",
    "        if done and reward is not None and reward>0:\n",
    "            #print(\"WIN!\")\n",
    "            wins += 1\n",
    "            reward = 100000\n",
    "            \n",
    "        # invalid action\n",
    "        elif reward is None:\n",
    "            #print(\"REWARD FOR INVALID ACTION\")\n",
    "            invalids += 1\n",
    "            reward = -100000\n",
    "            # new_action_range = [i for i in range(0, env.configuration.columns) if i!=action]\n",
    "            # action = random.choice(new_action_range)\n",
    "\n",
    "        # custom reward\n",
    "        else:\n",
    "            grid = np.asarray(obs.board).reshape(env.configuration.rows, env.configuration.columns)\n",
    "            # invalid action\n",
    "            if grid[0][action] != 0:\n",
    "                reward = -2**(2*(env.configuration.inarow+3))\n",
    "                print(\"IT SHOULD NOT ENTER HERE\")\n",
    "            else:\n",
    "                reward = get_heuristic(drop_piece(grid, action, mark, env.configuration), mark, env.configuration)\n",
    "        \n",
    "        agent.remember(obs.board, action, reward, next_obs.board, done)\n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        agent.replay(batch_size)\n",
    "    print(f\"Episode: {episode + 1}, Total Reward: {total_reward}\")\n",
    "    rewards.append(total_reward)\n",
    "    obs = trainer.reset()\n",
    "#print(f\"History of episode reward: {rewards}\")\n",
    "#plt.plot(rewards)\n",
    "#plt.show()\n",
    "print(f\"Episodes won: {wins}, percentage: {wins/num_episodes}\")\n",
    "print(f\"Invalid actions: {invalids}, percentage: {invalids/num_episodes}\")\n",
    "agent.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training results\n",
    "\n",
    "|Number of episodes|Won (percentage)|Invalid actions (percentage)|\n",
    "|---|---|---|\n",
    "|1000|671 (0.671)|281 (0.281)|\n",
    "|2000|1496 (0.748)|148 (0.074)|\n",
    "|3000|2331 (0.777)|310 (0.103)|81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.epsilon\n",
    "len(agent.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_agent(env, config):\n",
    "    agent = DeepQLearner(config)\n",
    "    agent.load()\n",
    "    return agent.act(obs.board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a copy for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.05587,
     "end_time": "2020-09-01T17:19:39.818427",
     "exception": false,
     "start_time": "2020-09-01T17:19:39.762557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import kaggle_environments as ke\n",
    "from utils.env_wrapper import ConnectX\n",
    "\n",
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, insize, action_space):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(insize, 64)\n",
    "        self.layer1 = nn.Linear(64, 32)\n",
    "        self.layer2 = nn.Linear(32, action_space)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = tc.tanh(self.input(x))\n",
    "        x = F.relu(self.input(x))\n",
    "        #x = tc.tanh(self.layer1(x))\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeepQLearner:\n",
    "    \"\"\"The trainer, to be serialised\"\"\"\n",
    "\n",
    "    def __init__(self, config, discount=0.9, learning_rate=1.0):\n",
    "\n",
    "        print(f\"Creating agent with {config}\")\n",
    "        self.square_options = 3  # empty, player 1, player2\n",
    "\n",
    "        # hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = GAMMA\n",
    "        self.epsilon = EPS_START\n",
    "        self.epsilon_decay = EPS_DECAY\n",
    "        self.discount = discount\n",
    "        self.batch_size = BATCH_SIZE\n",
    "\n",
    "        self.memory = deque(maxlen=10000)\n",
    "\n",
    "        self.action_range = config.columns\n",
    "        # E.g. for board states rows*cols that can be in position 0, 1, 2\n",
    "        self.state_len = config.rows * config.columns\n",
    "\n",
    "        self.model = DQN(self.state_len, self.action_range)\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = tc.optim.Adam(\n",
    "            self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def act(self, board):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_range)\n",
    "        state_tensor = torch.as_tensor(board, dtype=torch.float)\n",
    "        action_predictions = self.model(state_tensor)\n",
    "        return tc.argmax(action_predictions).item()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * torch.max(self.model(torch.tensor(next_state, dtype=torch.float32))).item()\n",
    "            target_f = self.model(torch.tensor(state, dtype=torch.float32)).numpy()\n",
    "            target_f[action] = target\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss_function(torch.tensor(target_f), self.model(torch.tensor(state, dtype=torch.float32)))\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if self.epsilon > 0.01:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def do_training_episode(self, render=True):\n",
    "        trainer = self.connectx.env.train([None, \"random\"])\n",
    "        obs = trainer.reset()\n",
    "\n",
    "        rewards = []\n",
    "        while not self.connectx.env.done:\n",
    "            state_tensor = tc.as_tensor(np.expand_dims(obs.board, 0), dtype=tc.float)\n",
    "            action_predictions = self.model(state_tensor)\n",
    "\n",
    "            # Remove values where the max value is a full column by min,\n",
    "            # -1. so that if empty column has min value, it is still picked\n",
    "            less_than_min_value = tc.min(action_predictions) - 1.\n",
    "            non_full_columns = tc.where(\n",
    "                tc.tensor(  # where col is not full\n",
    "                    obs.board[:self.connectx.configuration[\"columns\"]]) == 0,\n",
    "                action_predictions,\n",
    "                less_than_min_value  # avoid selection if col is full\n",
    "            )\n",
    "\n",
    "            if not self.connectx.env.done:\n",
    "                action = tc.argmax(non_full_columns, dim=-1)\n",
    "                next_obs, reward, done, info = trainer.step(int(action))\n",
    "                rewards.append(reward)\n",
    "                # if render:\n",
    "                #     env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\n",
    "                self.update(\n",
    "                    tc.as_tensor(np.expand_dims(obs.board, 0), dtype=tc.float),\n",
    "                    action, reward, \n",
    "                    tc.as_tensor(np.expand_dims(next_obs.board, 0), dtype=tc.float))\n",
    "            obs = next_obs\n",
    "\n",
    "        if render:\n",
    "            env.render()  # final state\n",
    "\n",
    "        return rewards\n",
    "\n",
    "    def update(self, s, a, r, nxt_s):\n",
    "        \"\"\"Update the model with Bellman equation\n",
    "        \n",
    "        TODO: introduce if done, 0?\n",
    "        \"\"\"\n",
    "\n",
    "        # Create the \"label\"\n",
    "        q_prediction = tc.max(self.model(nxt_s), dim=-1)[0]  # max (1 is index)\n",
    "        target_q = r + self.discount * q_prediction\n",
    "\n",
    "        # Create the \"predicted value\" - at action a\n",
    "        q_preds_from_state = self.model(s)\n",
    "        gather_indices = tc.arange(a.shape[0]) * q_preds_from_state.shape[-1] + a\n",
    "        q_preds_from_state_at_a = tc.gather(\n",
    "            tc.reshape(q_preds_from_state, [-1]),\n",
    "            -1,\n",
    "            gather_indices\n",
    "        )\n",
    "\n",
    "        loss = tc.mean(self.loss_function(target_q, q_preds_from_state_at_a))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss  # todo - VALUE?\n",
    "\n",
    "    def save(self, filename=\"model.pt\"):\n",
    "\n",
    "        print(f\"Saving {filename} (whole model, includes file path)\")\n",
    "        tc.save(self.model, filename)\n",
    "\n",
    "    def save_state_dict(self, filename=\"model_state_dict.pt\"):\n",
    "        print(f\"Saving {filename} (state dict only)\")\n",
    "        tc.save(self.model.state_dict(), filename)\n",
    "\n",
    "    def load(self, filename=\"model.pt\"):\n",
    "\n",
    "        print(f\"Loading {filename}\")\n",
    "        self.model = tc.load(filename)\n",
    "\n",
    "    def load_from_state_dict(self, filename=\"model_state_dict.pt\"):\n",
    "        print(f\"Loading model from state dict {filename}\")\n",
    "        self.model = FFDNN(self.state_len, self.action_range)\n",
    "        state_dict = tc.load(filename)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # View init\n",
    "    env = ConnectX()  # , {\"rows\": 4, \"columns\": 4}, debug=True)\n",
    "    env.render()\n",
    "    agent = DeepQLearner(env)\n",
    "\n",
    "    model_name = \"model10k.pt\"\n",
    "    state_dict_name = \"model_state_dict10k.pt\"\n",
    "    \n",
    "    # Train, player 1 against random\n",
    "    if not os.path.exists(model_name):\n",
    "        print(\"Train agent\")\n",
    "        for i in range(10000):\n",
    "            if i % 100 == 0:\n",
    "                print(\"Trained\", i)\n",
    "            agent.do_training_episode(render=False)\n",
    "        agent.save(model_name)\n",
    "        agent.save_state_dict(state_dict_name)\n",
    "    else:\n",
    "        # safer, doesn't require file reference\n",
    "        agent.load_from_state_dict(state_dict_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.030751,
     "end_time": "2020-09-01T17:19:40.015882",
     "exception": false,
     "start_time": "2020-09-01T17:19:39.985131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_heuristic(grid, mark, config):\n",
    "    score = 0\n",
    "    for i in range(config.inarow):\n",
    "        num = count_windows(grid, i+1, mark, config)\n",
    "        score += (4**(i+1))*num\n",
    "        num_opp = count_windows(grid, i+1, mark%2+1, config)\n",
    "        score -= (2**((2*i)+3))*num_opp\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013901,
     "end_time": "2020-09-01T17:19:40.045046",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.031145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will take each window of 4 on the board and use it to evaluate a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heuristic(grid, mark, config):\n",
    "    score = 0\n",
    "    for i in range(config.inarow):\n",
    "        num = count_windows(grid, i+1, mark, config)\n",
    "        if (i==(config.inarow-1) and num>=1):\n",
    "            return float(\"inf\")\n",
    "        score += 2**(i+1) * num\n",
    "        num_opp = count_windows(grid, i+1, mark%2+1, config)\n",
    "        if (i==(config.inarow-1) and num_opp>=1):\n",
    "            return float(\"-inf\")\n",
    "        score -= 2**(2*(i+1)) * num_opp\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019562,
     "end_time": "2020-09-01T17:19:40.087990",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.068428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining the rest of the functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017153,
     "end_time": "2020-09-01T17:19:40.128193",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.111040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Nothing much to explain here. Most of the functions are the same as compared to the tutorial notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.057006,
     "end_time": "2020-09-01T17:19:40.207965",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.150959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_windows(grid, num_discs, piece, config):\n",
    "    num_windows = 0\n",
    "    # horizontal\n",
    "    for row in range(config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[row, col:col+config.inarow])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # vertical\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns):\n",
    "            window = list(grid[row:row+config.inarow, col])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # positive diagonal\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # negative diagonal\n",
    "    for row in range(config.inarow-1, config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    return num_windows\n",
    "\n",
    "def drop_piece(grid, col, mark, config):\n",
    "    next_grid = grid.copy()\n",
    "    for row in range(config.rows-1, -1, -1):\n",
    "        if next_grid[row][col] == 0:\n",
    "            break\n",
    "    next_grid[row][col] = mark\n",
    "    return next_grid\n",
    "\n",
    "def check_window(window, num_discs, piece, config):\n",
    "    return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025173,
     "end_time": "2020-09-01T17:19:40.253818",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.228645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Implementing minimax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027164,
     "end_time": "2020-09-01T17:19:40.312082",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.284918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we have used 2 functions score_move_a and score_move_b that are calling each other recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.056314,
     "end_time": "2020-09-01T17:19:40.385748",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.329434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_move_a(grid, col, mark, config,n_steps=1):\n",
    "    next_grid = drop_piece(grid, col, mark, config)\n",
    "    valid_moves = [col for col in range (config.columns) if next_grid[0][col]==0]\n",
    "    if len(valid_moves)==0 or n_steps ==0:\n",
    "        score = get_heuristic(next_grid, mark, config)\n",
    "        return score\n",
    "    else :\n",
    "        scores = [score_move_b(next_grid,col,mark,config,n_steps-1) for col in valid_moves]\n",
    "        score = min(scores)\n",
    "    return score\n",
    "\n",
    "def score_move_b(grid, col, mark, config,n_steps):\n",
    "    next_grid = drop_piece(grid,col,(mark%2)+1,config)\n",
    "    valid_moves = [col for col in range (config.columns) if next_grid[0][col]==0]\n",
    "    if len(valid_moves)==0 or n_steps ==0:\n",
    "        score = get_heuristic(next_grid, mark, config)\n",
    "        return score\n",
    "    else :\n",
    "        scores = [score_move_a(next_grid,col,mark,config,n_steps-1) for col in valid_moves]\n",
    "        score = max(scores)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017843,
     "end_time": "2020-09-01T17:19:40.424038",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.406195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027277,
     "end_time": "2020-09-01T17:19:40.473266",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.445989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we have implemented a 1 step look-ahead agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.051415,
     "end_time": "2020-09-01T17:19:40.540816",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.489401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def agent(obs, config):\n",
    "    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n",
    "    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n",
    "    scores = dict(zip(valid_moves, [score_move_a(grid, col, obs.mark, config,1) for col in valid_moves]))\n",
    "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
    "    return random.choice(max_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014447,
     "end_time": "2020-09-01T17:19:40.582907",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.568460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the agent against negamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.244123,
     "end_time": "2020-09-01T17:19:40.844378",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.600255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termcolor not installed, skipping dependency\n",
      "No pygame installed, ignoring import\n"
     ]
    }
   ],
   "source": [
    "from kaggle_environments import make, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 6.272425,
     "end_time": "2020-09-01T17:19:47.130863",
     "exception": false,
     "start_time": "2020-09-01T17:19:40.858438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "C:\\Users\\shago\\AppData\\Local\\Temp\\ipykernel_15624\\345777383.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(filename)\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n",
      "Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "Loading model.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe srcdoc=\"<!--\n",
       "  Copyright 2020 Kaggle Inc\n",
       "\n",
       "  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n",
       "  you may not use this file except in compliance with the License.\n",
       "  You may obtain a copy of the License at\n",
       "\n",
       "      http://www.apache.org/licenses/LICENSE-2.0\n",
       "\n",
       "  Unless required by applicable law or agreed to in writing, software\n",
       "  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n",
       "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "  See the License for the specific language governing permissions and\n",
       "  limitations under the License.\n",
       "-->\n",
       "<!DOCTYPE html>\n",
       "<html lang=&quot;en&quot;>\n",
       "  <head>\n",
       "    <title>Kaggle Simulation Player</title>\n",
       "    <meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot; />\n",
       "    <link\n",
       "      rel=&quot;stylesheet&quot;\n",
       "      href=&quot;https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.css&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "    />\n",
       "    <style type=&quot;text/css&quot;>\n",
       "      html,\n",
       "      body {\n",
       "        height: 100%;\n",
       "        font-family: sans-serif;\n",
       "        margin: 0px;\n",
       "      }\n",
       "      canvas {\n",
       "        /* image-rendering: -moz-crisp-edges;\n",
       "        image-rendering: -webkit-crisp-edges;\n",
       "        image-rendering: pixelated;\n",
       "        image-rendering: crisp-edges; */\n",
       "      }\n",
       "    </style>\n",
       "    <script src=&quot;https://unpkg.com/preact@10.0.1/dist/preact.umd.js&quot;></script>\n",
       "    <script src=&quot;https://unpkg.com/preact@10.0.1/hooks/dist/hooks.umd.js&quot;></script>\n",
       "    <script src=&quot;https://unpkg.com/htm@2.2.1/dist/htm.umd.js&quot;></script>\n",
       "    <script>\n",
       "      // Polyfill for Styled Components\n",
       "      window.React = {\n",
       "        ...preact,\n",
       "        createElement: preact.h,\n",
       "        PropTypes: { func: {} },\n",
       "      };\n",
       "    </script>\n",
       "    <script src=&quot;https://unpkg.com/styled-components@3.5.0-0/dist/styled-components.min.js&quot;></script>\n",
       "  </head>\n",
       "  <body>\n",
       "    <script>\n",
       "      \n",
       "window.kaggle = {\n",
       "  &quot;debug&quot;: true,\n",
       "  &quot;playing&quot;: true,\n",
       "  &quot;step&quot;: 0,\n",
       "  &quot;controls&quot;: true,\n",
       "  &quot;environment&quot;: {\n",
       "    &quot;id&quot;: &quot;b0c45d9c-68a0-11ef-80a8-a83b7687752e&quot;,\n",
       "    &quot;name&quot;: &quot;connectx&quot;,\n",
       "    &quot;title&quot;: &quot;ConnectX&quot;,\n",
       "    &quot;description&quot;: &quot;Classic Connect in a row but configurable.&quot;,\n",
       "    &quot;version&quot;: &quot;1.0.1&quot;,\n",
       "    &quot;configuration&quot;: {\n",
       "      &quot;episodeSteps&quot;: 1000,\n",
       "      &quot;actTimeout&quot;: 2,\n",
       "      &quot;runTimeout&quot;: 1200,\n",
       "      &quot;columns&quot;: 7,\n",
       "      &quot;rows&quot;: 6,\n",
       "      &quot;inarow&quot;: 4,\n",
       "      &quot;agentTimeout&quot;: 60,\n",
       "      &quot;timeout&quot;: 2\n",
       "    },\n",
       "    &quot;specification&quot;: {\n",
       "      &quot;action&quot;: {\n",
       "        &quot;description&quot;: &quot;Column to drop a checker onto the board.&quot;,\n",
       "        &quot;type&quot;: &quot;integer&quot;,\n",
       "        &quot;minimum&quot;: 0,\n",
       "        &quot;default&quot;: 0\n",
       "      },\n",
       "      &quot;agents&quot;: [\n",
       "        2\n",
       "      ],\n",
       "      &quot;configuration&quot;: {\n",
       "        &quot;episodeSteps&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum number of steps in the episode.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;minimum&quot;: 1,\n",
       "          &quot;default&quot;: 1000\n",
       "        },\n",
       "        &quot;actTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum runtime (seconds) to obtain an action from an agent.&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 2\n",
       "        },\n",
       "        &quot;runTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum runtime (seconds) of an episode (not necessarily DONE).&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 1200\n",
       "        },\n",
       "        &quot;columns&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of columns on the board&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 7,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;rows&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of rows on the board&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 6,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;inarow&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of checkers in a row required to win.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 4,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;agentTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Obsolete field kept for backwards compatibility, please use observation.remainingOverageTime.&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 60\n",
       "        },\n",
       "        &quot;timeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Obsolete copy of actTimeout maintained for backwards compatibility. May be removed in the future.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 2,\n",
       "          &quot;minimum&quot;: 0\n",
       "        }\n",
       "      },\n",
       "      &quot;info&quot;: {},\n",
       "      &quot;observation&quot;: {\n",
       "        &quot;remainingOverageTime&quot;: {\n",
       "          &quot;description&quot;: &quot;Total remaining banked time (seconds) that can be used in excess of per-step actTimeouts -- agent is disqualified with TIMEOUT status when this drops below 0.&quot;,\n",
       "          &quot;shared&quot;: false,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 60\n",
       "        },\n",
       "        &quot;step&quot;: {\n",
       "          &quot;description&quot;: &quot;Current step within the episode.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;shared&quot;: true,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 0\n",
       "        },\n",
       "        &quot;board&quot;: {\n",
       "          &quot;description&quot;: &quot;Serialized grid (rows x columns). 0 = Empty, 1 = P1, 2 = P2&quot;,\n",
       "          &quot;type&quot;: &quot;array&quot;,\n",
       "          &quot;shared&quot;: true,\n",
       "          &quot;default&quot;: []\n",
       "        },\n",
       "        &quot;mark&quot;: {\n",
       "          &quot;defaults&quot;: [\n",
       "            1,\n",
       "            2\n",
       "          ],\n",
       "          &quot;description&quot;: &quot;Which checkers are the agents.&quot;,\n",
       "          &quot;enum&quot;: [\n",
       "            1,\n",
       "            2\n",
       "          ]\n",
       "        }\n",
       "      },\n",
       "      &quot;reward&quot;: {\n",
       "        &quot;description&quot;: &quot;-1 = Lost, 0 = Draw/Ongoing, 1 = Won&quot;,\n",
       "        &quot;enum&quot;: [\n",
       "          -1,\n",
       "          0,\n",
       "          1\n",
       "        ],\n",
       "        &quot;default&quot;: 0,\n",
       "        &quot;type&quot;: [\n",
       "          &quot;number&quot;,\n",
       "          &quot;null&quot;\n",
       "        ]\n",
       "      }\n",
       "    },\n",
       "    &quot;steps&quot;: [\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 0,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 1,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 1,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 2,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 4,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 1,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 3,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 4,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 2,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 5,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 6,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              0,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 3,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 5,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 7,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 8,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 5,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 9,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 10,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 11,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 12,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 2,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 2,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 13,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 14,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 3,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 15,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 16,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 6,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 1,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 17,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 18,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 1,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 1,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 19,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 20,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 3,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 4,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 21,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 22,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 3,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 23,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 24,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 5,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 3,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 25,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: -1,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 26,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              0,\n",
       "              1,\n",
       "              0,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              2,\n",
       "              2,\n",
       "              0,\n",
       "              1,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              1,\n",
       "              2,\n",
       "              2,\n",
       "              1,\n",
       "              2\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;DONE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 4,\n",
       "          &quot;reward&quot;: 1,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;DONE&quot;\n",
       "        }\n",
       "      ]\n",
       "    ],\n",
       "    &quot;rewards&quot;: [\n",
       "      -1,\n",
       "      1\n",
       "    ],\n",
       "    &quot;statuses&quot;: [\n",
       "      &quot;DONE&quot;,\n",
       "      &quot;DONE&quot;\n",
       "    ],\n",
       "    &quot;schema_version&quot;: 1,\n",
       "    &quot;info&quot;: {}\n",
       "  },\n",
       "  &quot;logs&quot;: [\n",
       "    [],\n",
       "    [],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001733,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;C:\\\\Users\\\\shago\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_15624\\\\345777383.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\\n  self.model = torch.load(filename)\\n&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.17801,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.006784,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.120339,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001295,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.160183,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001434,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.128787,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.002009,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.087772,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001208,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.09182,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001194,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.117571,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001801,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.077883,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.001443,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.007766,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.00096,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.033756,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.00114,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.020112,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.00101,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 0.021717,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 0.000952,\n",
       "        &quot;stdout&quot;: &quot;Creating agent with {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\\nLoading model.pt\\n&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ],\n",
       "    [\n",
       "      {},\n",
       "      {\n",
       "        &quot;duration&quot;: 3.1e-05,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      }\n",
       "    ]\n",
       "  ],\n",
       "  &quot;mode&quot;: &quot;ipython&quot;\n",
       "};\n",
       "\n",
       "\n",
       "window.kaggle.renderer = // Copyright 2020 Kaggle Inc\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "function renderer({\n",
       "  act,\n",
       "  agents,\n",
       "  environment,\n",
       "  frame,\n",
       "  height = 400,\n",
       "  interactive,\n",
       "  isInteractive,\n",
       "  parent,\n",
       "  step,\n",
       "  update,\n",
       "  width = 400,\n",
       "}) {\n",
       "  // Configuration.\n",
       "  const { rows, columns, inarow } = environment.configuration;\n",
       "\n",
       "  // Common Dimensions.\n",
       "  const unit = 8;\n",
       "  const minCanvasSize = Math.min(height, width);\n",
       "  const minOffset = minCanvasSize > 400 ? 30 : unit / 2;\n",
       "  const cellSize = Math.min(\n",
       "    (width - minOffset * 2) / columns,\n",
       "    (height - minOffset * 2) / rows\n",
       "  );\n",
       "  const cellInset = 0.8;\n",
       "  const pieceScale = cellSize / 100;\n",
       "  const xOffset = Math.max(0, (width - cellSize * columns) / 2);\n",
       "  const yOffset = Math.max(0, (height - cellSize * rows) / 2);\n",
       "\n",
       "  // Canvas Setup.\n",
       "  let canvas = parent.querySelector(&quot;canvas&quot;);\n",
       "  if (!canvas) {\n",
       "    canvas = document.createElement(&quot;canvas&quot;);\n",
       "    parent.appendChild(canvas);\n",
       "\n",
       "    if (interactive) {\n",
       "      canvas.addEventListener(&quot;click&quot;, evt => {\n",
       "        if (!isInteractive()) return;\n",
       "        const rect = evt.target.getBoundingClientRect();\n",
       "        const col = Math.floor((evt.clientX - rect.left - xOffset) / cellSize);\n",
       "        if (col >= 0 && col < columns) act(col);\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  canvas.style.cursor = isInteractive() ? &quot;pointer&quot; : &quot;default&quot;;\n",
       "\n",
       "  // Character Paths (based on 100x100 tiles).\n",
       "  const kPath = new Path2D(\n",
       "    `M78.3,96.5c-0.1,0.4-0.5,0.6-1.1,0.6H64.9c-0.7,0-1.4-0.3-1.9-1l-20.3-26L37,75.5v20.1 c0,0.9-0.5,1.4-1.4,1.4H26c-0.9,0-1.4-0.5-1.4-1.4V3.9c0-0.9,0.5-1.4,1.4-1.4h9.5C36.5,2.5,37,3,37,3.9v56.5l24.3-24.7 c0.6-0.6,1.3-1,1.9-1H76c0.6,0,0.9,0.2,1.1,0.7c0.2,0.6,0.1,1-0.1,1.2l-25.7,25L78,95.1C78.4,95.5,78.5,95.9,78.3,96.5z`\n",
       "  );\n",
       "  const goose1Path = new Path2D(\n",
       "    `M8.8,92.7c-4-18.5,4.7-37.2,20.7-46.2c0,0,2.7-1.4,3.4-1.9c2.2-1.6,3-2.1,3-5c0-5-2.1-7.2-2.1-7.2 c-3.9-3.3-6.3-8.2-6.3-13.7c0-10,8.1-18.1,18.1-18.1s18.1,8.1,18.1,18.1c0,6-1.5,32.7-2.3,38.8l-0.1,1`\n",
       "  );\n",
       "  const goose2Path = new Path2D(\n",
       "    `M27.4,19L8.2,27.6c0,0-7.3,2.9,2.6,5c6.1,1.3,24,5.9,24,5.9l1,0.3`\n",
       "  );\n",
       "  const goose3Path = new Path2D(\n",
       "    `M63.7,99.6C52.3,99.6,43,90.3,43,78.9s9.3-20.7,20.7-20.7c10.6,0,34.4,0.1,35.8,9`\n",
       "  );\n",
       "\n",
       "  // Canvas setup and reset.\n",
       "  let c = canvas.getContext(&quot;2d&quot;);\n",
       "  canvas.width = width;\n",
       "  canvas.height = height;\n",
       "  c.fillStyle = &quot;#000B2A&quot;;\n",
       "  c.fillRect(0, 0, canvas.width, canvas.height);\n",
       "\n",
       "  const getRowCol = cell => [Math.floor(cell / columns), cell % columns];\n",
       "\n",
       "  const getColor = (mark, opacity = 1) => {\n",
       "    if (mark === 1) return `rgba(0,255,255,${opacity})`;\n",
       "    if (mark === 2) return `rgba(255,255,255,${opacity})`;\n",
       "    return &quot;#fff&quot;;\n",
       "  };\n",
       "\n",
       "  const drawCellCircle = (cell, xFrame = 1, yFrame = 1, radiusOffset = 0) => {\n",
       "    const [row, col] = getRowCol(cell);\n",
       "    c.arc(\n",
       "      xOffset + xFrame * (col * cellSize + cellSize / 2),\n",
       "      yOffset + yFrame * (row * cellSize + cellSize / 2),\n",
       "      (cellInset * cellSize) / 2 - radiusOffset,\n",
       "      2 * Math.PI,\n",
       "      false\n",
       "    );\n",
       "  };\n",
       "\n",
       "  // Render the pieces.\n",
       "  const board = environment.steps[step][0].observation.board;\n",
       "\n",
       "  const drawPiece = mark => {\n",
       "    // Base Styles.\n",
       "    const opacity = minCanvasSize < 300 ? 0.6 - minCanvasSize / 1000 : 0.1;\n",
       "    c.fillStyle = getColor(mark, opacity);\n",
       "    c.strokeStyle = getColor(mark);\n",
       "    c.shadowColor = getColor(mark);\n",
       "    c.shadowBlur = 8 / cellInset;\n",
       "    c.lineWidth = 1 / cellInset;\n",
       "\n",
       "    // Outer circle.\n",
       "    c.save();\n",
       "    c.beginPath();\n",
       "    c.arc(50, 50, 50, 2 * Math.PI, false);\n",
       "    c.closePath();\n",
       "    c.lineWidth *= 4;\n",
       "    c.stroke();\n",
       "    c.fill();\n",
       "    c.restore();\n",
       "\n",
       "    // Inner circle.\n",
       "    c.beginPath();\n",
       "    c.arc(50, 50, 40, 2 * Math.PI, false);\n",
       "    c.closePath();\n",
       "    c.stroke();\n",
       "\n",
       "    // Kaggle &quot;K&quot;.\n",
       "    if (mark === 1) {\n",
       "      const scale = 0.54;\n",
       "      c.save();\n",
       "      c.translate(23, 23);\n",
       "      c.scale(scale, scale);\n",
       "      c.lineWidth /= scale;\n",
       "      c.shadowBlur /= scale;\n",
       "      c.stroke(kPath);\n",
       "      c.restore();\n",
       "    }\n",
       "\n",
       "    // Kaggle &quot;Goose&quot;.\n",
       "    if (mark === 2) {\n",
       "      const scale = 0.6;\n",
       "      c.save();\n",
       "      c.translate(24, 28);\n",
       "      c.scale(scale, scale);\n",
       "      c.lineWidth /= scale;\n",
       "      c.shadowBlur /= scale;\n",
       "      c.stroke(goose1Path);\n",
       "      c.stroke(goose2Path);\n",
       "      c.stroke(goose3Path);\n",
       "      c.beginPath();\n",
       "      c.arc(38.5, 18.6, 2.7, 0, Math.PI * 2, false);\n",
       "      c.closePath();\n",
       "      c.fill();\n",
       "      c.restore();\n",
       "    }\n",
       "  };\n",
       "\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    const [row, col] = getRowCol(i);\n",
       "    if (board[i] === 0) continue;\n",
       "    // Easing In.\n",
       "    let yFrame = Math.min(\n",
       "      (columns * Math.pow(frame, 3)) / Math.floor(i / columns),\n",
       "      1\n",
       "    );\n",
       "\n",
       "    if (\n",
       "      step > 1 &&\n",
       "      environment.steps[step - 1][0].observation.board[i] === board[i]\n",
       "    ) {\n",
       "      yFrame = 1;\n",
       "    }\n",
       "\n",
       "    c.save();\n",
       "    c.translate(\n",
       "      xOffset + cellSize * col + (cellSize - cellSize * cellInset) / 2,\n",
       "      yOffset +\n",
       "        yFrame * (cellSize * row) +\n",
       "        (cellSize - cellSize * cellInset) / 2\n",
       "    );\n",
       "    c.scale(pieceScale * cellInset, pieceScale * cellInset);\n",
       "    drawPiece(board[i]);\n",
       "    c.restore();\n",
       "  }\n",
       "\n",
       "  // Background Gradient.\n",
       "  const bgRadius = (Math.min(rows, columns) * cellSize) / 2;\n",
       "  const bgStyle = c.createRadialGradient(\n",
       "    xOffset + (cellSize * columns) / 2,\n",
       "    yOffset + (cellSize * rows) / 2,\n",
       "    0,\n",
       "    xOffset + (cellSize * columns) / 2,\n",
       "    yOffset + (cellSize * rows) / 2,\n",
       "    bgRadius\n",
       "  );\n",
       "  bgStyle.addColorStop(0, &quot;#000B49&quot;);\n",
       "  bgStyle.addColorStop(1, &quot;#000B2A&quot;);\n",
       "\n",
       "  // Render the board overlay.\n",
       "  c.beginPath();\n",
       "  c.rect(0, 0, canvas.width, canvas.height);\n",
       "  c.closePath();\n",
       "  c.shadowBlur = 0;\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    drawCellCircle(i);\n",
       "    c.closePath();\n",
       "  }\n",
       "  c.fillStyle = bgStyle;\n",
       "  c.fill(&quot;evenodd&quot;);\n",
       "\n",
       "  // Render the board overlay cell outlines.\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    c.beginPath();\n",
       "    drawCellCircle(i);\n",
       "    c.strokeStyle = &quot;#0361B2&quot;;\n",
       "    c.lineWidth = 1;\n",
       "    c.stroke();\n",
       "    c.closePath();\n",
       "  }\n",
       "\n",
       "  const drawLine = (fromCell, toCell) => {\n",
       "    if (frame < 0.5) return;\n",
       "    const lineFrame = (frame - 0.5) / 0.5;\n",
       "    const x1 = xOffset + (fromCell % columns) * cellSize + cellSize / 2;\n",
       "    const x2 =\n",
       "      x1 +\n",
       "      lineFrame *\n",
       "        (xOffset + ((toCell % columns) * cellSize + cellSize / 2) - x1);\n",
       "    const y1 =\n",
       "      yOffset + Math.floor(fromCell / columns) * cellSize + cellSize / 2;\n",
       "    const y2 =\n",
       "      y1 +\n",
       "      lineFrame *\n",
       "        (yOffset + Math.floor(toCell / columns) * cellSize + cellSize / 2 - y1);\n",
       "    c.beginPath();\n",
       "    c.lineCap = &quot;round&quot;;\n",
       "    c.lineWidth = 4;\n",
       "    c.strokeStyle = getColor(board[fromCell]);\n",
       "    c.shadowBlur = 8;\n",
       "    c.shadowColor = getColor(board[fromCell]);\n",
       "    c.moveTo(x1, y1);\n",
       "    c.lineTo(x2, y2);\n",
       "    c.stroke();\n",
       "  };\n",
       "\n",
       "  // Generate a graph of the board.\n",
       "  const getCell = (cell, rowOffset, columnOffset) => {\n",
       "    const row = Math.floor(cell / columns) + rowOffset;\n",
       "    const col = (cell % columns) + columnOffset;\n",
       "    if (row < 0 || row >= rows || col < 0 || col >= columns) return -1;\n",
       "    return col + row * columns;\n",
       "  };\n",
       "  const makeNode = cell => {\n",
       "    const node = { cell, directions: [], value: board[cell] };\n",
       "    for (let r = -1; r <= 1; r++) {\n",
       "      for (let c = -1; c <= 1; c++) {\n",
       "        if (r === 0 && c === 0) continue;\n",
       "        node.directions.push(getCell(cell, r, c));\n",
       "      }\n",
       "    }\n",
       "    return node;\n",
       "  };\n",
       "  const graph = board.map((_, i) => makeNode(i));\n",
       "\n",
       "  // Check for any wins!\n",
       "  const getSequence = (node, direction) => {\n",
       "    const sequence = [node.cell];\n",
       "    while (sequence.length < inarow) {\n",
       "      const next = graph[node.directions[direction]];\n",
       "      if (!next || node.value !== next.value || next.value === 0) return;\n",
       "      node = next;\n",
       "      sequence.push(node.cell);\n",
       "    }\n",
       "    return sequence;\n",
       "  };\n",
       "\n",
       "  // Check all nodes.\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    // Check all directions (not the most efficient).\n",
       "    for (let d = 0; d < 8; d++) {\n",
       "      const seq = getSequence(graph[i], d);\n",
       "      if (seq) {\n",
       "        drawLine(seq[0], seq[inarow - 1]);\n",
       "        i = board.length;\n",
       "        break;\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  // Upgrade the legend.\n",
       "  if (agents.length && (!agents[0].color || !agents[0].image)) {\n",
       "    const getPieceImage = mark => {\n",
       "      const pieceCanvas = document.createElement(&quot;canvas&quot;);\n",
       "      parent.appendChild(pieceCanvas);\n",
       "      pieceCanvas.style.marginLeft = &quot;10000px&quot;;\n",
       "      pieceCanvas.width = 100;\n",
       "      pieceCanvas.height = 100;\n",
       "      c = pieceCanvas.getContext(&quot;2d&quot;);\n",
       "      c.translate(10, 10);\n",
       "      c.scale(0.8, 0.8);\n",
       "      drawPiece(mark);\n",
       "      const dataUrl = pieceCanvas.toDataURL();\n",
       "      parent.removeChild(pieceCanvas);\n",
       "      return dataUrl;\n",
       "    };\n",
       "\n",
       "    agents.forEach(agent => {\n",
       "      agent.color = getColor(agent.index + 1);\n",
       "      agent.image = getPieceImage(agent.index + 1);\n",
       "    });\n",
       "    update({ agents });\n",
       "  }\n",
       "};\n",
       "\n",
       "\n",
       "    \n",
       "    </script>\n",
       "    <script>\n",
       "      const h = htm.bind(preact.h);\n",
       "      const { useContext, useEffect, useRef, useState } = preactHooks;\n",
       "      const styled = window.styled.default;\n",
       "\n",
       "      const Context = preact.createContext({});\n",
       "\n",
       "      const Loading = styled.div`\n",
       "        animation: rotate360 1.1s infinite linear;\n",
       "        border: 8px solid rgba(255, 255, 255, 0.2);\n",
       "        border-left-color: #0cb1ed;\n",
       "        border-radius: 50%;\n",
       "        height: 40px;\n",
       "        position: relative;\n",
       "        transform: translateZ(0);\n",
       "        width: 40px;\n",
       "\n",
       "        @keyframes rotate360 {\n",
       "          0% {\n",
       "            transform: rotate(0deg);\n",
       "          }\n",
       "          100% {\n",
       "            transform: rotate(360deg);\n",
       "          }\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const Logo = styled(\n",
       "        (props) => h`\n",
       "        <a href=&quot;https://kaggle.com&quot; target=&quot;_blank&quot; className=${props.className}>\n",
       "          <svg width=&quot;62px&quot; height=&quot;20px&quot; viewBox=&quot;0 0 62 24&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;>\n",
       "            <g fill=&quot;#1EBEFF&quot; fill-rule=&quot;nonzero&quot;>\n",
       "              <path d=&quot;M10.2,17.8c0,0.1-0.1,0.1-0.2,0.1H7.7c-0.1,0-0.3-0.1-0.4-0.2l-3.8-4.9l-1.1,1v3.8 c0,0.2-0.1,0.3-0.3,0.3H0.3c-0.2,0-0.3-0.1-0.3-0.3V0.3C0.1,0.1,0.2,0,0.3,0h1.8c0.2,0,0.3,0.1,0.3,0.3V11L7,6.3 c0.1-0.1,0.2-0.2,0.4-0.2h2.4c0.1,0,0.2,0,0.2,0.1c0,0.1,0,0.2,0,0.2l-4.9,4.7l5.1,6.3C10.2,17.6,10.2,17.7,10.2,17.8z&quot;/>\n",
       "              <path d=&quot;M19.6,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3v-0.4c-0.8,0.6-1.8,0.9-3,0.9c-1.1,0-2-0.3-2.8-1 c-0.8-0.7-1.2-1.6-1.2-2.7c0-1.7,1.1-2.9,3.2-3.5c0.8-0.2,2.1-0.5,3.8-0.6c0.1-0.6-0.1-1.2-0.5-1.7c-0.4-0.5-1-0.7-1.7-0.7 c-1,0-2,0.4-3,1C12.2,9.1,12.1,9.1,12,9l-0.9-1.3C11,7.5,11,7.4,11.1,7.3c1.3-0.9,2.7-1.4,4.2-1.4c1.1,0,2.1,0.3,2.8,0.8 c1.1,0.8,1.7,2,1.7,3.7v7.3C19.9,17.8,19.8,17.9,19.6,17.9z M17.5,12.4c-1.7,0.2-2.9,0.4-3.5,0.7c-0.9,0.4-1.2,0.9-1.1,1.6 c0.1,0.4,0.2,0.7,0.6,0.9c0.3,0.2,0.7,0.4,1.1,0.4c1.2,0.1,2.2-0.2,2.9-1V12.4z&quot;/>\n",
       "              <path d=&quot;M30.6,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3v11.7C32,20,31.5,21.5,30.6,22.5z M29.7,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7V9.9z&quot;/>\n",
       "              <path d=&quot;M42.9,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3H44c0.2,0,0.3,0.1,0.3,0.3v11.7C44.3,20,43.8,21.5,42.9,22.5z M42,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7L42,9.9 L42,9.9z&quot;/>\n",
       "              <path d=&quot;M48.3,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3V0.3c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3 v17.3C48.5,17.8,48.5,17.9,48.3,17.9z&quot;/>\n",
       "              <path d=&quot;M61.4,12.6c0,0.2-0.1,0.3-0.3,0.3h-8.5c0.1,0.9,0.5,1.6,1.1,2.2c0.7,0.6,1.6,0.9,2.7,0.9 c1,0,1.8-0.3,2.6-0.8c0.2-0.1,0.3-0.1,0.4,0l1.2,1.3c0.1,0.1,0.1,0.3,0,0.4c-1.3,0.9-2.7,1.4-4.4,1.4c-1.8,0-3.3-0.6-4.4-1.8 c-1.1-1.2-1.7-2.7-1.7-4.5c0-1.7,0.6-3.2,1.7-4.4c1-1.1,2.4-1.6,4.1-1.6c1.6,0,2.9,0.6,4,1.7c1.1,1.2,1.6,2.6,1.5,4.4L61.4,12.6 z M58,8.7c-0.6-0.5-1.3-0.8-2.1-0.8c-0.8,0-1.5,0.3-2.1,0.8c-0.6,0.5-1,1.2-1.1,2H59C59,9.9,58.6,9.3,58,8.7z&quot;/>\n",
       "            </g>\n",
       "          </svg>\n",
       "        </a>\n",
       "      `\n",
       "      )`\n",
       "        display: inline-flex;\n",
       "      `;\n",
       "\n",
       "      const Header = styled((props) => {\n",
       "        const { environment } = useContext(Context);\n",
       "\n",
       "        return h`<div className=${props.className} >\n",
       "          <${Logo} />\n",
       "          <span><b>Left / Right Arrow:</b> Increase / Decrease Step</span><span><b>0-9 Row Keys:</b> Playback Speed</span><span><b>Space:</b> Pause / Play</span>\n",
       "          ${environment.title}\n",
       "        </div>`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        border-bottom: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        color: #fff;\n",
       "        display: flex;\n",
       "        flex: 0 0 36px;\n",
       "        font-size: 14px;\n",
       "        justify-content: space-between;\n",
       "        padding: 0 8px;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Renderer = styled((props) => {\n",
       "        const context = useContext(Context);\n",
       "        const { animate, debug, playing, renderer, speed } = context;\n",
       "        const ref = preact.createRef();\n",
       "\n",
       "        useEffect(async () => {\n",
       "          if (!ref.current) return;\n",
       "\n",
       "          const renderFrame = async (start, step, lastFrame) => {\n",
       "            if (step !== context.step) return;\n",
       "            if (lastFrame === 1) {\n",
       "              if (!animate) return;\n",
       "              start = Date.now();\n",
       "            }\n",
       "            const frame =\n",
       "              playing || animate\n",
       "                ? Math.min((Date.now() - start) / speed, 1)\n",
       "                : 1;\n",
       "            try {\n",
       "              if (debug) console.time(&quot;render&quot;);\n",
       "              await renderer({\n",
       "                ...context,\n",
       "                frame,\n",
       "                height: ref.current.clientHeight,\n",
       "                hooks: preactHooks,\n",
       "                parent: ref.current,\n",
       "                preact,\n",
       "                styled,\n",
       "                width: ref.current.clientWidth,\n",
       "              });\n",
       "            } catch (error) {\n",
       "              if (debug) console.error(error);\n",
       "              console.log({ ...context, frame, error });\n",
       "            } finally {\n",
       "              if (debug) console.timeEnd(&quot;render&quot;);\n",
       "            }\n",
       "            window.requestAnimationFrame(() => renderFrame(start, step, frame));\n",
       "          };\n",
       "\n",
       "          await renderFrame(Date.now(), context.step);\n",
       "        }, [ref.current, context.step, context.renderer]);\n",
       "\n",
       "        return h`<div className=${props.className} ref=${ref} />`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        box-sizing: border-box;\n",
       "        display: flex;\n",
       "        height: 100%;\n",
       "        left: 0;\n",
       "        justify-content: center;\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Processing = styled((props) => {\n",
       "        const { processing } = useContext(Context);\n",
       "        const text = processing === true ? &quot;Processing...&quot; : processing;\n",
       "        return h`<div className=${props.className}>${text}</div>`;\n",
       "      })`\n",
       "        bottom: 0;\n",
       "        color: #fff;\n",
       "        font-size: 12px;\n",
       "        left: 0;\n",
       "        line-height: 24px;\n",
       "        position: absolute;\n",
       "        text-align: center;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Viewer = styled((props) => {\n",
       "        const { processing } = useContext(Context);\n",
       "        return h`<div className=${props.className}>\n",
       "          <${Renderer} />\n",
       "          ${processing && h`<${Processing} />`}\n",
       "        </div>`;\n",
       "      })`\n",
       "        background-color: #000b2a;\n",
       "        background-image: radial-gradient(\n",
       "          circle closest-side,\n",
       "          #000b49,\n",
       "          #000b2a\n",
       "        );\n",
       "        display: flex;\n",
       "        flex: 1;\n",
       "        overflow: hidden;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      // Partitions the elements of arr into subarrays of max length num.\n",
       "      const groupIntoSets = (arr, num) => {\n",
       "        const sets = [];\n",
       "        arr.forEach(a => {\n",
       "          if (sets.length === 0 || sets[sets.length - 1].length === num) {\n",
       "            sets.push([]);\n",
       "          }\n",
       "          sets[sets.length - 1].push(a);\n",
       "        });\n",
       "        return sets;\n",
       "      }\n",
       "\n",
       "      // Expects `width` input prop to set proper max-width for agent name span.\n",
       "      const Legend = styled((props) => {\n",
       "        const { agents, legend } = useContext(Context);\n",
       "\n",
       "        const agentPairs = groupIntoSets(agents.sort((a, b) => a.index - b.index), 2);\n",
       "\n",
       "        return h`<div className=${props.className}>\n",
       "          ${agentPairs.map(agentList =>\n",
       "            h`<ul>\n",
       "                ${agentList.map(a =>\n",
       "                  h`<li key=${a.id} title=&quot;id: ${a.id}&quot; style=&quot;color:${a.color || &quot;#FFF&quot;}&quot;>\n",
       "                      ${a.image && h`<img src=${a.image} />`}\n",
       "                      <span>${a.name}</span>\n",
       "                    </li>`\n",
       "                )}\n",
       "              </ul>`)}\n",
       "        </div>`;\n",
       "      })`\n",
       "        background-color: #000b2a;\n",
       "        font-family: sans-serif;\n",
       "        font-size: 14px;\n",
       "        height: 48px;\n",
       "        width: 100%;\n",
       "\n",
       "        ul {\n",
       "          align-items: center;\n",
       "          display: flex;\n",
       "          flex-direction: row;\n",
       "          justify-content: center;\n",
       "        }\n",
       "\n",
       "        li {\n",
       "          align-items: center;\n",
       "          display: inline-flex;\n",
       "          transition: color 1s;\n",
       "        }\n",
       "\n",
       "        span {\n",
       "          max-width: ${p => (p.width || 400) * 0.5 - 36}px;\n",
       "          overflow: hidden;\n",
       "          text-overflow: ellipsis;\n",
       "          white-space: nowrap;\n",
       "        }\n",
       "\n",
       "        img {\n",
       "          height: 24px;\n",
       "          margin-left: 4px;\n",
       "          margin-right: 4px;\n",
       "          width: 24px;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const StepInput = styled.input.attrs({\n",
       "        type: &quot;range&quot;,\n",
       "      })`\n",
       "        appearance: none;\n",
       "        background: rgba(255, 255, 255, 0.15);\n",
       "        border-radius: 2px;\n",
       "        display: block;\n",
       "        flex: 1;\n",
       "        height: 4px;\n",
       "        opacity: 0.8;\n",
       "        outline: none;\n",
       "        transition: opacity 0.2s;\n",
       "        width: 100%;\n",
       "\n",
       "        &:hover {\n",
       "          opacity: 1;\n",
       "        }\n",
       "\n",
       "        &::-webkit-slider-thumb {\n",
       "          appearance: none;\n",
       "          background: #1ebeff;\n",
       "          border-radius: 100%;\n",
       "          cursor: pointer;\n",
       "          height: 12px;\n",
       "          margin: 0;\n",
       "          position: relative;\n",
       "          width: 12px;\n",
       "\n",
       "          &::after {\n",
       "            content: &quot;&quot;;\n",
       "            position: absolute;\n",
       "            top: 0px;\n",
       "            left: 0px;\n",
       "            width: 200px;\n",
       "            height: 8px;\n",
       "            background: green;\n",
       "          }\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const PlayButton = styled.button`\n",
       "        align-items: center;\n",
       "        background: none;\n",
       "        border: none;\n",
       "        color: white;\n",
       "        cursor: pointer;\n",
       "        display: flex;\n",
       "        flex: 0 0 56px;\n",
       "        font-size: 20px;\n",
       "        height: 40px;\n",
       "        justify-content: center;\n",
       "        opacity: 0.8;\n",
       "        outline: none;\n",
       "        transition: opacity 0.2s;\n",
       "\n",
       "        &:hover {\n",
       "          opacity: 1;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const StepCount = styled.span`\n",
       "        align-items: center;\n",
       "        color: white;\n",
       "        display: flex;\n",
       "        font-size: 14px;\n",
       "        justify-content: center;\n",
       "        opacity: 0.8;\n",
       "        padding: 0 16px;\n",
       "        pointer-events: none;\n",
       "      `;\n",
       "\n",
       "      const Controls = styled((props) => {\n",
       "        const { environment, pause, play, playing, setStep, step } = useContext(\n",
       "          Context\n",
       "        );\n",
       "        const value = step + 1;\n",
       "        const onClick = () => (playing ? pause() : play());\n",
       "        const onInput = (e) => {\n",
       "          pause();\n",
       "          setStep(parseInt(e.target.value) - 1);\n",
       "        };\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            <${PlayButton} onClick=${onClick}><svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24px&quot; height=&quot;24px&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;#FFFFFF&quot;>${\n",
       "          playing\n",
       "            ? h`<path d=&quot;M6 19h4V5H6v14zm8-14v14h4V5h-4z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n",
       "            : h`<path d=&quot;M8 5v14l11-7z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n",
       "        }</svg><//>\n",
       "            <${StepInput} min=&quot;1&quot; max=${\n",
       "          environment.steps.length\n",
       "        } value=&quot;${value}&quot; onInput=${onInput} />\n",
       "            <${StepCount}>${value} / ${environment.steps.length}<//>\n",
       "          </div>\n",
       "        `;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        border-top: 4px solid #212121;\n",
       "        display: flex;\n",
       "        flex: 0 0 44px;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Info = styled((props) => {\n",
       "        const {\n",
       "          environment,\n",
       "          playing,\n",
       "          step,\n",
       "          speed,\n",
       "          animate,\n",
       "          header,\n",
       "          controls,\n",
       "          settings,\n",
       "        } = useContext(Context);\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            info:\n",
       "            step(${step}),\n",
       "            playing(${playing ? &quot;T&quot; : &quot;F&quot;}),\n",
       "            speed(${speed}),\n",
       "            animate(${animate ? &quot;T&quot; : &quot;F&quot;})\n",
       "          </div>`;\n",
       "      })`\n",
       "        color: #888;\n",
       "        font-family: monospace;\n",
       "        font-size: 12px;\n",
       "      `;\n",
       "\n",
       "      const Settings = styled((props) => {\n",
       "        const { environment, pause, play, playing, setStep, step } = useContext(\n",
       "          Context\n",
       "        );\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            <${Info} />\n",
       "          </div>\n",
       "        `;\n",
       "      })`\n",
       "        background: #fff;\n",
       "        border-top: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        padding: 20px;\n",
       "        width: 100%;\n",
       "\n",
       "        h1 {\n",
       "          font-size: 20px;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const Player = styled((props) => {\n",
       "        const context = useContext(Context);\n",
       "        const { agents, controls, header, legend, loading, settings, width } = context;\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            ${loading && h`<${Loading} />`}\n",
       "            ${!loading && header && h`<${Header} />`}\n",
       "            ${!loading && h`<${Viewer} />`}\n",
       "            ${!loading && legend && h`<${Legend} width=${width}/>`}\n",
       "            ${!loading && controls && h`<${Controls} />`}\n",
       "            ${!loading && settings && h`<${Settings} />`}\n",
       "          </div>`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        background: #212121;\n",
       "        border: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "        height: 100%;\n",
       "        justify-content: center;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const App = () => {\n",
       "        const renderCountRef = useRef(0);\n",
       "        const [_, setRenderCount] = useState(0);\n",
       "\n",
       "        // These are bindings to the 0-9 keys and are milliseconds of timeout per step\n",
       "        const speeds = [\n",
       "          0,\n",
       "          3000,\n",
       "          1000,\n",
       "          500,\n",
       "          333, // Default\n",
       "          200,\n",
       "          100,\n",
       "          50,\n",
       "          25,\n",
       "          10,\n",
       "        ];\n",
       "\n",
       "        const contextRef = useRef({\n",
       "          animate: false,\n",
       "          agents: [],\n",
       "          controls: false,\n",
       "          debug: false,\n",
       "          environment: { steps: [], info: {} },\n",
       "          header: window.innerHeight >= 600,\n",
       "          height: window.innerHeight,\n",
       "          interactive: false,\n",
       "          legend: true,\n",
       "          loading: false,\n",
       "          playing: false,\n",
       "          processing: false,\n",
       "          renderer: () => &quot;DNE&quot;,\n",
       "          settings: false,\n",
       "          speed: speeds[4],\n",
       "          step: 0,\n",
       "          width: window.innerWidth,\n",
       "        });\n",
       "\n",
       "        // Context helpers.\n",
       "        const rerender = (contextRef.current.rerender = () =>\n",
       "          setRenderCount((renderCountRef.current += 1)));\n",
       "        const setStep = (contextRef.current.setStep = (newStep) => {\n",
       "          contextRef.current.step = newStep;\n",
       "          rerender();\n",
       "        });\n",
       "        const setPlaying = (contextRef.current.setPlaying = (playing) => {\n",
       "          contextRef.current.playing = playing;\n",
       "          rerender();\n",
       "        });\n",
       "        const pause = (contextRef.current.pause = () => setPlaying(false));\n",
       "\n",
       "        const playNext = () => {\n",
       "          const context = contextRef.current;\n",
       "\n",
       "          if (\n",
       "            context.playing &&\n",
       "            context.step < context.environment.steps.length - 1\n",
       "          ) {\n",
       "            setStep(context.step + 1);\n",
       "            play(true);\n",
       "          } else {\n",
       "            pause();\n",
       "          }\n",
       "        };\n",
       "\n",
       "        const play = (contextRef.current.play = (continuing) => {\n",
       "          const context = contextRef.current;\n",
       "          if (context.playing && !continuing) return;\n",
       "          if (!context.playing) setPlaying(true);\n",
       "          if (\n",
       "            !continuing &&\n",
       "            context.step === context.environment.steps.length - 1\n",
       "          ) {\n",
       "            setStep(0);\n",
       "          }\n",
       "          setTimeout(playNext, context.speed);\n",
       "        });\n",
       "\n",
       "        const updateContext = (o) => {\n",
       "          const context = contextRef.current;\n",
       "          Object.assign(context, o, {\n",
       "            environment: { ...context.environment, ...(o.environment || {}) },\n",
       "          });\n",
       "          rerender();\n",
       "        };\n",
       "\n",
       "        // First time setup.\n",
       "        useEffect(() => {\n",
       "          // Timeout is used to ensure useEffect renders once.\n",
       "          setTimeout(() => {\n",
       "            // Initialize context with window.kaggle.\n",
       "            updateContext(window.kaggle || {});\n",
       "\n",
       "            if (window.kaggle.playing) {\n",
       "                play(true);\n",
       "            }\n",
       "\n",
       "            // Listen for messages received to update the context.\n",
       "            window.addEventListener(\n",
       "              &quot;message&quot;,\n",
       "              (event) => {\n",
       "                // Ensure the environment names match before updating.\n",
       "                try {\n",
       "                  if (\n",
       "                    event.data.environment.name ==\n",
       "                    contextRef.current.environment.name\n",
       "                  ) {\n",
       "                    updateContext(event.data);\n",
       "                  }\n",
       "                } catch {}\n",
       "              },\n",
       "              false\n",
       "            );\n",
       "            // Listen for keyboard commands.\n",
       "            window.addEventListener(\n",
       "              &quot;keydown&quot;,\n",
       "              (event) => {\n",
       "                const {\n",
       "                  interactive,\n",
       "                  isInteractive,\n",
       "                  playing,\n",
       "                  step,\n",
       "                  environment,\n",
       "                } = contextRef.current;\n",
       "                const key = event.keyCode;\n",
       "                const zero_key = 48\n",
       "                const nine_key = 57\n",
       "                if (\n",
       "                  interactive ||\n",
       "                  isInteractive() ||\n",
       "                  (key !== 32 && key !== 37 && key !== 39 && !(key >= zero_key && key <= nine_key))\n",
       "                )\n",
       "                  return;\n",
       "\n",
       "                if (key === 32) {\n",
       "                  playing ? pause() : play();\n",
       "                } else if (key === 39) {\n",
       "                  contextRef.current.playing = false;\n",
       "                  if (step < environment.steps.length - 1) setStep(step + 1);\n",
       "                  rerender();\n",
       "                } else if (key === 37) {\n",
       "                  contextRef.current.playing = false;\n",
       "                  if (step > 0) setStep(step - 1);\n",
       "                  rerender();\n",
       "                } else if (key >= zero_key && key <= nine_key) {\n",
       "                  contextRef.current.speed = speeds[key - zero_key];\n",
       "                }\n",
       "                event.preventDefault();\n",
       "                return false;\n",
       "              },\n",
       "              false\n",
       "            );\n",
       "          }, 1);\n",
       "        }, []);\n",
       "\n",
       "        if (contextRef.current.debug) {\n",
       "          console.log(&quot;context&quot;, contextRef.current);\n",
       "        }\n",
       "\n",
       "        // Ability to update context.\n",
       "        contextRef.current.update = updateContext;\n",
       "\n",
       "        // Ability to communicate with ipython.\n",
       "        const execute = (contextRef.current.execute = (source) =>\n",
       "          new Promise((resolve, reject) => {\n",
       "            try {\n",
       "              window.parent.IPython.notebook.kernel.execute(source, {\n",
       "                iopub: {\n",
       "                  output: (resp) => {\n",
       "                    const type = resp.msg_type;\n",
       "                    if (type === &quot;stream&quot;) return resolve(resp.content.text);\n",
       "                    if (type === &quot;error&quot;) return reject(new Error(resp.evalue));\n",
       "                    return reject(new Error(&quot;Unknown message type: &quot; + type));\n",
       "                  },\n",
       "                },\n",
       "              });\n",
       "            } catch (e) {\n",
       "              reject(new Error(&quot;IPython Unavailable: &quot; + e));\n",
       "            }\n",
       "          }));\n",
       "\n",
       "        // Ability to return an action from an interactive session.\n",
       "        contextRef.current.act = (action) => {\n",
       "          const id = contextRef.current.environment.id;\n",
       "          updateContext({ processing: true });\n",
       "          execute(`\n",
       "            import json\n",
       "            from kaggle_environments import interactives\n",
       "            if &quot;${id}&quot; in interactives:\n",
       "                action = json.loads('${JSON.stringify(action)}')\n",
       "                env, trainer = interactives[&quot;${id}&quot;]\n",
       "                trainer.step(action)\n",
       "                print(json.dumps(env.steps))`)\n",
       "            .then((resp) => {\n",
       "              try {\n",
       "                updateContext({\n",
       "                  processing: false,\n",
       "                  environment: { steps: JSON.parse(resp) },\n",
       "                });\n",
       "                play();\n",
       "              } catch (e) {\n",
       "                updateContext({ processing: resp.split(&quot;\\n&quot;)[0] });\n",
       "                console.error(resp, e);\n",
       "              }\n",
       "            })\n",
       "            .catch((e) => console.error(e));\n",
       "        };\n",
       "\n",
       "        // Check if currently interactive.\n",
       "        contextRef.current.isInteractive = () => {\n",
       "          const context = contextRef.current;\n",
       "          const steps = context.environment.steps;\n",
       "          return (\n",
       "            context.interactive &&\n",
       "            !context.processing &&\n",
       "            context.step === steps.length - 1 &&\n",
       "            steps[context.step].some((s) => s.status === &quot;ACTIVE&quot;)\n",
       "          );\n",
       "        };\n",
       "\n",
       "        return h`\n",
       "          <${Context.Provider} value=${contextRef.current}>\n",
       "            <${Player} />\n",
       "          <//>`;\n",
       "      };\n",
       "\n",
       "      preact.render(h`<${App} />`, document.body);\n",
       "    </script>\n",
       "  </body>\n",
       "</html>\n",
       "\" width=\"300\" height=\"300\" frameborder=\"0\"></iframe> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "env.run([my_agent,\"negamax\"])\n",
    "env.render(mode=\"ipython\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016238,
     "end_time": "2020-09-01T17:19:47.164902",
     "exception": false,
     "start_time": "2020-09-01T17:19:47.148664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Getting win percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016107,
     "end_time": "2020-09-01T17:19:47.197304",
     "exception": false,
     "start_time": "2020-09-01T17:19:47.181197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since one iteration is not enough to conclude which agent is better we run 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.031294,
     "end_time": "2020-09-01T17:19:47.244757",
     "exception": false,
     "start_time": "2020-09-01T17:19:47.213463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_win_percentages(agent1, agent2, n_rounds=100):\n",
    "    config = {'rows': 10, 'columns': 7, 'inarow': 4}\n",
    "    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n",
    "    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n",
    "    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n",
    "    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n",
    "    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n",
    "    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 1816.23011,
     "end_time": "2020-09-01T17:50:03.492046",
     "exception": false,
     "start_time": "2020-09-01T17:19:47.261936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 Win Percentage: 0.92\n",
      "Agent 2 Win Percentage: 0.04\n",
      "Number of Invalid Plays by Agent 1: 0\n",
      "Number of Invalid Plays by Agent 2: 0\n"
     ]
    }
   ],
   "source": [
    "get_win_percentages(agent1=agent, agent2=\"negamax\",n_rounds = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015862,
     "end_time": "2020-09-01T17:50:03.524172",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.508310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the algorithm works good and does get a good score but the question is how can we do better? \n",
    "\n",
    "So the thing is There are two main problems with the algorithm.\n",
    "\n",
    "1. The first one is fairly obvious that the this version of minimax is not efficient and could do better with optimisations like alpha-beta pruning.\n",
    "\n",
    "2. The second problem is a bit more subtle and complex. If you carefully understand what minimax is doing, it computes the score for each permutation possible but the agent will often come across a case when both players can win if they make a move and it is your agents turn as shown below. "
   ]
  },
  {
   "attachments": {
    "Capture.JPG": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAeAB4AAD/4RD6RXhpZgAATU0AKgAAAAgABAE7AAIAAAAQAAAISodpAAQAAAABAAAIWpydAAEAAAAgAAAQ0uocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFNpZGhhbnQgQWdhcndhbAAABZADAAIAAAAUAAAQqJAEAAIAAAAUAAAQvJKRAAIAAAADOTQAAJKSAAIAAAADOTQAAOocAAcAAAgMAAAInAAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADIwMjA6MDg6MDYgMTI6MzQ6NDMAMjAyMDowODowNiAxMjozNDo0MwAAAFMAaQBkAGgAYQBuAHQAIABBAGcAYQByAHcAYQBsAAAA/+ELImh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjAtMDgtMDZUMTI6MzQ6NDMuOTQyPC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPlNpZGhhbnQgQWdhcndhbDwvcmRmOmxpPjwvcmRmOlNlcT4NCgkJCTwvZGM6Y3JlYXRvcj48L3JkZjpEZXNjcmlwdGlvbj48L3JkZjpSREY+PC94OnhtcG1ldGE+DQogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9J3cnPz7/2wBDAAcFBQYFBAcGBQYIBwcIChELCgkJChUPEAwRGBUaGRgVGBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr/2wBDAQcICAoJChQLCxQqHBgcKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKir/wAARCAHhAjQDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDwrNGaMUUxBmiijFABRRRQAUUUUAFFFFABRRRQAUUUUAFFGaKACiigUAFFFFABRRRQAUUUdKACgUUUAFFFFABiiijNABRSUtACUuKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAozRRQAZozRRQAUUUUAFFGKKACiiigAooooAKKKKACijNFABRRRQAUUUUAFFFXba32gO4+bsPSgCKK0Z+ZPlHp3q0lvGnRQfc81JVmw0291W6W20yznvJ26RQRl2P4CmIrAAdBRXbW/wd8e3MQkj8PSqp7STxRn8mYGsvWfAPirQIml1bQryCFfvShN6L9WXIH50Ac7RRRQAUUUUAFFFFABRQBk4FdTpXw08ZazCsth4evDG3KvKohDD1BcjNAHLUV2d58IvHdjEZJvDtwwHaCSOY/kjE1yNzaz2dw8F3BJBMhw0cqFWU+4PIoAiooooAKKKKACiiigAorU0bwzrfiGQromlXd9g4ZoYiVX6t0H4mul/4Uz4+8rzP+Effb6faYc/lvzQBw1Fams+Gdb8PSBdb0q7scnCtNEQrfRuh/A1l0AFFFFABRRRQAUUVLbWs95cJBaQSTzOcLHEhZmPsByaAIqK7Oz+EXju+iEkPh24UHtPJHCfydgaq6r8NPGWjQtLf+HrwRryzxKJgo9SUJxQBy1FBGDg0UAFFFFABRRRQAUUV0WjeAfFWvxLLpOhXk8LfdlKbEb6M2AfzoA52iu2uPg749tojJJ4elZR2jnikP5KxNclf6be6VdNbanZz2c69Yp4yjD8DQBWooooAKKKKACiiigAoq9pWiaprlx5Gj6fc30o6rbxF9v1x0/Guqj+DXj6WLzF8PSBfRrmFT+RfNAHD0Vt614N8R+HV361o15aR5x5rxkx/99jI/WsSgAooooAKKKKACiinRxvLIscSM7scKqjJJ9AKAG0hAPUA12Gn/CrxvqcQktfDt0qsMgzlYc/g5FGofCrxvpkRkuvDt0yqMkwFZsfghNAHFvbRP/Dg+oqrLbNHyPmWtGSN4pGjlRkdThlYYIPoRTaAMnNFWrm2AzJGPqKq0hhRRmjrQAUUUUAFFFFAE9rF5ku49Fq/UNqu2AH+9zV/TbCfVdUtdPtF3T3UyQxj1ZiAP50xHb/C/wCF9148vmubtnttGt32zTqPmlbrsTPf1PbNfTug+HdJ8M6atjodjFaQKBnYvzOfVm6sfc0eHdBs/DPh6z0jTkCwWsYTOMF2/iY+5OSfrWnSGFFFFIZ5d8Rvgxpfia2m1Dw/DFp+sAbgqALFcH0YdAx/vD8c9R8zXdpcWF5NaXsLwXEDmOSNxhkYHBBFfdVfPv7RHhKK1vbLxPZxBBdN9mu9o6yAZRvqVBH/AAEU0JniNFFFMQVf0TRb/wARazb6XpMBnurhtqKOg9ST2AHJNUK+jP2e/CUVl4dn8S3MQN1fu0VuxH3IVODj/eYHP+6KAOo8A/CfRPBVvFcSRJf6vgF7uVchG9Iwfuj36n17V3lFFSUFYXinwZofjGwNrrlkkpAxHOo2yxf7rdR9Oh7it2igD47+IPgDUPAWufZrkmeyny1rdBcCRR1B9GGRkf41ydfZHxE8Jw+MfBV7pzRhrpUM1o+OVlUZXH1+6fYmvjgggkEYI6iqJEooooAK9u+FPwWi1Ozh1/xhE32aQB7WxJK+YvUO/faey9+p44PCfCnwpH4v8f2lndpvsrcG5ulI4ZFx8p9ixUH2Jr68VQqhVAAAwAB0pMaI7a1gsrZLezgjt4IxtSKJAqqPQAcCpaKKQyK5tYL22e3vII7iCQbXilQMrD0IPBrwL4rfBaLTLObX/B8TfZowXurEEt5a9S6d9o7r26jjgfQVIyhlKsAQRggjrQB8IUV2fxW8KR+EPH93Z2ibLK4AubVQOFRs/KPYMGA9gK4yqJCiilAJIAGSegoA6v4feANQ8e659mtiYLKDDXV0VyI1PQD1Y4OB/hX1P4W8GaH4OsBa6HZJESMSTsN0sv8AvN1P06DsKqfDvwnD4O8FWWnLGFumQTXb45aVhls/T7o9gK6ikMKKKKQzg/H3wn0Txrby3EcSWGr4JS7iXAdvSQD7w9+o9e1fLWt6Lf8Ah3WbjS9WgMF1bttdT0PoQe4I5Br7hrxv9oTwlFe+HYPEttEBdWDrFcMB9+FjgZ/3WIx/vGmhM+c6KKKYgqa0tLi/vIbSyhee4ncRxxoMs7E4AAqGvbv2d/CUV1e3vie8iDi1b7Nabh0kIy7fUKQP+BGgDsfhz8GNL8M20OoeIIYtQ1gjcVcBorc+ijoWH94/hjqfUaKKkoKzNe8O6T4m01rHXLGK7gYHG9fmQ+qt1U+4rTooA+T/AIofC+68B3y3Noz3OjXD7YZ2HzRN12Pjv6HvivP6+3fEWg2fibw9eaRqKBoLqMpnGSjfwsPcHBH0r4r1Kwn0rVLrT7tds9rM8Mg9GUkH+VUiWVqKKKACvVvhR8IW8XKus+IBJDo4YiKNTte6I64PZAeM9T0HrXCeDvDz+KvGGm6MhKi6mAkZeqxj5nP4KDX2fZ2dvp9jDZ2UKw28CCOKNBgIoGABSY0R6bpdjo9jHZaVaQ2ltGPlihQKB78dT79atUUUhiOiyRskih0YEMrDII9DXjHxO+CVpfWs+seDbYW96mXlsIxiOYd9g/hb2HB9j19oooA+ECCrFWBBBwQe1JXqHx38JReH/GialZRCO11ZGlKqMBZgfnx9cq31Y15fVEhRRRQBueEfCepeM/EEWlaSnzN80srfchQdWb/PJwK+qfBfw50HwRaKNNthNelcS30ygyucc4P8I9h+OetYnwT8JReHfAVvfSRAX2rKLmVyORGf9Wv02nP1Y16NSY0FFFFIZynjT4c6D43tGGpWwhvQuIr6FQJUOOMn+Iex/DHWvlbxd4T1LwZ4gl0rVk+ZfmilX7kyHoy/54ORX2pXnPxs8JReIvAVxfRxA32kqbmJwOTGP9Yv02jP1UUxM+VazriPypSB0PIrRqtermNW9DimIpCiiikMKKMUUAFFFFAGnD/qE/3RXc/B23S5+LmhRyjKiSSQZ9Vidh+oFcNF/qU/3RXS+AdZTQPiBo2pTtshhulErH+FG+Vj+AY0xH2dRRRUlBRRRQAV578crdJvhHqcjj5oJIJE9j5qr/JjXoVeU/tCaylj8P4dN3fvtRulAX1RPmY/ns/OgD5loooqiQr7M+Hdult8NfDscQwp06GQ49WQMf1Jr4zr64+DusprPwt0oq2ZLNDaSj+6UOAP++dp/Gkxo7iiiikMKKKKACvifxfbpaeN9ctohiOHUbiNQPQSMBX2leXcNhYz3l0+yC3jaWRj/CqjJP5Cvh/U759T1e8v5Bh7qd5mHoWYn+tNCZVooopiPcv2abdGvfEVyR+8jjt41PsxkJ/9BFe/V82/s66yln40vtLlbb/aFrmP/aeM5x/3yXP4V9JUmNBRRRSGFFFFAHgP7S1ui3vh25A/eSR3EbH2Uxkf+hGvDa9e/aK1lLzxpY6XE27+z7XMn+y8hzj/AL5CH8a8hqiWFbHhC3S78b6HbSjMc2o28bA+hkUGserWmXz6Zq9nfxjL2s6TKPUqwP8ASgD7moqGzu4b+xgvLV98FxGssbD+JWGQfyNTVJQUUUUAFc38RLdLn4a+Io5RlRp00gz6qhYfqBXSVw/xi1lNG+FuqlmxJeILSIf3i5wR/wB87j+FAHyPRRRVEhX1d8DbdIfhHpkiD5p5J5H9z5rL/JRXyjX01+z3rKX3w/m03d++066YFfRH+ZT+e/8AKhjR6tRRRUjCiiigAr5F+MVult8XNdjiGFMkchx6tEjH9Sa+uq+MfH2spr/xA1nUoG3wzXTCJh/Ei/Kp/EKKaEznaKKKYj1T9nm3Sb4lTyOPmg06WRPY741/kxr6cr5P+Cespo/xSsBM22O+R7Qn3YZUfiyqPxr6wpMaCiiikMKKKKAPH/2j7dG8EaZckfvI9REan2aNyf8A0EV83175+0lrKC30bREbMhd7uRfQAbEP45f8q8DqkSwooooA+6rS3S0soLaIYjhjWNQPQDAqasXwdrKeIPBek6pG277RaoX9nAw4/BgR+FbVSUFFFFABUN3bpd2U9tKMxzRtGwPoRg1NWL4x1lPD/gvVtUkbb9ntXKe7kYQfixA/GgD4pqG6H+jt+H86mqK6/wCPZvw/nVEmdRRRikMKKKKADFHNFFAGnF/qU/3R/Kn0yL/Up/uin0xH0/8ABj4jQ+JtBi0TU5wNYsY9ihjg3EQGAw9WA4P59zj1GvhW0u7iwvIrqynkt7iFg8csbFWQjuCOle0eEv2iLi1t47XxfYNeBQB9stMLIfdkOAT7gj6UrDufQVFee2/xy8BTRBpNWlt2/uSWcpI/75Uj9ay9Z/aE8K2MTf2TBeapN/CBH5KH6s3I/wC+TSGenX9/a6XYTXuoTpb20CF5JZDgKBXyN8S/G8njnxbLepuSwgHk2cbDBEYP3iPVjyfwHajxv8S9e8czbNQlFvYK2Y7KAkRg9ie7H3P4AVyFUSFFFFABXo/wc+ISeDPEL2eqSbdI1AhZmxnyZB92T6c4Ptg9q84ooA+7o5EmiWSJ1eNwGVlOQwPQg06vk3wL8Xte8FIlmcalpa9LSdyDGP8AYb+H6YI9q9j0r4/+Db2FTfteabJ/EssBcA+xTOfyFKw7np9FedXnx18CW0RaHUbi8I/ggtJAT/32FH615p4y+P8AqurwPZ+F7ZtJgbhrlm3TsPbHCfhk+hFIZ0Px2+I0MVjJ4S0acPcSkf2hIhyI1HIjz6k9fQcd+Pn6nO7SOzuxZmOWYnJJ9abVEhRRRQBc0nVLrRNYtdT06Ty7m1lWWNsZGQehHcHoR6V9h+CvGOneNvDsWpac4EmAtzbk/NBJjlT7eh7ivjCtbw54n1fwpqi6hoV49tMOHA5WRf7rL0IoA+2qK8W8O/tGaXcQpH4n0yaznxhprT95GT67SQy/T5q6r/hd/gHyt/8AbT7v7n2ObP8A6Bj9ako7+ue8a+MdO8E+HZdS1FwZMFba3B+aeTHCj29T2Feb+Iv2jNLt4Xj8MaZNeT4ws13+7jB9doJZvp8teHeI/E+r+K9UbUNdvHuZjwgPCxr/AHVXoBTsK5V1bVLrW9YutT1GTzLm6laWRsYGSegHYDoB6VToopiCiiigD6B+BPxGhlsY/CWszhLiIn+z5HOBIp5MefUHp6jjtz7fXwijtG6ujFWU5VgcEH1r17wb8f8AVdIgSz8UWzatAvC3KttnUe+eH/HB9SaVh3PpCivOrP46+BLmINNqNxZk/wAE9pISP++Aw/Wquq/H/wAG2ULGwa81KT+FYoCgJ9y+MfkaQz02SRIYmkldUjQFmZjgKB1JNfLHxj+ISeM/EKWelybtI08lYWxjzpD96T6cYHtk96reOvi9r3jVHsxjTdLbraQOSZB/tt/F9MAe1cDTsK4UUUUxBXX/AA08byeBvFsV6+57CceTeRqMkxk/eA9VPI/Ed65CigD7osL+11SwhvdPnS4tp0DxyxnIYGrFfH3gj4l694Gm2afKLiwZsyWU5JjJ7kd1PuPxBr2vRv2hPCt9Ev8Aa0F5pc38QMfnIPoy8n/vkUrDuerUV57cfHLwFDEWj1aW4b+5HZygn/vpQP1rz/xb+0RcXVvJa+ELBrMMCPtl3hpB7qgyAfck/SkM7H4z/EaHwzoMuiaZODrF9HsYKcm3iIwWPoxHA/PsM/MFTXd3cX95LdXs8lxcTMXklkYszk9yT1qGqJCiiigB8UskEySwuySRsGRlOCpHIIr64+GXxBtfHXh1GkkRNWtkC3kHQ56eYo/un9Dx9fkSruk6vqGhalFqGkXclpdRH5JYzgj29x7Hg0AfcdFeF+GP2jIfJSDxbpjiQDBurHBDe5QkY/An6Cu0j+OHgF4tzazJG39xrObP6KR+tSUegVm6/r+neGdFn1TWJxBbQjJPdz2VR3J7CvMtd/aI8P2cLLoNjdalPj5WkHkxj3ycsfpgfWvEPF/jnXPG2oC51u53RoSYbaP5Yoc/3V9fc5PvTsK5B4v8T3fjDxRd6ze/K07YjjB4ijHCqPoPzOT3rEoopiCiiigD2P4GfEaHQ7p/DWtziKyupN9pM5wsUp4Kk9lbj6H619G18H16f4H+OGt+F4I7DVo/7Y09AFQSPtmiHor85HsfoCKVh3PqGivNtP8Aj14IvIg11dXVg2OUntWbH4puo1D49eCLOIta3V1ftjhILVlz+L7aQz0mvnL45/EaHXLpPDWiTiWytZN93Mhysso4Cg91Xn6n6Vl+OPjhrfiiCSw0mP8AsfT3BVxG+6aUejPxgew+hJrzCnYVwqK6/wCPZvw/nUtRXX/Hs/4fzpiM7vRRRmkMKKM0UAFFFFAGnF/qU/3RT6ZF/qU/3RT6YgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKiuv+PZvw/nUtRXX/AB7N+H86AM6iiikMKKKKACiiigDTi/1Kf7op9Mi/1Kf7op9MQUVf0XRNR8RatDpuj2r3V1McKi9h3JPQAdya998Jfs96RZW8c/i24fUbogFraFzHCntkYZvrx9KAPnOivsy3+Hfg62iEcfhjSmUd5LRJD+bAmsvWfg74J1mJlOjpYyHpLYsYiv4D5fzBpXHY+R6K9H+IXwc1bwZHJqFjIdS0hfvTKuJIf99fT/aHHrivOKYgooooAKKKKACivWvAPwL1DxFbxal4llk0zT5AGjhQDz5V9eeEHuQT7d69l0r4T+CdJhVItAtrhh1e7Hnlvf5sj8gKLhY+QKK+ybz4beDL6IxzeGdNUHvBbrCfzTBrzTxl+zzA0D3fgq5dJhz9hunyreyv1H0bP1FK47HgNFT3tlc6dezWd/BJb3MLFJIpFwykdiKgpiCiiigAoorp/BXgHWvHWoNBpMQS3iI8+7l4jiB/mfYfoOaAOYor6l8O/Anwjo0KNqUMmsXIHzSXLFUz7Ipxj6k11X/Cv/B/leX/AMIvpG31+xR5/PGaVx2PjCivqXxF8CfCOswu2mwyaPckfLJbMWTPujHGPoRXgPjXwDrXgXUFg1aIPbyk+RdxcxygfyPsf1HNMRzFFFFABRRRQAUVPZWVzqN7DZ2EElxczMEjijXLMT2Ar3fwb+zzAsCXfjW5d5jz9htXwq+zP1P0XH1NAHgNFfZNn8NvBljEI4fDOmsB3nt1mP5vk1V1X4T+CdWhZJdAtrdj0e0HkFff5cD8waVx2PkCivWvH3wL1Dw7by6l4alk1PT4wWkhcDz4l9eOHHuAD7d68lpiCiiigAooooAKK9H+Hvwc1bxnHHqF9IdN0hvuzMuZJv8AcX0/2jx6Zr3HRvg74J0aJVGjpfSDrLfMZS34H5fyAouFj5Hor7MuPh34OuYjHJ4Y0pVPeO0SM/moBrz/AMW/s96Re28k/hK4fTroAlbaZzJC/tk5Zfrz9KVx2PnOir+taJqPh3VptN1i1e1uoThkbuOxB6EHsRVCmIKKKKACiitrwv4T1fxhq66dodt5suN0jscJEv8AeZuw/U9s0AYtFfTXhj4AeG9LhSTX2k1i6xlgWMcKn2VTk/iefQV2kfw+8HxReWvhfSCvq1lGx/MjNK47HxjRX1frvwT8Ga1C3kae2mTkfLLZOVwf9w5XH4D614N4++F2s+A5vOnxe6Y77Yr2JcDPYOv8J/MHsadxWOJooooAKKKKACinIjyyKkas7sQFVRkknsBXtfgf9n6e9gjvvGc8lmjAMtjAR5hH+23O36AE+4NAHiVFfYun/C/wVpkQjg8N2MmB965j88n8XzRqHwv8FanEY5/DdjHkfeto/II/FMUrjsfHVFe2+OP2fp7KCS+8GTyXiKCzWM5HmAf7DcbvoQD7k14o6PFIySKyOpIZWGCCOxFMQ2orr/j2b8P51LUV1/x7P+H86AM6ijNFIYUUZooAKKKKANOL/Up/uingZOBTIv8AUp/uius+GmlprPxL0OymXdGboSOp6MEBcj/x2mI+i/hP4Bh8FeFo5LmJf7XvUEl1IR8yA8iL2C9/U59q7yiipKCiiigBskaTRNHKivG4KsrDIYHqCK+T/i94FXwV4tzYpt0vUAZrUdoyD80f4EjHsRX1lXmHx/0tL34aNelf3mn3Ucit3AY7CP8Ax4fkKaEz5eooopiCvWvgX4Bi8RaxLr+rQrLp+nOFiicZWWbGefUKMHHqV968lr6/+E+lppPwt0SNFw09uLlz/eMnz5/IgfhQwR2NFFFSUFFFFAHkvxz8Axa34fk8R6dCq6jpybp9o5nhHXPuvXPoCPSvmmvu2aKOeF4ZkDxyKVdT0YEYIr4g1qw/srX9Q0/Ofsl1JBk/7LFf6U0JlGiiimI1PDeg3XifxJZaNYcTXcoQMRkIvVmPsACfwr7J8O+H7DwvoNtpOlRCOCBcZxzI3d2Pck814P8As4aWlx4o1XU3Xc1narGmf4TIx5/JCPxNfRdJjQUUUUhhWZ4i8P2HijQbnSdViEkE64zjmNuzqexB5rTooA+I/Emg3XhjxJe6Nf8AM1pKULAYDr1Vh7EEH8ay69l/aP0tLfxRpWpou1ry1aN8fxGNhz+TgfgK8aqiQooq9oth/auv6fp+cfa7qODI/wBpgv8AWgD6I+BngGLRPD8fiPUYVbUdRTdBuHMEJ6Y92659CB6161TIYo4IUhhQJHGoVFHRQBgCn1JQUUUUAFfNPx08AxeHdYi1/SYVi0/UXKyxIMLFNjPHoGGTj1De1fS1cd8WNLTVvhbrcbrloLc3KH+6Y/nz+QI/GgD5AoooqiQrvvhD4FXxr4tzfJu0vTwJrodpCT8sf4kHPsDXA19Q/ADS0svhot6F/eahdSSM3chTsA/8dP5mhgj02ONIYljiRUjQBVVRgKB0AFOooqSgooooA4P4seAYfGvhaSS2iX+17JDJayAfM4HJi9w3b0OPevksjBwa+8K+OPiXpaaN8S9csoV2xi6MiKOihwHA/wDHqaEzlqKKKYieys59Qv4LOzjMtxcSLFEg6szHAH5mvsXwJ4Ms/BHhiDTbVUe4ID3VwBzNJ3P0HQDsPxr56+BOlpqXxStpJV3LY28lyAfUYQH8C4P4V9U0mNBRRRSGFV7+wtdU0+ex1CBLi1uEKSxOMhgasUUAfG3xB8IS+CfGFzpTFntziW1kI+/E2cfiMFT7g1zFfQf7SWlo+j6NqwXEkVw9szeoZdwH4bD+Zr58qiQooooA94+AXgGKSE+LtVhVzuMeno44XBw0v1zlR6YPtXvFZnhrS00TwvpmmRLtW1tY4z7kKMn8Tk1p1JQUUUUAFeD/AB98AxRwjxdpUKodwj1BEHDZOFl+ucKfXI9694rM8S6Wmt+F9T0yVdy3VrJGPYlTg/gcGgD4iqK6/wCPZvw/nUtRXX/Hs34fzqiTO70UUUhhRRmigAooooA04v8AUp/uj+Vdt8IrxLH4saFLKcBpmiGfV42QfqwriYv9Sn+6P5VYtbmWzu4bm2cxzQuskbjqrA5B/MUxH3XRWF4M8U2vjHwraaxZkAyLtnjH/LKUfeX8+nqCD3rdqSgooooAK86+Ot4lt8J7+Jzg3U0MSe5Egf8Akhr0Wvm/4/8AjKLV9ft/D1hJvg0wlrhh0ac8bf8AgI4+rMO1Ajx+iiiqEFfZPw2vEvvhl4eliOQthFEceqLsP6qa+Nq9+/Z58ZRNaXHhO9k2zIzXFln+JTy6D6H5vxb0pMaPcqKKKQwooooAK+JPFN4mo+MNZvYjmO5v55VI7hpGI/nX1L8V/GUXg/wRcukmNQvla3s1HXcRgv8A8BBz9cDvXyLTQmFFFFMR7f8As1XiJqmv2RP7yaGGVR7IzA/+jBX0DXxt8O/Ff/CG+OLHVZNxtgTFdKoyTE3Dcd8cNj1UV9iwTxXVtHcW8iywyoHjdTkMpGQR7YpMaJKKKKQwooqOeeK1tpLi4kWKGJC8jscBVAySfbFAHgX7St4j6poFkD+8hhmlYezsoH/os14hXT/ETxX/AMJl44vtVj3C2JEVqrDBES8Lx2zy2PVjXMVRIVq+FrxNO8YaNeynEdtfwSsT2CyKT/KsqigD7worifhR4yi8YeCLZ3kzqFiq294p67gMB/8AgQGfrkdq7apKCiiigArmPiTeJY/DLxDLKcBrCWIZ9XXYP1YV09eG/tDeMoltLfwnZSbpnZbi9x/Co5RD9T834L60AeA0UUVRIV9V/Aq8S5+E9hEhybWaaJ/YmQv/ACcV8qV7B8APGUWka/ceHr+TZBqZDW7Hos442/8AAhx9VUd6GCPpCiiipKCiiigAr5C+Lt4l98WNdliOQsyxHHqkaof1U19QeM/FNr4O8K3esXhBMa7YIz/y1lP3V/Pr6AE9q+Mbq5lvLua5uXMk0ztJI56sxOSfzNNCZFRRRTEeo/s+XiW3xNaJzg3VhLEnuQyP/JDX0/XxF4c1ufw34ksNYtRmSzmWTbnG8d1+hGR+NfaGjavZ69o1rqmmS+ba3UYkjbvj0PoQeCPUUmNF2iiikMKKKKAPHP2kLxE8H6TZE/vJr/zVHskbA/8AowV85V6F8ZvGUXi3xuyWEnmafpqm3hYdJGzl3H1PA9QoNee1SJCiiigD7n068TUdLtL2I5juYUlUjuGUEfzqzXlfwI8ZRa34QXQrmT/T9KG1VPV4CflYfTO32wvrXqlSUFFFFABVbUbxNO0u7vZTiO2heViewVST/KrNeV/HfxlFonhBtCtpP9P1UbWUdUgB+Zj9cbffLelAHzHUV1/x7N+H86lqK6/49m/D+dUSZ1GKKKQwxRRRQAUUUUAacX+pT/dFPpkX+pT/AHRT6YjrPAHxB1LwFrBuLT/SLKYgXNmzYWQeoPZh2NfTnhP4ieHPGNuh0u/jS6YfNZzkJMp9Nv8AF9VyK+N6UEggg4I6GgD7vqG7vLWwtmuL65htoE5aWaQIq/Univi238X+JbSIR2viHVYIxwEjvZFH5Bqo32p3+pyB9Svrm7cdGuJmkI/EmlYdz3f4jfHa2itptK8EyGadxtfUsYSMd/LB5J/2ug7Z7eAO7SOzuxZmOWYnJJ9abRTEFFFFABU9le3OnX0N5YzPBcwOHjlQ4ZWHQioKKAPpbwD8c9J1u3isfFUkemaioC/aHOIJz65/gPsePQ9q9XimjnhWWCRZI3GVdGBDD2Ir4Sq9Ya1qulZ/svU7yyzyfs9w0f8A6CRSsO59xVxPjL4r+GvB8DpJdJqGoDhbK1cM2f8Aabon48+gNfLV54p8QajEY9Q13UrqM8FJ7yRwfwJrKosFzd8XeLtT8aa7JqeryZY/LFCn3IU7Ko/r3rCoopiCiiigAr1P4X/GKfwhGmka6sl3pGf3bJzJa5POPVfbt29K8sooA+3dE8R6P4jtBc6HqNvexkZPlP8AMv8AvL1U+xArTr4TguJrWZZbaWSGRejxsVI/EVr/APCaeKfK8v8A4STV/L6bPt8uPy3UrDufYWt+I9H8OWhudc1G3sowMjzX+Zv91erH2ANfOvxQ+MU/i+N9I0JZLTSM/vGfiS6weM+i+3fv6V5hPcTXUzS3Msk0jdXkYsT+JqOnYVwooooAKKKKAN3wj4u1PwXrsep6RJhh8ssL/cmTurD+vavp3wb8V/DXjCBEjuk0/UDw1ldOFbP+y3R/w59QK+RaKAPvCmSzRwQtLPIscaDLO7ABR7k18T2finxBp0Qj0/XdStYxwEgvJEA/AGoL/WtV1XH9qaneXuOR9ouGk/8AQiaVh3Pojx98c9J0S3lsfCskep6iwK/aEOYID65/jPsOPU9q+cL29udRvpry+mee5ncvJK5yzMepNQUUxBRRRQAU5HaN1dGKspyrA4IPrTaKAPoH4c/Ha2ltodK8bSGGdBtTUsZSQdvMA5B/2uh747+02l5a39stxY3MNzA/KywyB1b6EcV8K1asdTv9MkL6bfXNo56tbzNGT+INKw7n3NXL+LPiJ4c8HW7nVL+N7pR8tnAQ8zH02/w/VsCvk+48X+JbuIx3XiHVZ4zwUkvZGH5FqyCSSSTknqaLBc6vx/8AEHUvHusC4u/9HsoSRbWatlYx6k92Pc1ydFFMQUUUUAFd98NPinfeA7lra4R73R5m3SWwbDRt/fTPf1HQ+3WuBooA+1PDnjPQPFlqs2h6lDcMRloS22VP95DyPr0963K+EUkeKQPGzI6nIZTgitiPxn4ohi8uLxJq6R9Ni30oH5bqVh3PsrU9W0/RrNrrVr2CzgXrJPIEH0Gep9q8F+J3xvGr2s+ieDzJHayZSe/IKtKvdUHVQe5PJ9B38cu726v5vOvrma5l/vzSF2/M1BRYLhRRRTEFFFFAGhoeuah4c1mDVNIuGguoGyrDoR3UjuD0Ir6Z8D/Gjw/4pgjt9Umj0jU8ANFO+I5D6o54/A4P1618rUUAfd6sGUMpBBGQR3oZgqlmIAAySe1fENh4i1rS02aZrF/Zp/dt7p4x+hFF/wCIta1RNmp6xf3if3bi6eQfqTSsO59MeOPjR4f8LQSW+lzR6vqeCFigfMcZ9XccfgMn6da+Ztc1zUPEesz6pq9w091O2WY9AOygdgOgFZ9FMQVFdf8AHs34fzqWorr/AI9m/D+dAGdRRRSGFFFFABRRRQBpxf6lP90U+mRf6lP90fyp9MQUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFRXX/Hs/4fzqWobr/j2f8P50AZ9FGaM0hhRRmigAooooA04v9Sn+6P5U+mRf6lP90U+mIK7Pwp8KfFXi+FLmxshbWT8rd3beWjD1UYLMPcAiu7+C3wpt9Tgj8UeJYBLbbs2VpIvyyYP+sYHqueg79TxjP0CqhVCqAABgADpSuOx4Fb/s03LRA3XieKKTusdkXH5lx/KsvWf2dvEVnE0mj6hZ6nt/5ZnMLt9M5X82FfSVFFwsfDeqaTqGiag9jq9nNZ3Mf3opkKnHr7j3HFU6+z/GPgrSfG2jPY6tCBIATBcqo8yBvUH09R0NfI3ifw5e+FPEV1o+pria3bAcD5ZFP3XX2IpiMmiiigAoorp/APgq78deJ49Nt2MNug8y6uNuRFGP6noB/QGgDM0Hw3rHie/+x6DYTXs3BYRj5UHqzHhR7kivUdK/Zw1u4hV9X1mzsWPOyKNpiv15UfkTXvHh/wAO6X4X0iLTdFtUt4IxzgfNIf7zHuT61p0rjsfP15+zVfJETp/iS3nk7LPaNEPzDN/KvN/Ffw78S+Dfn1nT2FsThbuE+ZET2+YdPocGvsmo54Ibq3eC5iSaGRSrxyKGVh6EHqKLhY+E6K9T+MXwvTwhdLrGho39kXUm1ouT9lkPOM/3T29OnpXllMQUUUUAFOjjeWRY4lZ3chVVRksT0AFEcbyyLHErO7kKqqMliegAr6l+Ffwrs/B2mxajqsKT65MgZnYZFqD/AAJ7+rfgOOoB5H4d+BHi3W4Unvkh0iFhkfa2PmEf7gyR9GxXVf8ADNEvlZ/4SlPM/u/YDj8/M/pXvdFK47Hy14i+BHi3RIXnsUh1eFRk/ZGPmAf7hwT9FzXm0kbxSNHKrI6EqysMFSOoIr7urzb4qfCuz8Y6bLqOlQpBrkKFldRgXQH8D+/o34HjoXCx8sUU6SN4pGjlVkdCVZWGCpHUEU2mIKKKKACun8KfDvxL4y+fRtPY2wOGu5j5cQPf5j1+gya6z4O/C9PF902sa4jf2RaybVi5H2qQc4z/AHR39enrX0zBBDa26QW0SQwxqFSONQqqPQAdBSuOx4FZ/s1XzxA6h4kt4JO6wWjSj8yy/wAqq6r+zhrdvCz6RrNnfMOdksbQlvpyw/Mivouii4WPiPXvDeseGL/7Hr1hNZTclRIPlceqsOGHuCay6+3fEHh3S/FGkS6brVqlxBIOMj5oz/eU9iPWvknx94Ku/AvieTTbhjNbuPMtbjbgSxn+o6Ef0IpiOYooooAKKK1vDHhy98V+IrXR9MXM1w2C5HyxqPvO3sBQBV0vSdQ1vUEsdIs5ry5k+7FChY49fYe54r1LRv2dvEV5EsmsahZ6Zu/5ZjMzr9cYX8mNe4+DvBWk+CdGSx0mEGQgGe5ZR5k7epPp6DoK6GlcdjwG4/ZpuViJtfE8UsnZZLIoPzDn+VcB4r+FPirwhC9zfWQubJOWu7RvMRR6sMBlHuQBX17SMoZSrAEEYII60XCx8IUV7d8afhTb6ZBJ4o8NQCK23ZvbSNfljyf9YoHRc9R26jjOPEaYgooooAKKK+i/g58KLbTtPt/EniO3Wa/nUSWtvKuRbqejEH+M9fb69ADzTwx8F/F3iWFLk2qaZaOMrLfEoWHqEALfmAD612kf7NExizL4pjWT+6tgWH5+YP5V75RSuOx8ya7+z94p0yFptKmtdWRRnZG3lyf98twfwOa8wu7O5sLuS1voJLe4ibbJFKhVkPoQeRX3VXG/EP4caZ470llkRLfVIlP2a8C8g/3W9VP6dR7lwsfINFWdR0+60nU7jT9QiaG5tpDHLG3Zgf8APNVqYgooooAK3fDPgzX/ABfcmLQNOkuVQ4kmOFjj/wB5zwD7dfat74WfDqTx5rrG6Lw6TZ4a5lXguT0jU+p7nsPwr6r03TLLR9PisdLtY7W1hXakUS4A/wAT79TRcLHgmn/s26pLEDqniC1tXI5WCBpsfiStGofs26pFETpfiC1unA4WeBoc/iC1fQtFK47HxZ4m8Ga/4QuRFr+nSWyucRzDDRyf7rjgn26+1YVfc2paZZaxp8tjqlrHdWsy7XilXIP+B9+or5U+Kfw6k8B66ptS82k3mWtpW5KEdY2PqOx7j8adxWOEqK6/49m/D+dS1Fdf8ezfh/OgDOzRRRSGFFFFABRRRQBpxf6lP90Vr+GdGbxD4p03SUJX7ZcpEzD+FSfmP4DJrIi/1Kf7orvPgzs/4W9ofm/d3TYz6+S+P1xTEfWVrbQ2VpDa2saxQQIscaL0VQMAD6AVLRRUlBRRRQAV4t+0Z4djuNB0/wAQRIPPtZfs0rDqY3yVz9GH/j5r2muA+N+z/hUOrb/vboNn185P6ZoA+TqKKKokK+pfgT4dj0b4dRX7IBc6rIZ5G77ASqD6YBP/AAI18tV9n/D/AGf8K38O+V93+zLfOPXy1z+uaTGjoaKKKQwooooAzPEeiQeI/Dd/pF2AY7yFo8n+Fv4W+oOD+FfE1xBJa3MsEy7ZInKOvoQcEV92V8VeNNn/AAnuv+V/q/7TuduPTzWxTQmYlFFFMR6X8CPDset/ERLu5QPDpcRucHoZMhU/Ikt/wGvqWvBP2aNn2jxJn/Wbbbb9My5/pXvdJjQUUUUhhRRRQB8tfHfw7HonxEe7tkCQ6pELnA6CTJV/zIDf8CrzSvdf2l9n2jw3j/Wbbnd9MxY/rXhVUSFSW8El1cxQQruklcIi+pJwBUdbfgvZ/wAJ7oHm/wCr/tO23Z9PNXNAH2F4c0SDw54bsNItABHZwrHkfxN/E31JyfxrTooqSgooooAK80+O3h2PWfh1LfqgNzpUgnjbvsJCuPpgg/8AARXpdc98QNn/AArfxF5v3f7MuMZ9fLbH64oA+MKKKKokK+h/2c/DsdvoOoeIJUHn3Uv2aJj1EaYLY+rH/wAcFfPFfWPwQ2f8Kh0nZ97dPv8Ar5z/ANMUMEd/RRRUlBRRRQBFdW0N7aTWt1GssE6NHIjdGUjBB+oNfFHibRm8PeKdS0lyW+x3LxKx/iUH5T+Iwa+3K+SPjNs/4W9rnlfd3Q5x6+Smf1zTQmcNRRRTEdb8L/Dsfif4i6XYXKB7ZZDPOp6MiDdg+xIA/GvsOvmb9nbZ/wALIut/3v7Mk2fXzI/6Zr6ZpMaCiiikMKKKKAPnj9ozw7Ha63p2v26BftqGC4I7umNpPuVOP+AV4tX0n+0ds/4QLTs/6z+012/TypM/0r5sqkSwooooA+w/hh4dj8M/DvS7QIFmmiFzcHuZHAY5+gwv/Aa62mQ7Ps8flf6vaNuPTHFPqSgooooAK5L4n+HY/E3w71S0KBpoYjc257iRAWGPqMr/AMCrraZNs+zyeb/q9p3Z9Mc0AfCVRXX/AB7N+H86lqG6/wCPZ/w/nVEmfRRRSGFFFFABRRiigDTi/wBSn+6K1/DOst4e8U6bqyAt9juUlZR/EoPzD8RkVkRf6lP90fyp9MR912tzDe2kN1ayLLBOiyRuvRlIyCPqDUtfPvwW+K1vpkEfhfxLOIrbdiyu5G+WPJ/1bE9Fz0PboeMY+gVYMoZSCCMgjvUlC0UUUAFeLftGeIo7fQdP8PxOPPupftMqjqI0yFz9WP8A44a9I8Y+NdJ8E6M99q0wMhBEFsrDzJ29APT1PQV8jeJ/Ed74r8RXWsam2ZrhshAfljUfdRfYCmhMyaKKKYgr6l+BPiKPWfh1FYM4NzpUhgkXvsJLIfpgkf8AATXy1XT+AfGt34F8Tx6lbqZrdx5d1b7sCWM/1HUH+hNAH2TRWZ4f8RaX4o0iLUtFukuIJBzg/NGf7rDsR6Vp1JQUUVHPPDa27z3MqQwxqWeSRgqqPUk9BQBQ8R63B4c8N3+r3ZAjs4Wkwf4m/hX6k4H418TXE8l1cyzzNuklcu7epJyTXp/xi+KCeL7pdH0N2/si1k3NLyPtUg4zj+6O3r19K8sqkSwooooA9L+BHiKPRPiIlpcuEh1SI22T0EmQyfmQV/4FX1LXwjHI8UiyRMyOhDKynBUjoQa+pfhX8VLPxhpsWnarMkGuQoFZGOBdAfxp7+q/iOOiY0ek0UUUhhRRXm3xU+Kln4P02XTtKmSfXJkKqinItQf439/RfxPHUA8j+O/iKPW/iI9pbOHh0uIW2R0MmSz/AJEhf+A15pTpJHlkaSVmd3JZmY5LE9STTaokKkt55LW5inhbbJE4dG9CDkGo6KAPt3w5rcHiPw3YavaEGO8hWTA/hb+JfqDkfhWnXzF8HfignhC6bR9cdv7IupNyy8n7LIeM4/unv6dfWvpmCeG6t0ntpUmhkUMkkbBlYeoI6ipKJKKKKACvNPjt4ij0b4dS2CuBc6rIII177AQzn6YAH/AhXceIPEWl+F9Il1LWrpLeCMcZPzSH+6o7k+lfJPj7xrd+OvE8mpXCmG3QeXa2+7IijH9T1J/oBTQmcxRRRTEFfQ/7OfiKO40HUPD8rjz7WX7TEp6mN8BsfRh/4+K+eK1vDHiO98KeIrXWNMbE1u2ShPyyKfvI3sRQB9tUVz3g7xrpPjbRkvtJmAkAAntmYeZA3oR6eh6GuhqSgoopGYKpZiAAMkntQBHdXMNlaTXV1IsUECNJI7dFUDJJ+gFfFHibWW8Q+KdS1ZwV+2XLyqp/hUn5R+AwK9a+NPxWt9Tgk8L+GpxLbbsXt3G3yyYP+rUjquep79BxnPiNNCYUUUUxHW/C/wARR+GPiLpd/cuEtmkME7HoqONuT7AkH8K+w6+D6+i/g58V7bUdPt/DfiO4WG/gUR2txK2BcKOikn+MdPf69Uxo9looopDCiiuN+IfxH0zwJpLNI6XGqSqfs1mG5J/vN6KP16D2APKv2jPEUd1renaBbuG+xIZ7gDs742g+4UZ/4HXi1WdR1G61bU7jUNQlaa5uZDJLI3dif88VWqiQooooA+w/hh4ij8TfDvS7sOGmhiFtcDuJEAU5+ow3/Aq62vkr4WfEWTwHrrC6DzaTeYW5iXkoR0kUeo7juPwr6r03U7LWNPivtLuY7q1mXcksTZB/+v7dRSGWqKKKQwrkvif4ij8M/DvVLsuFmmiNtbjuZHBUY+gy3/Aa6PUtTstH0+W+1S5jtbWFdzyytgD/AOv7dTXyp8U/iLJ4811Rah4dJs8rbRNwXJ6yMPU9h2H40xHCVFdf8ezfh/Opaiuv+PZvw/nTEZ1FFFIYUUUUAFH1oxR9aANOL/Up/uj+VPpkX+pT/dH8qfTEFdn4U+K3irwhCltY3oubJOFtLtfMRR6KchlHsCBXGUUAe5W/7S1ysQF14Yilk7tHelB+RQ/zrL1n9onxFeRNHo+n2embv+WhzM6/TOF/NTXkNFAFzVNW1DW9Qe+1e8mvLmT70szljj09h7DiqdFFABRRRQAUUUUAamg+JNY8MX/2zQb+aym4DGM/K49GU8MPYg16jpX7R+t28Kpq+jWd8w43xSNCW+vDD8gK8aooA9vvP2lb54iNP8N28EnZp7tpR+QVf515v4r+IniXxl8ms6gxtgcraQjy4ge3yjr9Tk1zFFABRRRQAUUUUAFOjkeKRZImZHQhlZTgqR0INNooA9L8O/HfxbokKQXzw6vCowPtanzAP98YJ+rZrqv+Gl5fKx/wiyeZ/e+3nH5eX/WvCqKAPS/EXx38W63C8Fi8OkQsMH7Ip8wj/fOSPquK82kkeWRpJWZ3clmZjksT1JNNooAKKKKACiiigArp/CnxE8S+Dfk0bUGFsTlrSYeZET3+U9PqMGuYooA9vs/2lb5IgNQ8N288ndoLtoh+RVv51V1X9o/W7iFk0jRrOxY8b5ZGmK/ThR+YNeNUUWC5qa94k1jxPf8A2zXr+a9m5CmQ/Kg9FUcKPYAVl0UUAFFFFABRRRQBc0vVtQ0TUEvtIvJrO5j+7LC5U49Pcex4r1LRv2ifEVnEsesafZ6nt/5aDMLt9cZX8lFeQ0UAe5XH7S1y0RFr4Yiik7NJelx+QQfzrgPFfxW8VeL4Xtr69FtZPw1paL5aMPRjksw9iSK4yigAooooAKKKKACiiigD0Dwx8aPF3hqFLY3SanaIMLFfAuVHoHBDfmSB6V2kf7S8wixL4WjaT+8t+VH5eWf514XRQB6rrv7QPinU4Wh0qG10lGGN8a+ZJ/303A/AZrzC7vLm/u5Lq+nkuLiVt0ksrlmc+pJ5NQ0UAFFFFABRRRQAVu+GfGev+ELky6BqMlsrnMkJw0cn+8h4J9+vvWFRQB7Xp/7SWqRRAap4ftbpwOWgnaHP4ENRqH7SWqSxEaX4ftbVyOGnnabH4ALXilFFgubvibxnr/i+5Euv6jJcqhzHCMLHH/uoOAffr71hUUUAFRXX/Hs34fzqWorr/j2f8P50AZ1FFFIYUUUUAFFFFAGnF/qU/wB0U+mRf6lP90U+mIKKKUAkgAZJ6CgBKK2Lfwh4lu4hJa+HtVnjPIeOykYfmFqjfaZf6ZIE1KxubRz0W4haMn8CKAKtFFFABRRRQAUUUUAFFFXrDRdV1XP9l6ZeXuOD9nt2k/8AQQaAKNFat54W8QadEZNQ0LUrWMcl57ORAPxIrKoAKKKKACiiigAooooAKKs2mn3l82LO2lmx1KKSB+NX/wDhE9b27vsJx/10TP5Zp2bMJ4mjTdpzSfm0Y9FWbvT7yxbF5bSw56F1IB/Gq1BrGUZq8XdBRRRSKCiiigAooooAKKdsb0oKsO1OzFcbRRRSGFFFFABRRRQAUUVasdMv9TkKabY3N246rbwtIR+AFAFWiti48IeJbSIyXXh7VYIxyXkspFH5layCCCQRgjqKAEooooAKKKKACiiigAopyRvLIEjVndjgKoyTWxH4M8UTReZF4b1d4+u9bGUj89tAGLRU93ZXVhN5N9bTW0v9yaMo35GoKACiiigAooooAKKKKACitGw8O61qib9M0e/vE/vW9q8g/QGi/wDDutaWm/U9Hv7NP71xavGP1AoAzqKKKACorr/j2b8P51LUV1/x7N+H86AM6iiikMKKKKACiiigDTi/1Kf7op9Mi/1Kf7oqxa20t5dw2tshkmmdY40HVmJwB+ZpiOn8AfD7UvHusG3tP9HsoSDc3jLlYx6Ad2PYV9OeE/h34c8HW6DS7CN7pR815OoeZj67v4fouBVvwZ4WtfB3hW00ezAJjXdPIP8AlrKfvN+fT0AA7Vu0hhUN3Z2t/bNb31tDcwPw0U0YdW+oPFTUUhniHxG+BNtLbTar4JjMM6Dc+m5ykg7+WTyD/s9D2x38AdGjdkdSrKcMpGCD6V93V83/AB/8GxaRr9v4hsI9kGpkrcKOizjnd/wIc/VWPemhM8fooopiCp7KyudRvobOxhee5ncJHEgyzMegFQV79+zz4NiW0uPFl7Humdmt7LP8Kjh3H1Py/g3rQBseAfgZpOiW8V94qjj1PUWAb7O4zBAfTH8Z9zx6DvXq8UMcEKxQRrHGgwqIoAUewFPoqSgrifGXwo8NeMIHeS1TT9QPK3tqgVs/7S9H/Hn0IrtqKAPizxd4R1PwXrsmmavHhh80UyfcmTsyn+nasKvrr4r+DYvGHgi5RI86hYq1xZsOu4DJT/gQGPrg9q+RaokKKKKACuv8NeEluIkvdUU+W3McPTcPU+3tWN4a01dU1uKKUZhjHmSD1A7ficCvUQMDA4FawjfVnzWdZjOjahSdm92NjjSKMJEioijAVRgD8KdRRW58Ze+rGyRpLGUlRXRhgqwyD+FcT4l8JLbxPe6Wp8teZIeu0eo9vau4oIyMHkVMopnZhMZVwlTmg9Oq6M8YorW8S6aul63LFEMQyDzIx6A9vwORWTXM1Z2P0ejVjWpqpHZ6hRRRSNRyruNShQvShRtXFLWiVjNu4UUUVQhrIG9jURGDg1PTJBxmpkikyKiiisywpyI0jqiKWZjhVAySfSm17B8APBsWr6/ceIb+PfBphC26no0553f8BHP1ZT2oA6H4c/Am2itodV8bRmadxuTTc4SMdvMI5J/2eg757e02lna2FstvY20NtAnCxQxhFX6AcVNRUlBXL+LPh34c8Y27jVLCNLph8t5AoSZT67v4vo2RXUUUAfHfj/4fal4C1gW93/pFlMSba8VcLIPQjsw7iuTr7T8Z+FrXxj4Vu9HvAAZF3QSH/llKPut+fX1BI718Y3VtLZ3c1rcoY5oXaORD1VgcEfmKokiooooAK774afCy+8eXLXNw72WjwttkuQuWkb+4me/qeg9+lcp4c0SfxJ4ksNHtTiS8mWPdjOwd2+gGT+FfaGjaRZ6Do1rpemReVa2sYjjXvj1PqSeSfU0MEUPDngzQPCdqsOh6bDbsBhpiu6V/95zyfp09q3KKKkop6npOn6zZta6tZQXkDdY54w4+oz0PvXgvxO+CA0i1n1vweJJLWPLz2BJZol7sh6sB3B5Hqe30NRQB8H0V6F8ZvBsXhLxuz2Efl6fqSm4hUdI2zh0H0PI9AwFee1RIUUUUAaGh6HqHiPWYNL0i3ae6nbCqOgHdiewHUmvpnwP8F/D/AIWgjuNUhj1fU8AtLOmY4z6Ih4/E5P06VS+BHg2LRPCC67cx/wCn6qNyseqQA/Ko+uN3vlfSvVKQ0IqhVCqAABgADpQyhlKsAQRggjrS0UhnnHjj4L+H/FMElxpcMekanglZYExHIfR0HH4jB+vSvmbXND1Dw5rM+l6vbtBdQNhlPQjswPcHqDX3BXlfx38Gxa34QbXbaP8A0/ShuZh1eAn5lP0zu9sN60xHzHUV1/x7N+H86lqK6/49m/D+dMRnUUUUhhRSUUALRRRQBpw/6lP90fyrtvhFZpffFjQopRkLM0oz6pGzj9VFcTF/qU/3R/Kus+Gmqpo3xL0O9mbbGLoRux6KHBQn/wAepiPseiiipKCiiigArzr462aXPwnv5XGTazQyp7EyBP5Oa9FrzD4/6qll8NGsi37zULqONV7kKd5P/jo/MUAfL1FFFUSFfZPw2s0sfhl4eiiGA1hFKcerrvP6sa+Nq+v/AIT6qmrfC3RJEbLQW4tnH90x/Jj8gD+NJjR2NFFFIYUUUUAFfEnimzTTvGGs2UQxHbX88SgdgsjAfyr7YmljgheaZgkcalnY9FAGSa+INav/AO1df1DUMY+13Uk+D/tMW/rTQmUaKKKYjsfh+gM19J/Eqoo/Hd/hXbVwHgS7EWrTW7HHnx5X3K8/yJrv66KfwnwGdxksbJvrb8gooorQ8YKKKKAOJ+ICATWMn8TK6n8Nv+NcdXUeO7sS6tDbqc+RHlvYtz/ICuXrmn8R+i5TGUcFTUv61YUq/eH1pKBwak9MsUUUVqZBRRRQAUjfdP0paa5whpPYZDRRRWRoFfVfwKs0tvhPYSoMG6mmlf3IkKfyQV8qV9Q/ADVUvfhotkG/eafdSRsvcBjvB/8AHj+RpMaPT6KKKQwooooAK+Qvi7ZpY/FjXYohgNMspx6vGrn9WNfXtfHHxL1VNZ+JeuXsLbozdGNGHRggCA/+O00JnLUUUUxHqP7Plmlz8TWlcZNrYSyp7Esifyc19P18rfAnVU034pW0crbVvreS2BPqcOB+JQD8a+qaTGgooopDCiiigDxz9pCzR/B+k3pH7yG/8pT7PGxP/osV85V9B/tJaqiaPo2khsyS3D3LL6BV2g/jvP5GvnyqRLCiiigD7n06zTTtLtLKIYjtoUiUDsFUAfyqzWZ4a1VNb8L6ZqcTblurWOQ+xKjI/A5FadSUFFFFABVbUbNNR0u7spRmO5heJge4ZSD/ADqzWZ4l1VNE8L6nqcrbVtbWSQe5CnA/E4FAHxFUV1/x7N+H86lqK6/49n/D+dUSZ1FFFIYGiiigAooooA04v9Sn+6KeDg5FMi/1Kf7op9MR9afCfx9D418LRx3Mq/2vZII7qMn5nA4EvuG7+hz7V3lfD2i63qPh3VodS0e6e1uoTlXXuO4I6EHuDXvvhL9oTSL23jg8W276ddAANcwoZIX98DLL9OfrSsO57JRXN2/xE8HXMQkj8T6UqnnEl2kZ/JiDWXrPxi8E6NEzHWEvpB0isVMpb8R8v5kUhnbSSJDE0krqkaAszMcBQOpJr5P+L3jpfGvi3Fi+7S9PBhtT2kJPzSfiQMewFWfiF8Y9W8ZxyafYxnTdIb70KtmSb/fb0/2Rx65rzimhBRRRTEFetfAvx9F4d1iXQNWmWLT9RcNFK5wsU2Mc+gYYGfUL715LRQB94UV80+AfjpqHh23i03xLFJqenxgLHMhHnxL6c8OPYkH37V7LpXxY8E6tCrxa/bW7Hql2fIK+3zYH5E1JR2NFcxefEnwZYxGSbxNprAdoLhZj+SZNeaeMv2hoFge08FWzvMePt10mFX3VOp+rY+hoA2Pjn4+i0Tw/J4c06ZW1HUU2z7TzBCeufdumPQk+lfNNT3t7c6jezXl/PJcXMzF5JZGyzE9yagqiQooooAltbmSzuo7iBtskbBlPvXqmkarBq9itxAfm6SJ3RvSvJqtWGo3Wm3Ins5TG/f0YehHerjLlPJzLLljYJrSS2/yZ67RXJWPjy3dQuo27xP3eL5lP4dR+taX/AAmGibc/azn08p8/yrfmifGVMtxdOXK6b+Sv+Rt1R1fVYNIsWuJz83SNO7t6VgX3jy3RSunW7yv2eX5VH4dT+lcff6jdalcme8lMj9vRR6AdqiVRLY9HBZLWqyUq65Y/i/8AIiurmS8upLidt0kjFmPvUVFFYH26SirIKKKKBkkbdj+FSVXp6yEdeatS7kNEtFN8xaDIvbmquhWY6onbceOlIzlvYU2obuUkFFFFSUFd98IfHS+CvFuL59ul6gBDdHtGQflk/Ak59ia4GigD7ujkSaJZInV43AZWU5DA9CDTq+Vvh78Y9W8GRx6ffRnUtIX7sLNiSH/cb0/2Tx6Yr3HRvjF4J1mJWGsJYyHrFfKYiv4n5fyJpDO4orm7j4ieDraIySeJ9KZRziO7SQ/kpJrz/wAW/tCaRZW8kHhK3fUboghbmZDHCnvg4Zvpx9aQzqPix4+h8FeFpI7aVf7XvUMdrGD8yA8GX2C9vU496+SycnJq/rWt6j4i1abUtYunurqY5Z27DsAOgA7AVQqiQooooAnsryfT7+C8s5DFcW8iyxOOqspyD+Yr7F8CeM7Pxv4Yg1K1ZEuAAl1bg8wydx9D1B7j8a+M62vC/izV/B+rrqOh3PlS42yIwykq/wB1l7j9R2xQB9rUV5T4Y+P/AIb1SFI9fWTR7rGGJUyQsfZlGR+I49TXaR/EHwfLF5i+KNIC+jXsan8ic1JR0VV7+/tdL0+e+1CdLe1t0LyyucBQK4bXfjZ4M0WFvI1BtTnA+WKyQtk/75wuPxP0rwbx98UdZ8dzeTPiy0xH3RWUTZGexdv4j+QHYUxXKHxB8Xy+NvGFzqrBktxiK1jJ+5Eucficlj7k1zFFFMQUUUUAe8fALx9FHCfCOqzKh3GTT3c8Nk5aL65yw9cn2r3ivhFHeKRXjZkdSCrKcEEdwa9r8D/tAz2UEdj4zgkvEUBVvoAPMA/2143fUEH2JpWHc+g6K5TT/ih4K1OISQeJLGPI+7cyeQR+D4o1D4oeCtMiMk/iSxkwPu20nnk/gmaQzq68H+Pvj6KSEeEdKmVzuEmoOh4XBysX1zhj6YHvVTxx+0DPewSWPgyCSzRgVa+nA8wj/YXnb9SSfYGvFHd5ZGeRmd2JLMxyST3Jp2FcbUV1/wAezfh/Opaiuv8Aj2b8P50xGdRmiikMKKMUUAFFFFAGnF/qU/3RT6ZF/qU/3RT6YgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKiuv+PZvw/nUtRXX/AB7N+H86AM6iiikMKKKKACiiigDTi/1Kf7op9Mi/1Kf7op9MQUVNaWlxf3kVrZQSXFxMwSOKNSzOT2AFe0eEv2d7i6t47rxfftZhgD9jtMNIPZnOQD7AH60AeI0V9XW/wN8BQxBZNJluG/vyXkoJ/wC+WA/SsvWf2e/Ct9E39kz3mlzfwkSecg+qtyf++hRcdj5lorr/ABv8NNe8DTb9QiFxYM2I72AExk9ge6n2P4E1yFAgooooAKKKKACiu+8C/CHXvGqJeHGm6W3S7nQkyD/YX+L65A969j0r4AeDbKFRfrealJ/E0s5QE+wTGPzNFwsfL1FfVd58CvAlzEVh064syf44LuQkf99lh+leaeMvgBqukQPeeF7ltWgXlrZl2zqPbHD/AIYPoDRcLHj9FOdGjdkdSrKcMpGCD6U2gAooooAKKK0dI0S71mcpbKAi/flb7q/4n2p7mdSpClFzm7JGdRXo9j4M0u0UG4VrqTu0hwPwA/rmtL+xNL27f7Otcf8AXFc/nitPZs8GpxBh4ytCLf4Hk1Fej33gzS7tSbdWtZOzRnI/EH+mK4nV9Eu9GnCXKgo33JV+63+B9qmUWjvwmZ4fFvlg7PszOoooqD0wooooAKKUAk4HJqwlt3kP4CqUW9iW0itRV4RIP4R+VIYYz/CB9Kv2bJ50UqKmktyvK8ioazaa3LTT2CiiikMKKKKACiuv8EfDTXvHM2/T4hb2CtiS9nBEYPcDux9h+JFe16N+z34VsYl/tae81Sb+ImTyUP0VeR/30aAPmWivq64+BvgKaIrHpMtu39+O8lJH/fTEfpXn/i39ne4tbeS68IX7XgUE/Y7vCyH2VxgE+xA+tFwseI0VNd2lxYXktrewSW9xCxSSKRSrIR2INQ0AFFFFABRRV3SdI1DXdSi0/SLSS7upT8kUYyT7+w9zwKAKVFe+eGP2c4fJSfxbqbmQjJtbHAC+xcg5/AD6mu0j+B/gFItraNJI399rybP6MB+lFwsfJ9FfSOu/s7+H7yFm0G+utNnx8qyHzoz7YOGH1yfpXiHi/wAD654J1AW2t222NyRDcx/NFNj+63r7HB9qAOdooooAKKKKACiivT/A/wAD9b8UQR3+rSf2Pp7gMhkTdNKPVU4wPc/UA0AeYUV9T6f8BfBFnEFurW6v2xy890y5/BNtGofAXwReRFbW1urBscPBdM2PwfdSuOx8sUV6f44+B+t+F4JL/SZP7Y09AWcxptmiHqyc5HuPqQK8wpiCorr/AI9m/D+dS1Fdf8ezfh/OgDOooopDCiiigAooooA04v8AUp/uin0yL/Up/uj+VdL4B0ZNf+IGjabOu+Ga6Uyqf4kX5mH4hTTEe+/Bj4cw+GdBi1vU4AdYvo96lhk28RGQo9GI5P5djn1GiipKCiiigCvf2FrqlhNZahAlxbToUkikGQwNfI3xL8ESeBvFstkm57CcedZyMckxk/dJ9VPB/A96+wa8p/aE0ZL74fw6lt/faddKQ3oj/Kw/PZ+VNCZ8y0UUUxBXo/wc+HqeM/EL3mqR7tI08hplzjzpD92P6cZPtgd684r64+DujJo3wt0oKuJLxDdyn+8XOQf++do/Chgjto40hiWOJFSNAFVVGAoHQAU6iipKCiiigDxD47fDmGWxk8W6NAEuIiP7QjQYEingSY9QevqOe3Pz9X3VeWkN/Yz2d0m+C4jaKRT/ABKwwR+Rr4f1OxfTNXvLCQ5e1neFj6lWI/pTQmVaKKKYizp9lJqN/DaQ/flbGfQdz+Ar1awsYdOso7a2XaiD8WPcn3ri/AVsJNRubgjJijCj2LH/AOtXeVvTWlz4nPsTKddUFtH83/wAooorU+dCq9/Yw6jZSW1yu5HH4qexHvViikOMnCSlF2aPIdQspNOv5rSb78TYz6jsfxFVq6vx7bCPUba4AwZYyp9yp/8Ar1ylc0lZ2P0zBV/rGHhVe7X49QoopVGWA9TUnWWbePau49T09qmo6UV1pWVjmbuwooopgFVbiPa24dDVqmTDMLfTNRJXQ4uzKVFFFcx0BXX/AA08ESeOfFsVk+5LCAedeSKcERg/dB9WPA/E9q5Cvpr9nvRksfh/NqW399qN0xLeqJ8qj89/50AenWFha6XYQ2WnwJb20CBI4oxgKBViiipKCiiigDy74z/DmHxNoMut6ZABrFjHvYqMG4iAyVPqwHI/LuMfMFfeFfGPj7Rk0D4gazpsC7IYbpjEo/hRvmUfgGFNCZztFFFMQ+KKSeZIoUZ5JGCoqjJYngAV9cfDL4fWvgXw6iyRo+rXKBryfqc9fLU/3R+p5+ngnwT0ZNY+KVgZl3R2KPdke6jCn8GZT+FfWFJjQUUUUhhWbr+gad4m0WfS9YgE9tMMEd0PZlPYjsa0qKAPirxf4Yu/B/ii70a9+ZoGzHIBxLGeVYfUfkcjtWJXvn7SWjIbfRtbRcSB3tJG9QRvQfhh/wA68DqiQooooA9j+Bnw5h1y6fxLrcAlsrWTZaQuMrLKOSxHdV4+p+lfRtYvg7Rk8P8AgvSdLjXb9ntUD+7kZc/ixJ/GtqpKCiiigAr5y+Ofw5h0O6TxLokAisrqTZdwoMLFKeQwHZW5+h+tfRtYvjHRk8QeC9W0uRd32i1cJ7OBlD+DAH8KAPimorr/AI9m/D+dS1Fdf8ezfh/OqJM6iiikMKKKKACiiigDTh/1Kf7o/lXc/B24S2+LmhSSnCmSSMZ9WidR+pFcNF/qU/3R/Krmm38+lapa6haNtntZkmjPoykEfypiPueiszw7r1n4m8PWer6c4aC6jD4zko38Sn3ByD9K06koKKKKACvPfjlcJD8I9Tjc/NPJBGnufNVv5Ka9Cr59/aI8WxXV7ZeGLOQOLVvtN3tPSQjCL9QpJ/4EKAPEaKKKokK+zPh3cJc/DXw7JEcqNOhjOPVUCn9Qa+M6+jP2e/FsV74dn8NXMgF1YO0tupP34WOTj/dYnP8AvCkxo9kooopDCiiigAr4n8X3CXfjfXLmI5jm1G4kUj0MjEV9YfETxZD4O8FXuotIFumQw2iZ5aVhhcfT7x9ga+OCSSSTknqaaExKKKKYjsPh/KBc3sP8TIjD8CR/7NXb15ToWpf2VrENy2fLztkA7qev+P4V6ojrJGrxsGVgCpHQiuim9LHwue0JQxXtOkl+Wg6iiitDwQoopruscbPIwVVBLE9AKA3OK+IEoNzZQ/xKjsfxIH/stcfWjrupf2rrE1yufLztjB7KOn+P41nVyyd3c/SsvouhhYU5bpfnqFOQ4dT6Gm0UjuNCimQvvjHqODT66k7q5zPQKKKKYBTZTiJvpTqguX4CD6mpk7IcVdlaiiiuU6Ar6u+Btwk3wj0yND80Ek8b+x81m/kwr5Rr279nfxbFa3t74YvJAgum+02m49ZAMOv1KgH/AICaGCPoKiiipKCiiigAr5F+MVwlz8XNdkiOVEkcZx6rEin9Qa+p/EWvWfhnw9eavqLhYLWMvjOC7fwqPcnAH1r4r1K/n1XVLrULtt091M80h9WYkn+dNCZWooopiPVP2ebhIfiVPG5+afTpY09zvjb+Smvpyvirwd4hfwr4w03WUBYWswMir1aM/K4/FSa+z7O8t9QsYbyylWa3nQSRSIch1IyCKTGiaiiikMKKKKAPH/2j7hF8EaZbE/vJNREij2WNwf8A0IV8316h8d/FsXiDxomm2UgktdJRoiynIaYn58fTCr9VNeX1SJYUUUUAfdVpcJd2UFzEcxzRrIpHoRkVNXnPwT8WxeIvAVvYySA32kqLaVCeTGP9W302jH1U16NUlBRRRQAVDd3CWllPcynEcMbSMT6AZNTV5z8bPFsXh3wFcWMcgF9qym2iQHkRn/WN9Npx9WFAHyrUV1/x7N+H86lqK6/49n/D+dUSZ1FFFIYUUZooADQKKBQBpxf6lP8AdFPpkX+pT/dFPpiPQPhf8ULrwHfNbXavc6NcPumgU/NE3Teme/qO+K+ndB8RaT4m01b7Q76K7gYDOxvmQ+jL1U+xr4iqzYale6VdLc6ZeT2c69JYJCjD8RRYLn3PRXyLb/GLx7bRCOPxDKyjjMkEUh/NlJrL1nx94q1+JotW128nhb70QfYjfVVwD+VKw7nvvxG+M+l+GbabT/D80WoawRtDIQ0VufVj0LD+6Pxx0PzNd3dxf3k13ezPPcTuZJJHOWdickk1DRTEFFFFABV/RNav/Dus2+qaTOYLq3bcjDofUEdwRwRVCigD608A/FjRPGtvFbySpYavgB7SVsB29YyfvD26j0713lfB4ODkV1OlfEvxlo0KxWHiG8WNeFSVhMFHoA4OKVh3PsesLxT4z0PwdYG61y9SIkZjgU7pZf8AdXqfr0Hc18v3nxd8d30Rjm8RXCg94I44T+aKDXI3N1PeXDz3c8k8znLSSuWZj7k8miwXOn+IPj/UPHuufabkGCygytrahsiNT1J9WOBk/wCFcnRRTEFFFFABXSeHfFT6Wotb0NLa5+Uj70f+I9q5uimm09DnxGHp4mn7Oqro9ftL+1v4vMs50mX/AGTyPqOoqxXjSO8bBo2ZGHQqcGrX9rajt2/2hdbfTzmx/OtfaHzVTh1837upp5o9Tu7+1sIvMvJ0hX/aPJ+g6muE8ReKn1RTa2QaK1z8xP3pP8B7Vzru8jFpGZ2PUscmm1MptnoYLJqOGkqk3zSX3L5BRRRWZ7oUUUUAORyjZWraTK/fB9DVKirjJxJlFM0KOlUQ7DoxH40hYnqSfqav2hHsyzJcBeE5Pr6VWJJOT1pKKzlJyLUUgoooqSgqa0u7iwvIbuymeC4gcSRyIcMjA5BBqGigD6f+HPxn0vxNbQ6f4gmi0/WANpZyFiuD6qegY/3T+Geg9Rr4ProtG8feKtAiWLSddvIIV+7EX3ov0VsgflSsO59nVma94i0nwzprX2uX0VpAoON7fM59FXqx9hXyxcfGLx7cxGOTxDKqnjMcEUZ/NVBrkr/Ur3VbprnU7ye8nbrLPIXY/iaLBc7f4ofFC68eXy21or22jW77oYGPzSt03vjv6DtmvP6KKYgooooAK9W+FHxebwiq6N4gMk2jliYpFG57Unrgd0J5x1HUeleU0UAfc2m6pY6xYx3ulXcN3bSD5ZYXDA+3HQ+3WrVfDula3qmh3Hn6PqFzYynq1vKU3fXHX8a6qP4y+PoovLXxDIV9WtoWP5lM0rDufW7uscbPIwRFBLMxwAPU14x8TvjbaWNrPo/g25FxevlJb+M5jhHfYf4m9xwPc9PEta8ZeI/ES7Na1m8u4858p5CI/wDvgYH6ViUWC4pJZizEkk5JPekoopiCiiigDc8I+LdS8GeIItV0l/mX5ZYm+5Mh6q3+eDg19U+C/iNoPje0U6bciG9C5lsZmAlQ45wP4h7j8cdK+OqdHI8UiyROyOpyrKcEH1BoA+7qK+PtP+KvjfTIhHa+IrplUYAnCzY/FwaNQ+KvjfU4jHdeIrpVYYIgCw5/FAKVh3Ppbxp8RtB8EWjHUrkTXpXMVjCwMrnHGR/CPc/hnpXyt4u8W6l4z8QS6rqz/M3yxRL9yFB0Vf8APJyaxZJHlkaSV2d2OWZjkk+pNNpiCorr/j2b8P51LUV1/wAezfh/OgDOoo70UhhRRRQAUGjNFAGnF/qU/wB0fyp9Mh/1Kf7o/lT6YgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKiuv+PZvw/nUtRXX/AB7N+H86AM7vRR3opDDNFJRQAuKMUUUAacX+pT/dH8qfTIv9Sn+6KfTEFbfh7wd4g8VSlNB0qe7CnDSqNsan0LnCj867v4Q/CgeLnGt68rLo8TlY4gcG6YdRnqEHQkdTwO9fSlnZ22n2cVpYwR29vCu2OKJQqoPQAUrjsfNNv+zz4xmiDSXGlW7f3JLhyR/3yhH61l6z8E/G2jxNKNOTUI16mxlEh/75OGP4CvrCii4WPhKWKSCVopo2jkQ7WRxgqfQimV9d/EH4ZaR46sZHaNLXVlX9zeqvPHRX/vL+o7e/yjq+k3mhaxc6ZqcRhurWQxyIex9Qe4I5B7g0xFKiiigAoora8J+F7/xh4it9I0tR5svzPI33YkH3nPsP1OB3oAzLOyutQu47Wwtpbm4kOEihQuzH2A5NegaV8CfG2pQrJLa22nq3IF3Pg/koYj8a+hfBngTRfBGmrb6Tbg3DKBPeOMyTH3PYeijgfrXSUrjsfMF5+z54ztoi0LabeEfwQXLAn/vtVH61wOt+HNY8N3Yttd064sZD93zUwH91bow+hr7dqlq+jadr2myWGsWcV5ayfejlXIz6juD7jmi4WPhyiu++Kfw0m8B6qk1ozT6PdsRbyt96Nuvlt746HuPoa4GmIKKKKAClUFmCqCSTgAd6FBZgqgkk4AHevR/DfhuLSrdZ7lQ944ySRny/Ye/vVRi5M8/HY6ngqfNLVvZHL2PgzU7tQ8wS1Q/89T835D+uK0v+FfNt/wCQkN3p5HH/AKFXa0Vt7OJ8jUzzGSleLS9Ev1uecX3gzU7RS8IS6Qf88j835H+mawGBVirAgg4IPavZqwPEnhuLVbdp7ZQl4gyCBjzPY+/vUyp9j0cFnsnJQxPXr/meb0UrAqxVgQQcEHtSVifWhRRRQAU9Imf7o49afBFvO5vuj9atDjpWsYX1ZnKVtEVxanu36UhtWHRgas0Vp7OJHOygyshwwxSVfZQ64YZqnJGY2wenY1lKHKaRlcZRRRWZYUUU5FLsFFMBACxwoyalW2Y/eIFWEjEa4H4mnVsqa6mLm+hXNqez/pUbwunJGR6irlFN00CmzPoqeeHHzp07ioKxaadjVO6CiiipGFFFe3/CD4QW+p2cPiTxXAJbaQbrOyfpIP8Ano47j0HfqeOoB5p4c+H/AIn8VqJNF0maWAnH2h8Rxf8AfTYB+gya7KP9nfxg8W9rvSI2/uNcSZ/SMj9a+mI40ijWOJFREAVVUYCgdABTqVx2PkbXfhB4z0CFpp9Ja7gUZaWyYS4HrtHzY98VxJBBIIwR1Ffd9eafE34R2Hi6zm1HR4Y7TXFBcOo2rdH+6/bPo358dC4WPlqipJ4JbW4kguI2imicpIjDBVgcEEeuajpiCiiigAq5pekajrd6tnpFlPe3DdI4Iyxx6nHQe9b3w+8C3vj3xELG2bybWECS7ucZ8pM9vVj0A+p6A19X+G/C2keE9LWw0KzS3i43t1eVv7zN1J/yMUXA+c9P+AXjW9iDzx2NhkZ23Nzkj/vgNRqHwC8a2UReCOxv8DO22ucE/wDfYWvqOilcdj4b1TSNR0S9az1eynsrhesc8ZU49RnqPeqdfbPiTwtpHizS2sNds0uIudjdHib+8rdQf8nNfKHxB8C3vgLxEbG5bzrWYGS0ucY81M9/Rh0I+h6EU7iOVqK6/wCPZvw/nUtRXX/Hs/4fzoAzqKKO9IYUUGigAooooA04v9Sn+6K0dE0qbXNesdLtuJbydIVOPu7iBn8OtZ0X+pT/AHRXd/BqNJfi7oay/dDysM+ohcj9QKYj6u0vTbXR9JtdOsIxHbWsSxRqOwAxz7+p9atUUVJQUUUUAFeF/tGeGI/s+n+JreMCQP8AZLkgfeBBZCfphhn3HpXulef/ABwjR/hFqzP96N4GT6+cg/kTQB8n0UUVRIV9NfADwxHpXgltaljH2rVZCQxHKxISqj8SGPvkelfMtfZ3w+jSL4b+HVi+6dNgY49TGCf1JpMaOiooopDCiiigDD8Z+HIfFnhHUNHnVS08R8lj/BKOUb88fhkV8WyI0UjRyKVdSVZT2Ir7ur4p8ZxpD481+OL/AFaalcKuPQStimhMxaKKKYjoPBliLvXRLIMpbL5n/Aug/wAfwr0euK+H2N9//exHj6fNXa10U/hPgc8qSljHF9El+F/1CiiitDxQooooA848Z2ItNdMsYwlyvmf8C6H/AB/GufrsviDjfYf3sSZ+ny1xtc09JH6NldSVTB05S7W+52Cgc0U5P9Yv1FSeiXVXaoA7UtFFdRzhRRRTAKiuF3R57ipabJ/qm+hqZaoa3KNFFFcp0BVm2XClvXiq1XIP9SK0p/ERPYkoooroMQooooACMjBqg67XI9DV+qc/+uasqmxcNyOiiisDY6T4f+HB4r8d6ZpMgJgll3z4/wCeajcwz2yBj6mvsqONIo1jiRURAFVVGAoHQAV8z/s7xo/xIuWf70emyMn18yMfyJr6apMaCiiikMKKKKAPm39oTwxHpfiq11u1jCR6pGRMAOPNTAJ/FSv4gmvIa+kv2jo0PgPTZD/rF1JVX6GKTP8AIV821SJYUUUUAfXHwh8MR+Gvh3YAxhbu/QXdw2OSXGVH4LgY9c+tdxUdvGkNtFHF/q0QKuPQDipKkoKKKKACuH+L3hiPxL8O78CMNd2CG7t2xyCgyw/FcjHrj0ruKjuI0mtpY5f9W6FWz6Ec0AfCdRXX/Hs34fzqWorr/j2b8P51RJnUGig0hhRRRQAUUZo5oA0bZt1uvtxXQeDdaHh3xppOrPny7W5Rpcf3CcN/46TXMWUmGKHvyKuUxH3ejrJGrxsHRgCrKcgj1FLXi/wR+J0F9p8HhXXbjZewDZYzSHiZO0ef7w6D1GO459oqSgooooAK8g/aI12Oz8H2ejI48+/uBIy56Rx8n/x4r+Rr03X9f07wzo02qazcLBbQjknq57Ko7k+lfIfjjxfdeNvFVxq10CkZ/d28JOfJiHRfrySfcmmhM52iiimIK+r/AIJ67HrXwysYd4M+nFrSVc8jByv4bSv5GvlCu2+F3j6TwJ4m86ffJpl2BHeRL1x/C4HquT9QSKGB9dUVXsL+01TT4b7TriO5tZ1DxyxnKsKsVJQUUUUAU9W1O30bR7vUrxtsFpC0znPZRnH17V8RXt3Jf6hcXk/MtxK0r/Vjk/zr2P43/E6DVwfC/h+48y1jfN7cRnKysDxGp7gHknuQPTnxWmhMKKKKYjoPBl8LTXRFIcJcr5f/AALqP8Pxr0evGVYqwZSQQcgjtXo/hvxJFqtusFywS8QYIJx5nuPf2ranLofJZ7gpOX1mCv3/AMzfooorY+UCiisDxJ4ki0q3aC2YPeOMAA58v3Pv7Um0ldm1ChUxFRU6au2cv4zvhd66YozlLZfL/wCBdT/h+Fc/SsxZizEkk5JPekrlbu7n6Xh6KoUY0o9EFA4oopG5fVtygjvS1Vgl2Ha33T+lWgc9K6oyujnkrMKKKKoQVFcNtjx3NSMwRcscVTkkMjZPTsKznKysVFXYyiiiuc3CrNs2VK+nNVqcjFGBFVF2dyZK6L1FNSQSLkfiKdXTuYBRRRTACcDJqg7bnJ9TU082fkTp3NQVhUld2NYK2oUUUVkaHb/CDXY9A+JumTXDhILom0kYnAG8YX8N22vrmvhAEggg4I6GvqT4R/E2DxdpEWl6pOF1y1j2uHPN0o/jX1OPvD8enRMaPS6KKKQwoorA8ZeMtM8E6E+o6rJljkQW6n553/uj+p7UAeQ/tIa7HJc6RoMTgvEGu5wD0z8qfjgP+YrwytHX9cvfEmvXer6nJvubqTe3oo6BR7AAAewrOqiQooooA+zfAGux+JPAWk6ijhna3WObnpInyt+oJ+hFdHXy78G/iSng7VJNL1iRho964JfqLeXpv+hGAfoD2r6giljmhSWF1kjdQyOhyGB6EHuKkodRRRQAVznj/XY/DfgLVtRdwrrbtHDz1kf5V/Ug/QGuhlljhheWZ1jjRSzu5wFA6knsK+X/AIyfElPGOqR6Xo8jHR7JyQ/QXEvTf9AMgfUnvQB5jVe8bEOPU1YqhdSb5cDovFUSQUUUUhhiijNFABRRRQAoJUgjgitGCYSp/tDqKzaVXKMCpwaANYEqwZSQQcgjtXp/hL47+I/D9vHaarGmtWsYAUzOVmUenmc5/wCBAn3ryeK7VhiT5T69qsA5GRzTEfSFv+0f4aaIG60nVY5O6xrG4/MuP5Vl6z+0lEImXw/oTmQ/dlvpAAP+AL1/76FeB0UWC5t+J/F+t+MNQ+169evcMvEcQ+WOIeiqOB9ep7msSiigAooooAKKKKAOn8IfEHxB4JuC2jXebdzmS0nG+J/w7H3BBr1zSv2ktPeFRrehXMMg+81pIsgP4Ntx+Zr58ooA+jbz9pDw+kROn6NqU8nZZzHEPzDN/KvNPGXxm8S+LYHs42TS9PfhoLUndIPRn6n6DAPcV57RRYAooooAKKKKAClVirBlJBByCO1JRQB0Fj4z1O0UJMUukH/PUfN+Y/rmtL/hYLbf+QaN3r5/H/oNcbRV88kebUyvB1Jc0qa+V1+R0F94z1O7UpCUtUP/ADyHzfmf6YrAZizFmJJJySe9JRUtt7nXRw9GguWlFIKKKKRuFFFFABT0lZPunj0plFO9hFgXR7r+tIbpj0UCoKKrnkLlQrMznLHNJRRUlBRRRSAKKKKAFDFTlTg1Ktyw+8AahoqlJrYTSe5YN0eyfrUbzO/U4HoKjoocmxKKQUUUVJQUUUUAFSQTzWtwk9tK8M0bBkkjYqyn1BHQ1HRQB694Y/aE1zS4Ut/ENnHq8ajAmDeVNj3IBDfkD6mu0j/aO8LmLMulausn91Y4mH57x/Kvm2iiwXPc9d/aQmkhaPw3oqwuRgT3sm7H/AF7/wDAvwrx3XNf1TxJqb6hrd7Jd3L/AMTnhR6KBwo9hxWdRQAUUUUAFFFFABXZ+DPin4j8FKLexnW7sM5NndZZB/unqv4HHqDXGUUAfROn/tI6NJEP7V0O+gkxyLZ0lH/jxWjUP2kdGjiP9laHfTyY4Fy6RD/x0tXztRRYLnZ+M/in4j8aqbe+nW0sM5Fna5VD/vHq34nHoBXGUhIUZY4HvVaa8ABEXJ9aAH3E/lrtX7x/SqGaCSxyTkmikMKMUUUAFFFFAB0ooooAKKKKAClV2T7rEfQ0lHegCUXMo/j/AEFL9qm/v/oKhooAm+1Tf3/0FH2qb+/+gqGigCb7VN/f/QUn2qb+/wDoKioNAE32qb+/+gpPtU39/wDQVFRQBL9qm/v/AKCl+1Tf3/0FQ0ZoAl+1Tf3/ANBR9qm/v/oKioxQBN9qm/v/AKCj7VN/f/QVDRQBN9qm/v8A6CkN1N/f/QVFQaAJftU39/8AQUv2qb+/+gqEUUATfapv7/6Cj7VN/f8A0FQ0UATfapv7/wCgpPtU39/9BUVGKAJftU39/wDQUv2qb+/+gqGjFAE32qb+/wDoKPtU39/9BUOKKAJftU39/wDQUv2qb+/+gqHpRmgCX7VN/f8A0FH2qb+/+gqI0CgCX7VN/f8A0FH2qb+/+gqKigCUXU39/wDQUv2qb+/+gqEUUATfapv7/wCgo+1Tf3/0FQ0UATfapv7/AOgo+1Tf3/0FQ0UATfapv7/6Cj7VN/f/AEFQ0UATfapv7/6Cj7VN/f8A0FQ0UATfapv7/wCgpPtU39/9BUVFAE32qb+/+go+1Tf3/wBBUNFAEv2qb+/+goN1N/f/AEFRd6KAJvtU39/9BSfapv7/AOgqKigCb7VN/f8A0FJ9qm/v/oKiooAm+1Tf3/0FJ9qm/v8A6CoqKAJvtU39/wDQUfapv7/6CoRRQBN9qm/v/oKQ3Mp/jP5VFRQArMWPzEk+5pKKKAAUYo70GgAooooAMUUZooABRRRQAUd6KKACjvRRQAUUUUAFFFFABRRRQAdqKKKAEpRRRQAUUUUAFFFFABQaKKAAUUUUAFFFFAB3ooooAKKKKACiiigANJRRQAvagUUUAFBoooABRRRQAUUUUAHeiiigAooooADSUUUAKKKKKACiiigANFFFAAaKKKACg0UUAAooooABRRRQAUUUUAFFFFAAaO9FFAAaSiigBaKKKAP/2Q=="
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015916,
     "end_time": "2020-09-01T17:50:03.557113",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.541197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Problematic_configuration.JPG](attachment:Capture.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015947,
     "end_time": "2020-09-01T17:50:03.589395",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.573448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you are playing with color green you can win this turn by playing in column 3(1 based indexing) but the agent will not play in this column rather in column 4. This is because when it computes the score, he sees that after he makes a 4 in a row the opponent also makes a 4 in a row and since it adds a higher penalty, the agent tries to stop the other one raher than making his own because the agent does not understand the concept that the game ends as soon as he makes a 4 in a row. First we will try to address the first problem by making minor tweaks to the functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015997,
     "end_time": "2020-09-01T17:50:03.621651",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.605654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Improved agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016155,
     "end_time": "2020-09-01T17:50:03.654275",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.638120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First we shall tweak the heuristic function to return a score of infinity whenever we get a 4 in a row and a score of -infinity if the opponent gets a 4 in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015947,
     "end_time": "2020-09-01T17:50:03.686660",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.670713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tweaking the hueristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T17:50:03.731946Z",
     "iopub.status.busy": "2020-09-01T17:50:03.731088Z",
     "iopub.status.idle": "2020-09-01T17:50:03.734787Z",
     "shell.execute_reply": "2020-09-01T17:50:03.734060Z"
    },
    "papermill": {
     "duration": 0.031708,
     "end_time": "2020-09-01T17:50:03.734908",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.703200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_heuristic(grid, mark, config):\n",
    "    score = 0\n",
    "    for i in range(config.inarow):\n",
    "        num  = count_windows (grid,i+1,mark,config)\n",
    "        if (i==(config.inarow-1) and num >= 1):\n",
    "            return float(\"inf\")\n",
    "        score += (4**(i+1))*num\n",
    "    for i in range(config.inarow):\n",
    "        num_opp = count_windows (grid,i+1,mark%2+1,config)\n",
    "        if (i==(config.inarow-1) and num_opp >= 1):\n",
    "            return float (\"-inf\")\n",
    "        score-= (2**((2*i)+3))*num_opp\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016483,
     "end_time": "2020-09-01T17:50:03.768316",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.751833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tweaking the minimax functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T17:50:03.817469Z",
     "iopub.status.busy": "2020-09-01T17:50:03.816693Z",
     "iopub.status.idle": "2020-09-01T17:50:03.820089Z",
     "shell.execute_reply": "2020-09-01T17:50:03.819474Z"
    },
    "papermill": {
     "duration": 0.035262,
     "end_time": "2020-09-01T17:50:03.820212",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.784950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_move_a(grid, col, mark, config,n_steps=1):\n",
    "    next_grid = drop_piece(grid, col, mark, config)\n",
    "    valid_moves = [col for col in range (config.columns) if next_grid[0][col]==0]\n",
    "    score = get_heuristic(next_grid, mark, config)\n",
    "    #Since we have just dropped our piece there is only the possibility of us getting 4 in a row and not the opponent.\n",
    "    #Thus score can only be +infinity.\n",
    "    if len(valid_moves)==0 or n_steps ==0 or score == float(\"inf\"):\n",
    "        return score\n",
    "    else :\n",
    "        scores = [score_move_b(next_grid,col,mark,config,n_steps-1) for col in valid_moves]\n",
    "        score = min(scores)\n",
    "    return score\n",
    "\n",
    "def score_move_b(grid, col, mark, config,n_steps):\n",
    "    next_grid = drop_piece(grid,col,(mark%2)+1,config)\n",
    "    valid_moves = [col for col in range (config.columns) if next_grid[0][col]==0]\n",
    "    score = get_heuristic(next_grid, mark, config)\n",
    "    #The converse is true here.\n",
    "    #Since we have just dropped opponent piece there is only the possibility of opponent getting 4 in a row and not us.\n",
    "    #Thus score can only be -infinity.\n",
    "    if len(valid_moves)==0 or n_steps ==0 or score == float (\"-inf\"):\n",
    "        return score\n",
    "    else :\n",
    "        scores = [score_move_a(next_grid,col,mark,config,n_steps-1) for col in valid_moves]\n",
    "        score = max(scores)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016527,
     "end_time": "2020-09-01T17:50:03.853733",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.837206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining the agent with new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T17:50:03.897568Z",
     "iopub.status.busy": "2020-09-01T17:50:03.896678Z",
     "iopub.status.idle": "2020-09-01T17:50:03.898938Z",
     "shell.execute_reply": "2020-09-01T17:50:03.899729Z"
    },
    "papermill": {
     "duration": 0.029461,
     "end_time": "2020-09-01T17:50:03.899898",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.870437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def agent(obs, config):\n",
    "    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n",
    "    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n",
    "    scores = dict(zip(valid_moves, [score_move_a(grid, col, obs.mark, config,1) for col in valid_moves]))\n",
    "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
    "    return random.choice(max_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01629,
     "end_time": "2020-09-01T17:50:03.933108",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.916818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "By doing these few tweaks the function will return the score of infinity as soon as it selects a row that makes a four in a row thus making the score higher than could be obtained any other way.\n",
    "\n",
    "This also ensures that if by us making a move enables the opponent to make a four in a row, a score of -infinity is returned and that path in the minimax tree is thrown out and the agent gives any other path a priority if it returns a non -infinity score without condsidering how low the score is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016255,
     "end_time": "2020-09-01T17:50:03.966498",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.950243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing against negamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 7.691857,
     "end_time": "2020-09-01T17:50:11.675157",
     "exception": false,
     "start_time": "2020-09-01T17:50:03.983300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Action: <__main__.DeepQLearner object at 0x000001EE5DF164B0> is not of type 'integer'\n",
      "\n",
      "Failed validating 'type' in schema:\n",
      "    {'default': 0,\n",
      "     'description': 'Column to drop a checker onto the board.',\n",
      "     'minimum': 0,\n",
      "     'type': 'integer'}\n",
      "\n",
      "On instance:\n",
      "    <__main__.DeepQLearner object at 0x000001EE5DF164B0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe srcdoc=\"<!--\n",
       "  Copyright 2020 Kaggle Inc\n",
       "\n",
       "  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n",
       "  you may not use this file except in compliance with the License.\n",
       "  You may obtain a copy of the License at\n",
       "\n",
       "      http://www.apache.org/licenses/LICENSE-2.0\n",
       "\n",
       "  Unless required by applicable law or agreed to in writing, software\n",
       "  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n",
       "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "  See the License for the specific language governing permissions and\n",
       "  limitations under the License.\n",
       "-->\n",
       "<!DOCTYPE html>\n",
       "<html lang=&quot;en&quot;>\n",
       "  <head>\n",
       "    <title>Kaggle Simulation Player</title>\n",
       "    <meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot; />\n",
       "    <link\n",
       "      rel=&quot;stylesheet&quot;\n",
       "      href=&quot;https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.css&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "    />\n",
       "    <style type=&quot;text/css&quot;>\n",
       "      html,\n",
       "      body {\n",
       "        height: 100%;\n",
       "        font-family: sans-serif;\n",
       "        margin: 0px;\n",
       "      }\n",
       "      canvas {\n",
       "        /* image-rendering: -moz-crisp-edges;\n",
       "        image-rendering: -webkit-crisp-edges;\n",
       "        image-rendering: pixelated;\n",
       "        image-rendering: crisp-edges; */\n",
       "      }\n",
       "    </style>\n",
       "    <script src=&quot;https://unpkg.com/preact@10.0.1/dist/preact.umd.js&quot;></script>\n",
       "    <script src=&quot;https://unpkg.com/preact@10.0.1/hooks/dist/hooks.umd.js&quot;></script>\n",
       "    <script src=&quot;https://unpkg.com/htm@2.2.1/dist/htm.umd.js&quot;></script>\n",
       "    <script>\n",
       "      // Polyfill for Styled Components\n",
       "      window.React = {\n",
       "        ...preact,\n",
       "        createElement: preact.h,\n",
       "        PropTypes: { func: {} },\n",
       "      };\n",
       "    </script>\n",
       "    <script src=&quot;https://unpkg.com/styled-components@3.5.0-0/dist/styled-components.min.js&quot;></script>\n",
       "  </head>\n",
       "  <body>\n",
       "    <script>\n",
       "      \n",
       "window.kaggle = {\n",
       "  &quot;debug&quot;: true,\n",
       "  &quot;playing&quot;: true,\n",
       "  &quot;step&quot;: 0,\n",
       "  &quot;controls&quot;: true,\n",
       "  &quot;environment&quot;: {\n",
       "    &quot;id&quot;: &quot;f907acdb-64ad-11ef-88e1-a83b7687752e&quot;,\n",
       "    &quot;name&quot;: &quot;connectx&quot;,\n",
       "    &quot;title&quot;: &quot;ConnectX&quot;,\n",
       "    &quot;description&quot;: &quot;Classic Connect in a row but configurable.&quot;,\n",
       "    &quot;version&quot;: &quot;1.0.1&quot;,\n",
       "    &quot;configuration&quot;: {\n",
       "      &quot;episodeSteps&quot;: 1000,\n",
       "      &quot;actTimeout&quot;: 2,\n",
       "      &quot;runTimeout&quot;: 1200,\n",
       "      &quot;columns&quot;: 7,\n",
       "      &quot;rows&quot;: 6,\n",
       "      &quot;inarow&quot;: 4,\n",
       "      &quot;agentTimeout&quot;: 60,\n",
       "      &quot;timeout&quot;: 2\n",
       "    },\n",
       "    &quot;specification&quot;: {\n",
       "      &quot;action&quot;: {\n",
       "        &quot;description&quot;: &quot;Column to drop a checker onto the board.&quot;,\n",
       "        &quot;type&quot;: &quot;integer&quot;,\n",
       "        &quot;minimum&quot;: 0,\n",
       "        &quot;default&quot;: 0\n",
       "      },\n",
       "      &quot;agents&quot;: [\n",
       "        2\n",
       "      ],\n",
       "      &quot;configuration&quot;: {\n",
       "        &quot;episodeSteps&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum number of steps in the episode.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;minimum&quot;: 1,\n",
       "          &quot;default&quot;: 1000\n",
       "        },\n",
       "        &quot;actTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum runtime (seconds) to obtain an action from an agent.&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 2\n",
       "        },\n",
       "        &quot;runTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum runtime (seconds) of an episode (not necessarily DONE).&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 1200\n",
       "        },\n",
       "        &quot;columns&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of columns on the board&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 7,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;rows&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of rows on the board&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 6,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;inarow&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of checkers in a row required to win.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 4,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;agentTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Obsolete field kept for backwards compatibility, please use observation.remainingOverageTime.&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 60\n",
       "        },\n",
       "        &quot;timeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Obsolete copy of actTimeout maintained for backwards compatibility. May be removed in the future.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 2,\n",
       "          &quot;minimum&quot;: 0\n",
       "        }\n",
       "      },\n",
       "      &quot;info&quot;: {},\n",
       "      &quot;observation&quot;: {\n",
       "        &quot;remainingOverageTime&quot;: {\n",
       "          &quot;description&quot;: &quot;Total remaining banked time (seconds) that can be used in excess of per-step actTimeouts -- agent is disqualified with TIMEOUT status when this drops below 0.&quot;,\n",
       "          &quot;shared&quot;: false,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 60\n",
       "        },\n",
       "        &quot;step&quot;: {\n",
       "          &quot;description&quot;: &quot;Current step within the episode.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;shared&quot;: true,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 0\n",
       "        },\n",
       "        &quot;board&quot;: {\n",
       "          &quot;description&quot;: &quot;Serialized grid (rows x columns). 0 = Empty, 1 = P1, 2 = P2&quot;,\n",
       "          &quot;type&quot;: &quot;array&quot;,\n",
       "          &quot;shared&quot;: true,\n",
       "          &quot;default&quot;: []\n",
       "        },\n",
       "        &quot;mark&quot;: {\n",
       "          &quot;defaults&quot;: [\n",
       "            1,\n",
       "            2\n",
       "          ],\n",
       "          &quot;description&quot;: &quot;Which checkers are the agents.&quot;,\n",
       "          &quot;enum&quot;: [\n",
       "            1,\n",
       "            2\n",
       "          ]\n",
       "        }\n",
       "      },\n",
       "      &quot;reward&quot;: {\n",
       "        &quot;description&quot;: &quot;-1 = Lost, 0 = Draw/Ongoing, 1 = Won&quot;,\n",
       "        &quot;enum&quot;: [\n",
       "          -1,\n",
       "          0,\n",
       "          1\n",
       "        ],\n",
       "        &quot;default&quot;: 0,\n",
       "        &quot;type&quot;: [\n",
       "          &quot;number&quot;,\n",
       "          &quot;null&quot;\n",
       "        ]\n",
       "      }\n",
       "    },\n",
       "    &quot;steps&quot;: [\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 0,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: null,\n",
       "          &quot;reward&quot;: null,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 1,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INVALID&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;DONE&quot;\n",
       "        }\n",
       "      ]\n",
       "    ],\n",
       "    &quot;rewards&quot;: [\n",
       "      null,\n",
       "      0\n",
       "    ],\n",
       "    &quot;statuses&quot;: [\n",
       "      &quot;INVALID&quot;,\n",
       "      &quot;DONE&quot;\n",
       "    ],\n",
       "    &quot;schema_version&quot;: 1,\n",
       "    &quot;info&quot;: {}\n",
       "  },\n",
       "  &quot;logs&quot;: [\n",
       "    [],\n",
       "    [],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 8e-06,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ]\n",
       "  ],\n",
       "  &quot;mode&quot;: &quot;ipython&quot;\n",
       "};\n",
       "\n",
       "\n",
       "window.kaggle.renderer = // Copyright 2020 Kaggle Inc\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "function renderer({\n",
       "  act,\n",
       "  agents,\n",
       "  environment,\n",
       "  frame,\n",
       "  height = 400,\n",
       "  interactive,\n",
       "  isInteractive,\n",
       "  parent,\n",
       "  step,\n",
       "  update,\n",
       "  width = 400,\n",
       "}) {\n",
       "  // Configuration.\n",
       "  const { rows, columns, inarow } = environment.configuration;\n",
       "\n",
       "  // Common Dimensions.\n",
       "  const unit = 8;\n",
       "  const minCanvasSize = Math.min(height, width);\n",
       "  const minOffset = minCanvasSize > 400 ? 30 : unit / 2;\n",
       "  const cellSize = Math.min(\n",
       "    (width - minOffset * 2) / columns,\n",
       "    (height - minOffset * 2) / rows\n",
       "  );\n",
       "  const cellInset = 0.8;\n",
       "  const pieceScale = cellSize / 100;\n",
       "  const xOffset = Math.max(0, (width - cellSize * columns) / 2);\n",
       "  const yOffset = Math.max(0, (height - cellSize * rows) / 2);\n",
       "\n",
       "  // Canvas Setup.\n",
       "  let canvas = parent.querySelector(&quot;canvas&quot;);\n",
       "  if (!canvas) {\n",
       "    canvas = document.createElement(&quot;canvas&quot;);\n",
       "    parent.appendChild(canvas);\n",
       "\n",
       "    if (interactive) {\n",
       "      canvas.addEventListener(&quot;click&quot;, evt => {\n",
       "        if (!isInteractive()) return;\n",
       "        const rect = evt.target.getBoundingClientRect();\n",
       "        const col = Math.floor((evt.clientX - rect.left - xOffset) / cellSize);\n",
       "        if (col >= 0 && col < columns) act(col);\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  canvas.style.cursor = isInteractive() ? &quot;pointer&quot; : &quot;default&quot;;\n",
       "\n",
       "  // Character Paths (based on 100x100 tiles).\n",
       "  const kPath = new Path2D(\n",
       "    `M78.3,96.5c-0.1,0.4-0.5,0.6-1.1,0.6H64.9c-0.7,0-1.4-0.3-1.9-1l-20.3-26L37,75.5v20.1 c0,0.9-0.5,1.4-1.4,1.4H26c-0.9,0-1.4-0.5-1.4-1.4V3.9c0-0.9,0.5-1.4,1.4-1.4h9.5C36.5,2.5,37,3,37,3.9v56.5l24.3-24.7 c0.6-0.6,1.3-1,1.9-1H76c0.6,0,0.9,0.2,1.1,0.7c0.2,0.6,0.1,1-0.1,1.2l-25.7,25L78,95.1C78.4,95.5,78.5,95.9,78.3,96.5z`\n",
       "  );\n",
       "  const goose1Path = new Path2D(\n",
       "    `M8.8,92.7c-4-18.5,4.7-37.2,20.7-46.2c0,0,2.7-1.4,3.4-1.9c2.2-1.6,3-2.1,3-5c0-5-2.1-7.2-2.1-7.2 c-3.9-3.3-6.3-8.2-6.3-13.7c0-10,8.1-18.1,18.1-18.1s18.1,8.1,18.1,18.1c0,6-1.5,32.7-2.3,38.8l-0.1,1`\n",
       "  );\n",
       "  const goose2Path = new Path2D(\n",
       "    `M27.4,19L8.2,27.6c0,0-7.3,2.9,2.6,5c6.1,1.3,24,5.9,24,5.9l1,0.3`\n",
       "  );\n",
       "  const goose3Path = new Path2D(\n",
       "    `M63.7,99.6C52.3,99.6,43,90.3,43,78.9s9.3-20.7,20.7-20.7c10.6,0,34.4,0.1,35.8,9`\n",
       "  );\n",
       "\n",
       "  // Canvas setup and reset.\n",
       "  let c = canvas.getContext(&quot;2d&quot;);\n",
       "  canvas.width = width;\n",
       "  canvas.height = height;\n",
       "  c.fillStyle = &quot;#000B2A&quot;;\n",
       "  c.fillRect(0, 0, canvas.width, canvas.height);\n",
       "\n",
       "  const getRowCol = cell => [Math.floor(cell / columns), cell % columns];\n",
       "\n",
       "  const getColor = (mark, opacity = 1) => {\n",
       "    if (mark === 1) return `rgba(0,255,255,${opacity})`;\n",
       "    if (mark === 2) return `rgba(255,255,255,${opacity})`;\n",
       "    return &quot;#fff&quot;;\n",
       "  };\n",
       "\n",
       "  const drawCellCircle = (cell, xFrame = 1, yFrame = 1, radiusOffset = 0) => {\n",
       "    const [row, col] = getRowCol(cell);\n",
       "    c.arc(\n",
       "      xOffset + xFrame * (col * cellSize + cellSize / 2),\n",
       "      yOffset + yFrame * (row * cellSize + cellSize / 2),\n",
       "      (cellInset * cellSize) / 2 - radiusOffset,\n",
       "      2 * Math.PI,\n",
       "      false\n",
       "    );\n",
       "  };\n",
       "\n",
       "  // Render the pieces.\n",
       "  const board = environment.steps[step][0].observation.board;\n",
       "\n",
       "  const drawPiece = mark => {\n",
       "    // Base Styles.\n",
       "    const opacity = minCanvasSize < 300 ? 0.6 - minCanvasSize / 1000 : 0.1;\n",
       "    c.fillStyle = getColor(mark, opacity);\n",
       "    c.strokeStyle = getColor(mark);\n",
       "    c.shadowColor = getColor(mark);\n",
       "    c.shadowBlur = 8 / cellInset;\n",
       "    c.lineWidth = 1 / cellInset;\n",
       "\n",
       "    // Outer circle.\n",
       "    c.save();\n",
       "    c.beginPath();\n",
       "    c.arc(50, 50, 50, 2 * Math.PI, false);\n",
       "    c.closePath();\n",
       "    c.lineWidth *= 4;\n",
       "    c.stroke();\n",
       "    c.fill();\n",
       "    c.restore();\n",
       "\n",
       "    // Inner circle.\n",
       "    c.beginPath();\n",
       "    c.arc(50, 50, 40, 2 * Math.PI, false);\n",
       "    c.closePath();\n",
       "    c.stroke();\n",
       "\n",
       "    // Kaggle &quot;K&quot;.\n",
       "    if (mark === 1) {\n",
       "      const scale = 0.54;\n",
       "      c.save();\n",
       "      c.translate(23, 23);\n",
       "      c.scale(scale, scale);\n",
       "      c.lineWidth /= scale;\n",
       "      c.shadowBlur /= scale;\n",
       "      c.stroke(kPath);\n",
       "      c.restore();\n",
       "    }\n",
       "\n",
       "    // Kaggle &quot;Goose&quot;.\n",
       "    if (mark === 2) {\n",
       "      const scale = 0.6;\n",
       "      c.save();\n",
       "      c.translate(24, 28);\n",
       "      c.scale(scale, scale);\n",
       "      c.lineWidth /= scale;\n",
       "      c.shadowBlur /= scale;\n",
       "      c.stroke(goose1Path);\n",
       "      c.stroke(goose2Path);\n",
       "      c.stroke(goose3Path);\n",
       "      c.beginPath();\n",
       "      c.arc(38.5, 18.6, 2.7, 0, Math.PI * 2, false);\n",
       "      c.closePath();\n",
       "      c.fill();\n",
       "      c.restore();\n",
       "    }\n",
       "  };\n",
       "\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    const [row, col] = getRowCol(i);\n",
       "    if (board[i] === 0) continue;\n",
       "    // Easing In.\n",
       "    let yFrame = Math.min(\n",
       "      (columns * Math.pow(frame, 3)) / Math.floor(i / columns),\n",
       "      1\n",
       "    );\n",
       "\n",
       "    if (\n",
       "      step > 1 &&\n",
       "      environment.steps[step - 1][0].observation.board[i] === board[i]\n",
       "    ) {\n",
       "      yFrame = 1;\n",
       "    }\n",
       "\n",
       "    c.save();\n",
       "    c.translate(\n",
       "      xOffset + cellSize * col + (cellSize - cellSize * cellInset) / 2,\n",
       "      yOffset +\n",
       "        yFrame * (cellSize * row) +\n",
       "        (cellSize - cellSize * cellInset) / 2\n",
       "    );\n",
       "    c.scale(pieceScale * cellInset, pieceScale * cellInset);\n",
       "    drawPiece(board[i]);\n",
       "    c.restore();\n",
       "  }\n",
       "\n",
       "  // Background Gradient.\n",
       "  const bgRadius = (Math.min(rows, columns) * cellSize) / 2;\n",
       "  const bgStyle = c.createRadialGradient(\n",
       "    xOffset + (cellSize * columns) / 2,\n",
       "    yOffset + (cellSize * rows) / 2,\n",
       "    0,\n",
       "    xOffset + (cellSize * columns) / 2,\n",
       "    yOffset + (cellSize * rows) / 2,\n",
       "    bgRadius\n",
       "  );\n",
       "  bgStyle.addColorStop(0, &quot;#000B49&quot;);\n",
       "  bgStyle.addColorStop(1, &quot;#000B2A&quot;);\n",
       "\n",
       "  // Render the board overlay.\n",
       "  c.beginPath();\n",
       "  c.rect(0, 0, canvas.width, canvas.height);\n",
       "  c.closePath();\n",
       "  c.shadowBlur = 0;\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    drawCellCircle(i);\n",
       "    c.closePath();\n",
       "  }\n",
       "  c.fillStyle = bgStyle;\n",
       "  c.fill(&quot;evenodd&quot;);\n",
       "\n",
       "  // Render the board overlay cell outlines.\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    c.beginPath();\n",
       "    drawCellCircle(i);\n",
       "    c.strokeStyle = &quot;#0361B2&quot;;\n",
       "    c.lineWidth = 1;\n",
       "    c.stroke();\n",
       "    c.closePath();\n",
       "  }\n",
       "\n",
       "  const drawLine = (fromCell, toCell) => {\n",
       "    if (frame < 0.5) return;\n",
       "    const lineFrame = (frame - 0.5) / 0.5;\n",
       "    const x1 = xOffset + (fromCell % columns) * cellSize + cellSize / 2;\n",
       "    const x2 =\n",
       "      x1 +\n",
       "      lineFrame *\n",
       "        (xOffset + ((toCell % columns) * cellSize + cellSize / 2) - x1);\n",
       "    const y1 =\n",
       "      yOffset + Math.floor(fromCell / columns) * cellSize + cellSize / 2;\n",
       "    const y2 =\n",
       "      y1 +\n",
       "      lineFrame *\n",
       "        (yOffset + Math.floor(toCell / columns) * cellSize + cellSize / 2 - y1);\n",
       "    c.beginPath();\n",
       "    c.lineCap = &quot;round&quot;;\n",
       "    c.lineWidth = 4;\n",
       "    c.strokeStyle = getColor(board[fromCell]);\n",
       "    c.shadowBlur = 8;\n",
       "    c.shadowColor = getColor(board[fromCell]);\n",
       "    c.moveTo(x1, y1);\n",
       "    c.lineTo(x2, y2);\n",
       "    c.stroke();\n",
       "  };\n",
       "\n",
       "  // Generate a graph of the board.\n",
       "  const getCell = (cell, rowOffset, columnOffset) => {\n",
       "    const row = Math.floor(cell / columns) + rowOffset;\n",
       "    const col = (cell % columns) + columnOffset;\n",
       "    if (row < 0 || row >= rows || col < 0 || col >= columns) return -1;\n",
       "    return col + row * columns;\n",
       "  };\n",
       "  const makeNode = cell => {\n",
       "    const node = { cell, directions: [], value: board[cell] };\n",
       "    for (let r = -1; r <= 1; r++) {\n",
       "      for (let c = -1; c <= 1; c++) {\n",
       "        if (r === 0 && c === 0) continue;\n",
       "        node.directions.push(getCell(cell, r, c));\n",
       "      }\n",
       "    }\n",
       "    return node;\n",
       "  };\n",
       "  const graph = board.map((_, i) => makeNode(i));\n",
       "\n",
       "  // Check for any wins!\n",
       "  const getSequence = (node, direction) => {\n",
       "    const sequence = [node.cell];\n",
       "    while (sequence.length < inarow) {\n",
       "      const next = graph[node.directions[direction]];\n",
       "      if (!next || node.value !== next.value || next.value === 0) return;\n",
       "      node = next;\n",
       "      sequence.push(node.cell);\n",
       "    }\n",
       "    return sequence;\n",
       "  };\n",
       "\n",
       "  // Check all nodes.\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    // Check all directions (not the most efficient).\n",
       "    for (let d = 0; d < 8; d++) {\n",
       "      const seq = getSequence(graph[i], d);\n",
       "      if (seq) {\n",
       "        drawLine(seq[0], seq[inarow - 1]);\n",
       "        i = board.length;\n",
       "        break;\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  // Upgrade the legend.\n",
       "  if (agents.length && (!agents[0].color || !agents[0].image)) {\n",
       "    const getPieceImage = mark => {\n",
       "      const pieceCanvas = document.createElement(&quot;canvas&quot;);\n",
       "      parent.appendChild(pieceCanvas);\n",
       "      pieceCanvas.style.marginLeft = &quot;10000px&quot;;\n",
       "      pieceCanvas.width = 100;\n",
       "      pieceCanvas.height = 100;\n",
       "      c = pieceCanvas.getContext(&quot;2d&quot;);\n",
       "      c.translate(10, 10);\n",
       "      c.scale(0.8, 0.8);\n",
       "      drawPiece(mark);\n",
       "      const dataUrl = pieceCanvas.toDataURL();\n",
       "      parent.removeChild(pieceCanvas);\n",
       "      return dataUrl;\n",
       "    };\n",
       "\n",
       "    agents.forEach(agent => {\n",
       "      agent.color = getColor(agent.index + 1);\n",
       "      agent.image = getPieceImage(agent.index + 1);\n",
       "    });\n",
       "    update({ agents });\n",
       "  }\n",
       "};\n",
       "\n",
       "\n",
       "    \n",
       "    </script>\n",
       "    <script>\n",
       "      const h = htm.bind(preact.h);\n",
       "      const { useContext, useEffect, useRef, useState } = preactHooks;\n",
       "      const styled = window.styled.default;\n",
       "\n",
       "      const Context = preact.createContext({});\n",
       "\n",
       "      const Loading = styled.div`\n",
       "        animation: rotate360 1.1s infinite linear;\n",
       "        border: 8px solid rgba(255, 255, 255, 0.2);\n",
       "        border-left-color: #0cb1ed;\n",
       "        border-radius: 50%;\n",
       "        height: 40px;\n",
       "        position: relative;\n",
       "        transform: translateZ(0);\n",
       "        width: 40px;\n",
       "\n",
       "        @keyframes rotate360 {\n",
       "          0% {\n",
       "            transform: rotate(0deg);\n",
       "          }\n",
       "          100% {\n",
       "            transform: rotate(360deg);\n",
       "          }\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const Logo = styled(\n",
       "        (props) => h`\n",
       "        <a href=&quot;https://kaggle.com&quot; target=&quot;_blank&quot; className=${props.className}>\n",
       "          <svg width=&quot;62px&quot; height=&quot;20px&quot; viewBox=&quot;0 0 62 24&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;>\n",
       "            <g fill=&quot;#1EBEFF&quot; fill-rule=&quot;nonzero&quot;>\n",
       "              <path d=&quot;M10.2,17.8c0,0.1-0.1,0.1-0.2,0.1H7.7c-0.1,0-0.3-0.1-0.4-0.2l-3.8-4.9l-1.1,1v3.8 c0,0.2-0.1,0.3-0.3,0.3H0.3c-0.2,0-0.3-0.1-0.3-0.3V0.3C0.1,0.1,0.2,0,0.3,0h1.8c0.2,0,0.3,0.1,0.3,0.3V11L7,6.3 c0.1-0.1,0.2-0.2,0.4-0.2h2.4c0.1,0,0.2,0,0.2,0.1c0,0.1,0,0.2,0,0.2l-4.9,4.7l5.1,6.3C10.2,17.6,10.2,17.7,10.2,17.8z&quot;/>\n",
       "              <path d=&quot;M19.6,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3v-0.4c-0.8,0.6-1.8,0.9-3,0.9c-1.1,0-2-0.3-2.8-1 c-0.8-0.7-1.2-1.6-1.2-2.7c0-1.7,1.1-2.9,3.2-3.5c0.8-0.2,2.1-0.5,3.8-0.6c0.1-0.6-0.1-1.2-0.5-1.7c-0.4-0.5-1-0.7-1.7-0.7 c-1,0-2,0.4-3,1C12.2,9.1,12.1,9.1,12,9l-0.9-1.3C11,7.5,11,7.4,11.1,7.3c1.3-0.9,2.7-1.4,4.2-1.4c1.1,0,2.1,0.3,2.8,0.8 c1.1,0.8,1.7,2,1.7,3.7v7.3C19.9,17.8,19.8,17.9,19.6,17.9z M17.5,12.4c-1.7,0.2-2.9,0.4-3.5,0.7c-0.9,0.4-1.2,0.9-1.1,1.6 c0.1,0.4,0.2,0.7,0.6,0.9c0.3,0.2,0.7,0.4,1.1,0.4c1.2,0.1,2.2-0.2,2.9-1V12.4z&quot;/>\n",
       "              <path d=&quot;M30.6,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3v11.7C32,20,31.5,21.5,30.6,22.5z M29.7,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7V9.9z&quot;/>\n",
       "              <path d=&quot;M42.9,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3H44c0.2,0,0.3,0.1,0.3,0.3v11.7C44.3,20,43.8,21.5,42.9,22.5z M42,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7L42,9.9 L42,9.9z&quot;/>\n",
       "              <path d=&quot;M48.3,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3V0.3c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3 v17.3C48.5,17.8,48.5,17.9,48.3,17.9z&quot;/>\n",
       "              <path d=&quot;M61.4,12.6c0,0.2-0.1,0.3-0.3,0.3h-8.5c0.1,0.9,0.5,1.6,1.1,2.2c0.7,0.6,1.6,0.9,2.7,0.9 c1,0,1.8-0.3,2.6-0.8c0.2-0.1,0.3-0.1,0.4,0l1.2,1.3c0.1,0.1,0.1,0.3,0,0.4c-1.3,0.9-2.7,1.4-4.4,1.4c-1.8,0-3.3-0.6-4.4-1.8 c-1.1-1.2-1.7-2.7-1.7-4.5c0-1.7,0.6-3.2,1.7-4.4c1-1.1,2.4-1.6,4.1-1.6c1.6,0,2.9,0.6,4,1.7c1.1,1.2,1.6,2.6,1.5,4.4L61.4,12.6 z M58,8.7c-0.6-0.5-1.3-0.8-2.1-0.8c-0.8,0-1.5,0.3-2.1,0.8c-0.6,0.5-1,1.2-1.1,2H59C59,9.9,58.6,9.3,58,8.7z&quot;/>\n",
       "            </g>\n",
       "          </svg>\n",
       "        </a>\n",
       "      `\n",
       "      )`\n",
       "        display: inline-flex;\n",
       "      `;\n",
       "\n",
       "      const Header = styled((props) => {\n",
       "        const { environment } = useContext(Context);\n",
       "\n",
       "        return h`<div className=${props.className} >\n",
       "          <${Logo} />\n",
       "          <span><b>Left / Right Arrow:</b> Increase / Decrease Step</span><span><b>0-9 Row Keys:</b> Playback Speed</span><span><b>Space:</b> Pause / Play</span>\n",
       "          ${environment.title}\n",
       "        </div>`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        border-bottom: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        color: #fff;\n",
       "        display: flex;\n",
       "        flex: 0 0 36px;\n",
       "        font-size: 14px;\n",
       "        justify-content: space-between;\n",
       "        padding: 0 8px;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Renderer = styled((props) => {\n",
       "        const context = useContext(Context);\n",
       "        const { animate, debug, playing, renderer, speed } = context;\n",
       "        const ref = preact.createRef();\n",
       "\n",
       "        useEffect(async () => {\n",
       "          if (!ref.current) return;\n",
       "\n",
       "          const renderFrame = async (start, step, lastFrame) => {\n",
       "            if (step !== context.step) return;\n",
       "            if (lastFrame === 1) {\n",
       "              if (!animate) return;\n",
       "              start = Date.now();\n",
       "            }\n",
       "            const frame =\n",
       "              playing || animate\n",
       "                ? Math.min((Date.now() - start) / speed, 1)\n",
       "                : 1;\n",
       "            try {\n",
       "              if (debug) console.time(&quot;render&quot;);\n",
       "              await renderer({\n",
       "                ...context,\n",
       "                frame,\n",
       "                height: ref.current.clientHeight,\n",
       "                hooks: preactHooks,\n",
       "                parent: ref.current,\n",
       "                preact,\n",
       "                styled,\n",
       "                width: ref.current.clientWidth,\n",
       "              });\n",
       "            } catch (error) {\n",
       "              if (debug) console.error(error);\n",
       "              console.log({ ...context, frame, error });\n",
       "            } finally {\n",
       "              if (debug) console.timeEnd(&quot;render&quot;);\n",
       "            }\n",
       "            window.requestAnimationFrame(() => renderFrame(start, step, frame));\n",
       "          };\n",
       "\n",
       "          await renderFrame(Date.now(), context.step);\n",
       "        }, [ref.current, context.step, context.renderer]);\n",
       "\n",
       "        return h`<div className=${props.className} ref=${ref} />`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        box-sizing: border-box;\n",
       "        display: flex;\n",
       "        height: 100%;\n",
       "        left: 0;\n",
       "        justify-content: center;\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Processing = styled((props) => {\n",
       "        const { processing } = useContext(Context);\n",
       "        const text = processing === true ? &quot;Processing...&quot; : processing;\n",
       "        return h`<div className=${props.className}>${text}</div>`;\n",
       "      })`\n",
       "        bottom: 0;\n",
       "        color: #fff;\n",
       "        font-size: 12px;\n",
       "        left: 0;\n",
       "        line-height: 24px;\n",
       "        position: absolute;\n",
       "        text-align: center;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Viewer = styled((props) => {\n",
       "        const { processing } = useContext(Context);\n",
       "        return h`<div className=${props.className}>\n",
       "          <${Renderer} />\n",
       "          ${processing && h`<${Processing} />`}\n",
       "        </div>`;\n",
       "      })`\n",
       "        background-color: #000b2a;\n",
       "        background-image: radial-gradient(\n",
       "          circle closest-side,\n",
       "          #000b49,\n",
       "          #000b2a\n",
       "        );\n",
       "        display: flex;\n",
       "        flex: 1;\n",
       "        overflow: hidden;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      // Partitions the elements of arr into subarrays of max length num.\n",
       "      const groupIntoSets = (arr, num) => {\n",
       "        const sets = [];\n",
       "        arr.forEach(a => {\n",
       "          if (sets.length === 0 || sets[sets.length - 1].length === num) {\n",
       "            sets.push([]);\n",
       "          }\n",
       "          sets[sets.length - 1].push(a);\n",
       "        });\n",
       "        return sets;\n",
       "      }\n",
       "\n",
       "      // Expects `width` input prop to set proper max-width for agent name span.\n",
       "      const Legend = styled((props) => {\n",
       "        const { agents, legend } = useContext(Context);\n",
       "\n",
       "        const agentPairs = groupIntoSets(agents.sort((a, b) => a.index - b.index), 2);\n",
       "\n",
       "        return h`<div className=${props.className}>\n",
       "          ${agentPairs.map(agentList =>\n",
       "            h`<ul>\n",
       "                ${agentList.map(a =>\n",
       "                  h`<li key=${a.id} title=&quot;id: ${a.id}&quot; style=&quot;color:${a.color || &quot;#FFF&quot;}&quot;>\n",
       "                      ${a.image && h`<img src=${a.image} />`}\n",
       "                      <span>${a.name}</span>\n",
       "                    </li>`\n",
       "                )}\n",
       "              </ul>`)}\n",
       "        </div>`;\n",
       "      })`\n",
       "        background-color: #000b2a;\n",
       "        font-family: sans-serif;\n",
       "        font-size: 14px;\n",
       "        height: 48px;\n",
       "        width: 100%;\n",
       "\n",
       "        ul {\n",
       "          align-items: center;\n",
       "          display: flex;\n",
       "          flex-direction: row;\n",
       "          justify-content: center;\n",
       "        }\n",
       "\n",
       "        li {\n",
       "          align-items: center;\n",
       "          display: inline-flex;\n",
       "          transition: color 1s;\n",
       "        }\n",
       "\n",
       "        span {\n",
       "          max-width: ${p => (p.width || 400) * 0.5 - 36}px;\n",
       "          overflow: hidden;\n",
       "          text-overflow: ellipsis;\n",
       "          white-space: nowrap;\n",
       "        }\n",
       "\n",
       "        img {\n",
       "          height: 24px;\n",
       "          margin-left: 4px;\n",
       "          margin-right: 4px;\n",
       "          width: 24px;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const StepInput = styled.input.attrs({\n",
       "        type: &quot;range&quot;,\n",
       "      })`\n",
       "        appearance: none;\n",
       "        background: rgba(255, 255, 255, 0.15);\n",
       "        border-radius: 2px;\n",
       "        display: block;\n",
       "        flex: 1;\n",
       "        height: 4px;\n",
       "        opacity: 0.8;\n",
       "        outline: none;\n",
       "        transition: opacity 0.2s;\n",
       "        width: 100%;\n",
       "\n",
       "        &:hover {\n",
       "          opacity: 1;\n",
       "        }\n",
       "\n",
       "        &::-webkit-slider-thumb {\n",
       "          appearance: none;\n",
       "          background: #1ebeff;\n",
       "          border-radius: 100%;\n",
       "          cursor: pointer;\n",
       "          height: 12px;\n",
       "          margin: 0;\n",
       "          position: relative;\n",
       "          width: 12px;\n",
       "\n",
       "          &::after {\n",
       "            content: &quot;&quot;;\n",
       "            position: absolute;\n",
       "            top: 0px;\n",
       "            left: 0px;\n",
       "            width: 200px;\n",
       "            height: 8px;\n",
       "            background: green;\n",
       "          }\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const PlayButton = styled.button`\n",
       "        align-items: center;\n",
       "        background: none;\n",
       "        border: none;\n",
       "        color: white;\n",
       "        cursor: pointer;\n",
       "        display: flex;\n",
       "        flex: 0 0 56px;\n",
       "        font-size: 20px;\n",
       "        height: 40px;\n",
       "        justify-content: center;\n",
       "        opacity: 0.8;\n",
       "        outline: none;\n",
       "        transition: opacity 0.2s;\n",
       "\n",
       "        &:hover {\n",
       "          opacity: 1;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const StepCount = styled.span`\n",
       "        align-items: center;\n",
       "        color: white;\n",
       "        display: flex;\n",
       "        font-size: 14px;\n",
       "        justify-content: center;\n",
       "        opacity: 0.8;\n",
       "        padding: 0 16px;\n",
       "        pointer-events: none;\n",
       "      `;\n",
       "\n",
       "      const Controls = styled((props) => {\n",
       "        const { environment, pause, play, playing, setStep, step } = useContext(\n",
       "          Context\n",
       "        );\n",
       "        const value = step + 1;\n",
       "        const onClick = () => (playing ? pause() : play());\n",
       "        const onInput = (e) => {\n",
       "          pause();\n",
       "          setStep(parseInt(e.target.value) - 1);\n",
       "        };\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            <${PlayButton} onClick=${onClick}><svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24px&quot; height=&quot;24px&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;#FFFFFF&quot;>${\n",
       "          playing\n",
       "            ? h`<path d=&quot;M6 19h4V5H6v14zm8-14v14h4V5h-4z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n",
       "            : h`<path d=&quot;M8 5v14l11-7z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n",
       "        }</svg><//>\n",
       "            <${StepInput} min=&quot;1&quot; max=${\n",
       "          environment.steps.length\n",
       "        } value=&quot;${value}&quot; onInput=${onInput} />\n",
       "            <${StepCount}>${value} / ${environment.steps.length}<//>\n",
       "          </div>\n",
       "        `;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        border-top: 4px solid #212121;\n",
       "        display: flex;\n",
       "        flex: 0 0 44px;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Info = styled((props) => {\n",
       "        const {\n",
       "          environment,\n",
       "          playing,\n",
       "          step,\n",
       "          speed,\n",
       "          animate,\n",
       "          header,\n",
       "          controls,\n",
       "          settings,\n",
       "        } = useContext(Context);\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            info:\n",
       "            step(${step}),\n",
       "            playing(${playing ? &quot;T&quot; : &quot;F&quot;}),\n",
       "            speed(${speed}),\n",
       "            animate(${animate ? &quot;T&quot; : &quot;F&quot;})\n",
       "          </div>`;\n",
       "      })`\n",
       "        color: #888;\n",
       "        font-family: monospace;\n",
       "        font-size: 12px;\n",
       "      `;\n",
       "\n",
       "      const Settings = styled((props) => {\n",
       "        const { environment, pause, play, playing, setStep, step } = useContext(\n",
       "          Context\n",
       "        );\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            <${Info} />\n",
       "          </div>\n",
       "        `;\n",
       "      })`\n",
       "        background: #fff;\n",
       "        border-top: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        padding: 20px;\n",
       "        width: 100%;\n",
       "\n",
       "        h1 {\n",
       "          font-size: 20px;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const Player = styled((props) => {\n",
       "        const context = useContext(Context);\n",
       "        const { agents, controls, header, legend, loading, settings, width } = context;\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            ${loading && h`<${Loading} />`}\n",
       "            ${!loading && header && h`<${Header} />`}\n",
       "            ${!loading && h`<${Viewer} />`}\n",
       "            ${!loading && legend && h`<${Legend} width=${width}/>`}\n",
       "            ${!loading && controls && h`<${Controls} />`}\n",
       "            ${!loading && settings && h`<${Settings} />`}\n",
       "          </div>`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        background: #212121;\n",
       "        border: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "        height: 100%;\n",
       "        justify-content: center;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const App = () => {\n",
       "        const renderCountRef = useRef(0);\n",
       "        const [_, setRenderCount] = useState(0);\n",
       "\n",
       "        // These are bindings to the 0-9 keys and are milliseconds of timeout per step\n",
       "        const speeds = [\n",
       "          0,\n",
       "          3000,\n",
       "          1000,\n",
       "          500,\n",
       "          333, // Default\n",
       "          200,\n",
       "          100,\n",
       "          50,\n",
       "          25,\n",
       "          10,\n",
       "        ];\n",
       "\n",
       "        const contextRef = useRef({\n",
       "          animate: false,\n",
       "          agents: [],\n",
       "          controls: false,\n",
       "          debug: false,\n",
       "          environment: { steps: [], info: {} },\n",
       "          header: window.innerHeight >= 600,\n",
       "          height: window.innerHeight,\n",
       "          interactive: false,\n",
       "          legend: true,\n",
       "          loading: false,\n",
       "          playing: false,\n",
       "          processing: false,\n",
       "          renderer: () => &quot;DNE&quot;,\n",
       "          settings: false,\n",
       "          speed: speeds[4],\n",
       "          step: 0,\n",
       "          width: window.innerWidth,\n",
       "        });\n",
       "\n",
       "        // Context helpers.\n",
       "        const rerender = (contextRef.current.rerender = () =>\n",
       "          setRenderCount((renderCountRef.current += 1)));\n",
       "        const setStep = (contextRef.current.setStep = (newStep) => {\n",
       "          contextRef.current.step = newStep;\n",
       "          rerender();\n",
       "        });\n",
       "        const setPlaying = (contextRef.current.setPlaying = (playing) => {\n",
       "          contextRef.current.playing = playing;\n",
       "          rerender();\n",
       "        });\n",
       "        const pause = (contextRef.current.pause = () => setPlaying(false));\n",
       "\n",
       "        const playNext = () => {\n",
       "          const context = contextRef.current;\n",
       "\n",
       "          if (\n",
       "            context.playing &&\n",
       "            context.step < context.environment.steps.length - 1\n",
       "          ) {\n",
       "            setStep(context.step + 1);\n",
       "            play(true);\n",
       "          } else {\n",
       "            pause();\n",
       "          }\n",
       "        };\n",
       "\n",
       "        const play = (contextRef.current.play = (continuing) => {\n",
       "          const context = contextRef.current;\n",
       "          if (context.playing && !continuing) return;\n",
       "          if (!context.playing) setPlaying(true);\n",
       "          if (\n",
       "            !continuing &&\n",
       "            context.step === context.environment.steps.length - 1\n",
       "          ) {\n",
       "            setStep(0);\n",
       "          }\n",
       "          setTimeout(playNext, context.speed);\n",
       "        });\n",
       "\n",
       "        const updateContext = (o) => {\n",
       "          const context = contextRef.current;\n",
       "          Object.assign(context, o, {\n",
       "            environment: { ...context.environment, ...(o.environment || {}) },\n",
       "          });\n",
       "          rerender();\n",
       "        };\n",
       "\n",
       "        // First time setup.\n",
       "        useEffect(() => {\n",
       "          // Timeout is used to ensure useEffect renders once.\n",
       "          setTimeout(() => {\n",
       "            // Initialize context with window.kaggle.\n",
       "            updateContext(window.kaggle || {});\n",
       "\n",
       "            if (window.kaggle.playing) {\n",
       "                play(true);\n",
       "            }\n",
       "\n",
       "            // Listen for messages received to update the context.\n",
       "            window.addEventListener(\n",
       "              &quot;message&quot;,\n",
       "              (event) => {\n",
       "                // Ensure the environment names match before updating.\n",
       "                try {\n",
       "                  if (\n",
       "                    event.data.environment.name ==\n",
       "                    contextRef.current.environment.name\n",
       "                  ) {\n",
       "                    updateContext(event.data);\n",
       "                  }\n",
       "                } catch {}\n",
       "              },\n",
       "              false\n",
       "            );\n",
       "            // Listen for keyboard commands.\n",
       "            window.addEventListener(\n",
       "              &quot;keydown&quot;,\n",
       "              (event) => {\n",
       "                const {\n",
       "                  interactive,\n",
       "                  isInteractive,\n",
       "                  playing,\n",
       "                  step,\n",
       "                  environment,\n",
       "                } = contextRef.current;\n",
       "                const key = event.keyCode;\n",
       "                const zero_key = 48\n",
       "                const nine_key = 57\n",
       "                if (\n",
       "                  interactive ||\n",
       "                  isInteractive() ||\n",
       "                  (key !== 32 && key !== 37 && key !== 39 && !(key >= zero_key && key <= nine_key))\n",
       "                )\n",
       "                  return;\n",
       "\n",
       "                if (key === 32) {\n",
       "                  playing ? pause() : play();\n",
       "                } else if (key === 39) {\n",
       "                  contextRef.current.playing = false;\n",
       "                  if (step < environment.steps.length - 1) setStep(step + 1);\n",
       "                  rerender();\n",
       "                } else if (key === 37) {\n",
       "                  contextRef.current.playing = false;\n",
       "                  if (step > 0) setStep(step - 1);\n",
       "                  rerender();\n",
       "                } else if (key >= zero_key && key <= nine_key) {\n",
       "                  contextRef.current.speed = speeds[key - zero_key];\n",
       "                }\n",
       "                event.preventDefault();\n",
       "                return false;\n",
       "              },\n",
       "              false\n",
       "            );\n",
       "          }, 1);\n",
       "        }, []);\n",
       "\n",
       "        if (contextRef.current.debug) {\n",
       "          console.log(&quot;context&quot;, contextRef.current);\n",
       "        }\n",
       "\n",
       "        // Ability to update context.\n",
       "        contextRef.current.update = updateContext;\n",
       "\n",
       "        // Ability to communicate with ipython.\n",
       "        const execute = (contextRef.current.execute = (source) =>\n",
       "          new Promise((resolve, reject) => {\n",
       "            try {\n",
       "              window.parent.IPython.notebook.kernel.execute(source, {\n",
       "                iopub: {\n",
       "                  output: (resp) => {\n",
       "                    const type = resp.msg_type;\n",
       "                    if (type === &quot;stream&quot;) return resolve(resp.content.text);\n",
       "                    if (type === &quot;error&quot;) return reject(new Error(resp.evalue));\n",
       "                    return reject(new Error(&quot;Unknown message type: &quot; + type));\n",
       "                  },\n",
       "                },\n",
       "              });\n",
       "            } catch (e) {\n",
       "              reject(new Error(&quot;IPython Unavailable: &quot; + e));\n",
       "            }\n",
       "          }));\n",
       "\n",
       "        // Ability to return an action from an interactive session.\n",
       "        contextRef.current.act = (action) => {\n",
       "          const id = contextRef.current.environment.id;\n",
       "          updateContext({ processing: true });\n",
       "          execute(`\n",
       "            import json\n",
       "            from kaggle_environments import interactives\n",
       "            if &quot;${id}&quot; in interactives:\n",
       "                action = json.loads('${JSON.stringify(action)}')\n",
       "                env, trainer = interactives[&quot;${id}&quot;]\n",
       "                trainer.step(action)\n",
       "                print(json.dumps(env.steps))`)\n",
       "            .then((resp) => {\n",
       "              try {\n",
       "                updateContext({\n",
       "                  processing: false,\n",
       "                  environment: { steps: JSON.parse(resp) },\n",
       "                });\n",
       "                play();\n",
       "              } catch (e) {\n",
       "                updateContext({ processing: resp.split(&quot;\\n&quot;)[0] });\n",
       "                console.error(resp, e);\n",
       "              }\n",
       "            })\n",
       "            .catch((e) => console.error(e));\n",
       "        };\n",
       "\n",
       "        // Check if currently interactive.\n",
       "        contextRef.current.isInteractive = () => {\n",
       "          const context = contextRef.current;\n",
       "          const steps = context.environment.steps;\n",
       "          return (\n",
       "            context.interactive &&\n",
       "            !context.processing &&\n",
       "            context.step === steps.length - 1 &&\n",
       "            steps[context.step].some((s) => s.status === &quot;ACTIVE&quot;)\n",
       "          );\n",
       "        };\n",
       "\n",
       "        return h`\n",
       "          <${Context.Provider} value=${contextRef.current}>\n",
       "            <${Player} />\n",
       "          <//>`;\n",
       "      };\n",
       "\n",
       "      preact.render(h`<${App} />`, document.body);\n",
       "    </script>\n",
       "  </body>\n",
       "</html>\n",
       "\" width=\"300\" height=\"300\" frameborder=\"0\"></iframe> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "env.run([agent,\"negamax\"])\n",
    "env.render(mode=\"ipython\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022178,
     "end_time": "2020-09-01T17:50:11.719022",
     "exception": false,
     "start_time": "2020-09-01T17:50:11.696844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Obtaining the win percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T17:50:12.043051Z",
     "iopub.status.busy": "2020-09-01T17:50:11.910353Z",
     "iopub.status.idle": "2020-09-01T18:23:43.543213Z",
     "shell.execute_reply": "2020-09-01T18:23:43.543874Z"
    },
    "papermill": {
     "duration": 2011.803691,
     "end_time": "2020-09-01T18:23:43.544073",
     "exception": false,
     "start_time": "2020-09-01T17:50:11.740382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 Win Percentage: 0.96\n",
      "Agent 2 Win Percentage: 0.03\n",
      "Number of Invalid Plays by Agent 1: 0\n",
      "Number of Invalid Plays by Agent 2: 0\n"
     ]
    }
   ],
   "source": [
    "get_win_percentages(agent1=agent, agent2=\"negamax\",n_rounds = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02085,
     "end_time": "2020-09-01T18:23:43.586303",
     "exception": false,
     "start_time": "2020-09-01T18:23:43.565453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Optimising the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.085985,
     "end_time": "2020-09-01T18:23:43.694263",
     "exception": false,
     "start_time": "2020-09-01T18:23:43.608278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now this agent seems to work good but here is alot of room for optimisation so that agent works faster. In order to do so we need to understand the complexity of the algorithm and where it could be reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020725,
     "end_time": "2020-09-01T18:23:43.736115",
     "exception": false,
     "start_time": "2020-09-01T18:23:43.715390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding the complexity for a one step lookahead:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02055,
     "end_time": "2020-09-01T18:23:43.777603",
     "exception": false,
     "start_time": "2020-09-01T18:23:43.757053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For one step lookahead the following steps are to be performed:\n",
    "\n",
    "P.S: Here we have considered a board size on n*n and m pieces to connect\n",
    "1. The program drops a piece in each of the n columns which takes O(n^2) and generates n configurations\n",
    "\n",
    "2. For each of the n columns, it agains drops opponent piece in each possible column O(n^3) and genrates n^2 configurations\n",
    "\n",
    "3. For each of these n^2 cofigurations, a heuristic function is called upon. This heuritic function calls count_windows for each value less than config.inarow resulting in (n^2)*m configuraions\n",
    "\n",
    "4. The count_windows isolates all possible windows of size config.inarow in the grid resulting in (n^2)* m * ((n-m+1)^2) which we can take as (n^4)*m for simplicity\n",
    "\n",
    "5. Now for each of these windows a check_window is called once resulting in the total complexity to be (n^4)*(m^2)\n",
    "\n",
    "6. The complexity of check window itself is m and therfore the final complexity is of the order (n^4)*(m^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020511,
     "end_time": "2020-09-01T18:23:43.819181",
     "exception": false,
     "start_time": "2020-09-01T18:23:43.798670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the question is where can we reduce the time taken? The answer is at step 3.\n",
    "\n",
    "The insight is instead of calling check_window for each value less than m, we can use check window to return the correct count of m that it would have returned true for in the same time by cheking that if number of opponent piece are 0 then we can easily return the count of our piece. This will reduce our complexity to (n^4)*(m) which might not seem a lot but consider this that if the value of m was 4, the new code would be 4 times fater than the old one. A computation that earlier took 12 seconds and would have resulted in invalid submission can now be submitted and will run easily.\n",
    "\n",
    "The code for the following optimisation is given below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020679,
     "end_time": "2020-09-01T18:23:43.860916",
     "exception": false,
     "start_time": "2020-09-01T18:23:43.840237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tweaking the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T18:23:43.932852Z",
     "iopub.status.busy": "2020-09-01T18:23:43.927924Z",
     "iopub.status.idle": "2020-09-01T18:23:43.935572Z",
     "shell.execute_reply": "2020-09-01T18:23:43.936097Z"
    },
    "papermill": {
     "duration": 0.054445,
     "end_time": "2020-09-01T18:23:43.936255",
     "exception": false,
     "start_time": "2020-09-01T18:23:43.881810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_heuristic(grid, mark, config):\n",
    "    score = 0\n",
    "    num = count_windows(grid,mark,config)\n",
    "    for i in range(config.inarow):\n",
    "        if (i==(config.inarow-1) and num[i+1] >= 1):\n",
    "            return float(\"inf\")\n",
    "        score += (4**(i))*num[i+1]\n",
    "    num_opp = count_windows (grid,mark%2+1,config)\n",
    "    for i in range(config.inarow):\n",
    "        if (i==(config.inarow-1) and num_opp[i+1] >= 1):\n",
    "            return float (\"-inf\")\n",
    "        score-= (2**((2*i)+1))*num_opp[i+1]\n",
    "    return score\n",
    "\n",
    "def check_window(window, piece, config):\n",
    "    if window.count((piece%2)+1)==0:\n",
    "        return window.count(piece)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def count_windows(grid, piece, config):\n",
    "    num_windows = np.zeros(config.inarow+1)\n",
    "    # horizontal\n",
    "    for row in range(config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[row, col:col+config.inarow])\n",
    "            type_window = check_window(window, piece, config)\n",
    "            if type_window != -1:\n",
    "                num_windows[type_window] += 1\n",
    "    # vertical\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns):\n",
    "            window = list(grid[row:row+config.inarow, col])\n",
    "            type_window = check_window(window, piece, config)\n",
    "            if type_window != -1:\n",
    "                num_windows[type_window] += 1\n",
    "    # positive diagonal\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "            type_window = check_window(window, piece, config)\n",
    "            if type_window != -1:\n",
    "                num_windows[type_window] += 1\n",
    "    # negative diagonal\n",
    "    for row in range(config.inarow-1, config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "            type_window = check_window(window, piece, config)\n",
    "            if type_window != -1:\n",
    "                num_windows[type_window] += 1\n",
    "    return num_windows\n",
    "\n",
    "def check_window(window, piece, config):\n",
    "    if window.count((piece%2)+1)==0:\n",
    "        return window.count(piece)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 4.871756,
     "end_time": "2020-09-01T18:23:48.829463",
     "exception": false,
     "start_time": "2020-09-01T18:23:43.957707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Action: <__main__.DeepQLearner object at 0x000001EE5DF31640> is not of type 'integer'\n",
      "\n",
      "Failed validating 'type' in schema:\n",
      "    {'default': 0,\n",
      "     'description': 'Column to drop a checker onto the board.',\n",
      "     'minimum': 0,\n",
      "     'type': 'integer'}\n",
      "\n",
      "On instance:\n",
      "    <__main__.DeepQLearner object at 0x000001EE5DF31640>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe srcdoc=\"<!--\n",
       "  Copyright 2020 Kaggle Inc\n",
       "\n",
       "  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n",
       "  you may not use this file except in compliance with the License.\n",
       "  You may obtain a copy of the License at\n",
       "\n",
       "      http://www.apache.org/licenses/LICENSE-2.0\n",
       "\n",
       "  Unless required by applicable law or agreed to in writing, software\n",
       "  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n",
       "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "  See the License for the specific language governing permissions and\n",
       "  limitations under the License.\n",
       "-->\n",
       "<!DOCTYPE html>\n",
       "<html lang=&quot;en&quot;>\n",
       "  <head>\n",
       "    <title>Kaggle Simulation Player</title>\n",
       "    <meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot; />\n",
       "    <link\n",
       "      rel=&quot;stylesheet&quot;\n",
       "      href=&quot;https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.css&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "    />\n",
       "    <style type=&quot;text/css&quot;>\n",
       "      html,\n",
       "      body {\n",
       "        height: 100%;\n",
       "        font-family: sans-serif;\n",
       "        margin: 0px;\n",
       "      }\n",
       "      canvas {\n",
       "        /* image-rendering: -moz-crisp-edges;\n",
       "        image-rendering: -webkit-crisp-edges;\n",
       "        image-rendering: pixelated;\n",
       "        image-rendering: crisp-edges; */\n",
       "      }\n",
       "    </style>\n",
       "    <script src=&quot;https://unpkg.com/preact@10.0.1/dist/preact.umd.js&quot;></script>\n",
       "    <script src=&quot;https://unpkg.com/preact@10.0.1/hooks/dist/hooks.umd.js&quot;></script>\n",
       "    <script src=&quot;https://unpkg.com/htm@2.2.1/dist/htm.umd.js&quot;></script>\n",
       "    <script>\n",
       "      // Polyfill for Styled Components\n",
       "      window.React = {\n",
       "        ...preact,\n",
       "        createElement: preact.h,\n",
       "        PropTypes: { func: {} },\n",
       "      };\n",
       "    </script>\n",
       "    <script src=&quot;https://unpkg.com/styled-components@3.5.0-0/dist/styled-components.min.js&quot;></script>\n",
       "  </head>\n",
       "  <body>\n",
       "    <script>\n",
       "      \n",
       "window.kaggle = {\n",
       "  &quot;debug&quot;: true,\n",
       "  &quot;playing&quot;: true,\n",
       "  &quot;step&quot;: 0,\n",
       "  &quot;controls&quot;: true,\n",
       "  &quot;environment&quot;: {\n",
       "    &quot;id&quot;: &quot;07a045c2-64ae-11ef-a230-a83b7687752e&quot;,\n",
       "    &quot;name&quot;: &quot;connectx&quot;,\n",
       "    &quot;title&quot;: &quot;ConnectX&quot;,\n",
       "    &quot;description&quot;: &quot;Classic Connect in a row but configurable.&quot;,\n",
       "    &quot;version&quot;: &quot;1.0.1&quot;,\n",
       "    &quot;configuration&quot;: {\n",
       "      &quot;episodeSteps&quot;: 1000,\n",
       "      &quot;actTimeout&quot;: 2,\n",
       "      &quot;runTimeout&quot;: 1200,\n",
       "      &quot;columns&quot;: 7,\n",
       "      &quot;rows&quot;: 6,\n",
       "      &quot;inarow&quot;: 4,\n",
       "      &quot;agentTimeout&quot;: 60,\n",
       "      &quot;timeout&quot;: 2\n",
       "    },\n",
       "    &quot;specification&quot;: {\n",
       "      &quot;action&quot;: {\n",
       "        &quot;description&quot;: &quot;Column to drop a checker onto the board.&quot;,\n",
       "        &quot;type&quot;: &quot;integer&quot;,\n",
       "        &quot;minimum&quot;: 0,\n",
       "        &quot;default&quot;: 0\n",
       "      },\n",
       "      &quot;agents&quot;: [\n",
       "        2\n",
       "      ],\n",
       "      &quot;configuration&quot;: {\n",
       "        &quot;episodeSteps&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum number of steps in the episode.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;minimum&quot;: 1,\n",
       "          &quot;default&quot;: 1000\n",
       "        },\n",
       "        &quot;actTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum runtime (seconds) to obtain an action from an agent.&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 2\n",
       "        },\n",
       "        &quot;runTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Maximum runtime (seconds) of an episode (not necessarily DONE).&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 1200\n",
       "        },\n",
       "        &quot;columns&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of columns on the board&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 7,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;rows&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of rows on the board&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 6,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;inarow&quot;: {\n",
       "          &quot;description&quot;: &quot;The number of checkers in a row required to win.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 4,\n",
       "          &quot;minimum&quot;: 1\n",
       "        },\n",
       "        &quot;agentTimeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Obsolete field kept for backwards compatibility, please use observation.remainingOverageTime.&quot;,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 60\n",
       "        },\n",
       "        &quot;timeout&quot;: {\n",
       "          &quot;description&quot;: &quot;Obsolete copy of actTimeout maintained for backwards compatibility. May be removed in the future.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;default&quot;: 2,\n",
       "          &quot;minimum&quot;: 0\n",
       "        }\n",
       "      },\n",
       "      &quot;info&quot;: {},\n",
       "      &quot;observation&quot;: {\n",
       "        &quot;remainingOverageTime&quot;: {\n",
       "          &quot;description&quot;: &quot;Total remaining banked time (seconds) that can be used in excess of per-step actTimeouts -- agent is disqualified with TIMEOUT status when this drops below 0.&quot;,\n",
       "          &quot;shared&quot;: false,\n",
       "          &quot;type&quot;: &quot;number&quot;,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 60\n",
       "        },\n",
       "        &quot;step&quot;: {\n",
       "          &quot;description&quot;: &quot;Current step within the episode.&quot;,\n",
       "          &quot;type&quot;: &quot;integer&quot;,\n",
       "          &quot;shared&quot;: true,\n",
       "          &quot;minimum&quot;: 0,\n",
       "          &quot;default&quot;: 0\n",
       "        },\n",
       "        &quot;board&quot;: {\n",
       "          &quot;description&quot;: &quot;Serialized grid (rows x columns). 0 = Empty, 1 = P1, 2 = P2&quot;,\n",
       "          &quot;type&quot;: &quot;array&quot;,\n",
       "          &quot;shared&quot;: true,\n",
       "          &quot;default&quot;: []\n",
       "        },\n",
       "        &quot;mark&quot;: {\n",
       "          &quot;defaults&quot;: [\n",
       "            1,\n",
       "            2\n",
       "          ],\n",
       "          &quot;description&quot;: &quot;Which checkers are the agents.&quot;,\n",
       "          &quot;enum&quot;: [\n",
       "            1,\n",
       "            2\n",
       "          ]\n",
       "        }\n",
       "      },\n",
       "      &quot;reward&quot;: {\n",
       "        &quot;description&quot;: &quot;-1 = Lost, 0 = Draw/Ongoing, 1 = Won&quot;,\n",
       "        &quot;enum&quot;: [\n",
       "          -1,\n",
       "          0,\n",
       "          1\n",
       "        ],\n",
       "        &quot;default&quot;: 0,\n",
       "        &quot;type&quot;: [\n",
       "          &quot;number&quot;,\n",
       "          &quot;null&quot;\n",
       "        ]\n",
       "      }\n",
       "    },\n",
       "    &quot;steps&quot;: [\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 0,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;ACTIVE&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INACTIVE&quot;\n",
       "        }\n",
       "      ],\n",
       "      [\n",
       "        {\n",
       "          &quot;action&quot;: null,\n",
       "          &quot;reward&quot;: null,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;step&quot;: 1,\n",
       "            &quot;board&quot;: [\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0,\n",
       "              0\n",
       "            ],\n",
       "            &quot;mark&quot;: 1\n",
       "          },\n",
       "          &quot;status&quot;: &quot;INVALID&quot;\n",
       "        },\n",
       "        {\n",
       "          &quot;action&quot;: 0,\n",
       "          &quot;reward&quot;: 0,\n",
       "          &quot;info&quot;: {},\n",
       "          &quot;observation&quot;: {\n",
       "            &quot;remainingOverageTime&quot;: 60,\n",
       "            &quot;mark&quot;: 2\n",
       "          },\n",
       "          &quot;status&quot;: &quot;DONE&quot;\n",
       "        }\n",
       "      ]\n",
       "    ],\n",
       "    &quot;rewards&quot;: [\n",
       "      null,\n",
       "      0\n",
       "    ],\n",
       "    &quot;statuses&quot;: [\n",
       "      &quot;INVALID&quot;,\n",
       "      &quot;DONE&quot;\n",
       "    ],\n",
       "    &quot;schema_version&quot;: 1,\n",
       "    &quot;info&quot;: {}\n",
       "  },\n",
       "  &quot;logs&quot;: [\n",
       "    [],\n",
       "    [],\n",
       "    [\n",
       "      {\n",
       "        &quot;duration&quot;: 2.4e-05,\n",
       "        &quot;stdout&quot;: &quot;&quot;,\n",
       "        &quot;stderr&quot;: &quot;&quot;\n",
       "      },\n",
       "      {}\n",
       "    ]\n",
       "  ],\n",
       "  &quot;mode&quot;: &quot;ipython&quot;\n",
       "};\n",
       "\n",
       "\n",
       "window.kaggle.renderer = // Copyright 2020 Kaggle Inc\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "function renderer({\n",
       "  act,\n",
       "  agents,\n",
       "  environment,\n",
       "  frame,\n",
       "  height = 400,\n",
       "  interactive,\n",
       "  isInteractive,\n",
       "  parent,\n",
       "  step,\n",
       "  update,\n",
       "  width = 400,\n",
       "}) {\n",
       "  // Configuration.\n",
       "  const { rows, columns, inarow } = environment.configuration;\n",
       "\n",
       "  // Common Dimensions.\n",
       "  const unit = 8;\n",
       "  const minCanvasSize = Math.min(height, width);\n",
       "  const minOffset = minCanvasSize > 400 ? 30 : unit / 2;\n",
       "  const cellSize = Math.min(\n",
       "    (width - minOffset * 2) / columns,\n",
       "    (height - minOffset * 2) / rows\n",
       "  );\n",
       "  const cellInset = 0.8;\n",
       "  const pieceScale = cellSize / 100;\n",
       "  const xOffset = Math.max(0, (width - cellSize * columns) / 2);\n",
       "  const yOffset = Math.max(0, (height - cellSize * rows) / 2);\n",
       "\n",
       "  // Canvas Setup.\n",
       "  let canvas = parent.querySelector(&quot;canvas&quot;);\n",
       "  if (!canvas) {\n",
       "    canvas = document.createElement(&quot;canvas&quot;);\n",
       "    parent.appendChild(canvas);\n",
       "\n",
       "    if (interactive) {\n",
       "      canvas.addEventListener(&quot;click&quot;, evt => {\n",
       "        if (!isInteractive()) return;\n",
       "        const rect = evt.target.getBoundingClientRect();\n",
       "        const col = Math.floor((evt.clientX - rect.left - xOffset) / cellSize);\n",
       "        if (col >= 0 && col < columns) act(col);\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  canvas.style.cursor = isInteractive() ? &quot;pointer&quot; : &quot;default&quot;;\n",
       "\n",
       "  // Character Paths (based on 100x100 tiles).\n",
       "  const kPath = new Path2D(\n",
       "    `M78.3,96.5c-0.1,0.4-0.5,0.6-1.1,0.6H64.9c-0.7,0-1.4-0.3-1.9-1l-20.3-26L37,75.5v20.1 c0,0.9-0.5,1.4-1.4,1.4H26c-0.9,0-1.4-0.5-1.4-1.4V3.9c0-0.9,0.5-1.4,1.4-1.4h9.5C36.5,2.5,37,3,37,3.9v56.5l24.3-24.7 c0.6-0.6,1.3-1,1.9-1H76c0.6,0,0.9,0.2,1.1,0.7c0.2,0.6,0.1,1-0.1,1.2l-25.7,25L78,95.1C78.4,95.5,78.5,95.9,78.3,96.5z`\n",
       "  );\n",
       "  const goose1Path = new Path2D(\n",
       "    `M8.8,92.7c-4-18.5,4.7-37.2,20.7-46.2c0,0,2.7-1.4,3.4-1.9c2.2-1.6,3-2.1,3-5c0-5-2.1-7.2-2.1-7.2 c-3.9-3.3-6.3-8.2-6.3-13.7c0-10,8.1-18.1,18.1-18.1s18.1,8.1,18.1,18.1c0,6-1.5,32.7-2.3,38.8l-0.1,1`\n",
       "  );\n",
       "  const goose2Path = new Path2D(\n",
       "    `M27.4,19L8.2,27.6c0,0-7.3,2.9,2.6,5c6.1,1.3,24,5.9,24,5.9l1,0.3`\n",
       "  );\n",
       "  const goose3Path = new Path2D(\n",
       "    `M63.7,99.6C52.3,99.6,43,90.3,43,78.9s9.3-20.7,20.7-20.7c10.6,0,34.4,0.1,35.8,9`\n",
       "  );\n",
       "\n",
       "  // Canvas setup and reset.\n",
       "  let c = canvas.getContext(&quot;2d&quot;);\n",
       "  canvas.width = width;\n",
       "  canvas.height = height;\n",
       "  c.fillStyle = &quot;#000B2A&quot;;\n",
       "  c.fillRect(0, 0, canvas.width, canvas.height);\n",
       "\n",
       "  const getRowCol = cell => [Math.floor(cell / columns), cell % columns];\n",
       "\n",
       "  const getColor = (mark, opacity = 1) => {\n",
       "    if (mark === 1) return `rgba(0,255,255,${opacity})`;\n",
       "    if (mark === 2) return `rgba(255,255,255,${opacity})`;\n",
       "    return &quot;#fff&quot;;\n",
       "  };\n",
       "\n",
       "  const drawCellCircle = (cell, xFrame = 1, yFrame = 1, radiusOffset = 0) => {\n",
       "    const [row, col] = getRowCol(cell);\n",
       "    c.arc(\n",
       "      xOffset + xFrame * (col * cellSize + cellSize / 2),\n",
       "      yOffset + yFrame * (row * cellSize + cellSize / 2),\n",
       "      (cellInset * cellSize) / 2 - radiusOffset,\n",
       "      2 * Math.PI,\n",
       "      false\n",
       "    );\n",
       "  };\n",
       "\n",
       "  // Render the pieces.\n",
       "  const board = environment.steps[step][0].observation.board;\n",
       "\n",
       "  const drawPiece = mark => {\n",
       "    // Base Styles.\n",
       "    const opacity = minCanvasSize < 300 ? 0.6 - minCanvasSize / 1000 : 0.1;\n",
       "    c.fillStyle = getColor(mark, opacity);\n",
       "    c.strokeStyle = getColor(mark);\n",
       "    c.shadowColor = getColor(mark);\n",
       "    c.shadowBlur = 8 / cellInset;\n",
       "    c.lineWidth = 1 / cellInset;\n",
       "\n",
       "    // Outer circle.\n",
       "    c.save();\n",
       "    c.beginPath();\n",
       "    c.arc(50, 50, 50, 2 * Math.PI, false);\n",
       "    c.closePath();\n",
       "    c.lineWidth *= 4;\n",
       "    c.stroke();\n",
       "    c.fill();\n",
       "    c.restore();\n",
       "\n",
       "    // Inner circle.\n",
       "    c.beginPath();\n",
       "    c.arc(50, 50, 40, 2 * Math.PI, false);\n",
       "    c.closePath();\n",
       "    c.stroke();\n",
       "\n",
       "    // Kaggle &quot;K&quot;.\n",
       "    if (mark === 1) {\n",
       "      const scale = 0.54;\n",
       "      c.save();\n",
       "      c.translate(23, 23);\n",
       "      c.scale(scale, scale);\n",
       "      c.lineWidth /= scale;\n",
       "      c.shadowBlur /= scale;\n",
       "      c.stroke(kPath);\n",
       "      c.restore();\n",
       "    }\n",
       "\n",
       "    // Kaggle &quot;Goose&quot;.\n",
       "    if (mark === 2) {\n",
       "      const scale = 0.6;\n",
       "      c.save();\n",
       "      c.translate(24, 28);\n",
       "      c.scale(scale, scale);\n",
       "      c.lineWidth /= scale;\n",
       "      c.shadowBlur /= scale;\n",
       "      c.stroke(goose1Path);\n",
       "      c.stroke(goose2Path);\n",
       "      c.stroke(goose3Path);\n",
       "      c.beginPath();\n",
       "      c.arc(38.5, 18.6, 2.7, 0, Math.PI * 2, false);\n",
       "      c.closePath();\n",
       "      c.fill();\n",
       "      c.restore();\n",
       "    }\n",
       "  };\n",
       "\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    const [row, col] = getRowCol(i);\n",
       "    if (board[i] === 0) continue;\n",
       "    // Easing In.\n",
       "    let yFrame = Math.min(\n",
       "      (columns * Math.pow(frame, 3)) / Math.floor(i / columns),\n",
       "      1\n",
       "    );\n",
       "\n",
       "    if (\n",
       "      step > 1 &&\n",
       "      environment.steps[step - 1][0].observation.board[i] === board[i]\n",
       "    ) {\n",
       "      yFrame = 1;\n",
       "    }\n",
       "\n",
       "    c.save();\n",
       "    c.translate(\n",
       "      xOffset + cellSize * col + (cellSize - cellSize * cellInset) / 2,\n",
       "      yOffset +\n",
       "        yFrame * (cellSize * row) +\n",
       "        (cellSize - cellSize * cellInset) / 2\n",
       "    );\n",
       "    c.scale(pieceScale * cellInset, pieceScale * cellInset);\n",
       "    drawPiece(board[i]);\n",
       "    c.restore();\n",
       "  }\n",
       "\n",
       "  // Background Gradient.\n",
       "  const bgRadius = (Math.min(rows, columns) * cellSize) / 2;\n",
       "  const bgStyle = c.createRadialGradient(\n",
       "    xOffset + (cellSize * columns) / 2,\n",
       "    yOffset + (cellSize * rows) / 2,\n",
       "    0,\n",
       "    xOffset + (cellSize * columns) / 2,\n",
       "    yOffset + (cellSize * rows) / 2,\n",
       "    bgRadius\n",
       "  );\n",
       "  bgStyle.addColorStop(0, &quot;#000B49&quot;);\n",
       "  bgStyle.addColorStop(1, &quot;#000B2A&quot;);\n",
       "\n",
       "  // Render the board overlay.\n",
       "  c.beginPath();\n",
       "  c.rect(0, 0, canvas.width, canvas.height);\n",
       "  c.closePath();\n",
       "  c.shadowBlur = 0;\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    drawCellCircle(i);\n",
       "    c.closePath();\n",
       "  }\n",
       "  c.fillStyle = bgStyle;\n",
       "  c.fill(&quot;evenodd&quot;);\n",
       "\n",
       "  // Render the board overlay cell outlines.\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    c.beginPath();\n",
       "    drawCellCircle(i);\n",
       "    c.strokeStyle = &quot;#0361B2&quot;;\n",
       "    c.lineWidth = 1;\n",
       "    c.stroke();\n",
       "    c.closePath();\n",
       "  }\n",
       "\n",
       "  const drawLine = (fromCell, toCell) => {\n",
       "    if (frame < 0.5) return;\n",
       "    const lineFrame = (frame - 0.5) / 0.5;\n",
       "    const x1 = xOffset + (fromCell % columns) * cellSize + cellSize / 2;\n",
       "    const x2 =\n",
       "      x1 +\n",
       "      lineFrame *\n",
       "        (xOffset + ((toCell % columns) * cellSize + cellSize / 2) - x1);\n",
       "    const y1 =\n",
       "      yOffset + Math.floor(fromCell / columns) * cellSize + cellSize / 2;\n",
       "    const y2 =\n",
       "      y1 +\n",
       "      lineFrame *\n",
       "        (yOffset + Math.floor(toCell / columns) * cellSize + cellSize / 2 - y1);\n",
       "    c.beginPath();\n",
       "    c.lineCap = &quot;round&quot;;\n",
       "    c.lineWidth = 4;\n",
       "    c.strokeStyle = getColor(board[fromCell]);\n",
       "    c.shadowBlur = 8;\n",
       "    c.shadowColor = getColor(board[fromCell]);\n",
       "    c.moveTo(x1, y1);\n",
       "    c.lineTo(x2, y2);\n",
       "    c.stroke();\n",
       "  };\n",
       "\n",
       "  // Generate a graph of the board.\n",
       "  const getCell = (cell, rowOffset, columnOffset) => {\n",
       "    const row = Math.floor(cell / columns) + rowOffset;\n",
       "    const col = (cell % columns) + columnOffset;\n",
       "    if (row < 0 || row >= rows || col < 0 || col >= columns) return -1;\n",
       "    return col + row * columns;\n",
       "  };\n",
       "  const makeNode = cell => {\n",
       "    const node = { cell, directions: [], value: board[cell] };\n",
       "    for (let r = -1; r <= 1; r++) {\n",
       "      for (let c = -1; c <= 1; c++) {\n",
       "        if (r === 0 && c === 0) continue;\n",
       "        node.directions.push(getCell(cell, r, c));\n",
       "      }\n",
       "    }\n",
       "    return node;\n",
       "  };\n",
       "  const graph = board.map((_, i) => makeNode(i));\n",
       "\n",
       "  // Check for any wins!\n",
       "  const getSequence = (node, direction) => {\n",
       "    const sequence = [node.cell];\n",
       "    while (sequence.length < inarow) {\n",
       "      const next = graph[node.directions[direction]];\n",
       "      if (!next || node.value !== next.value || next.value === 0) return;\n",
       "      node = next;\n",
       "      sequence.push(node.cell);\n",
       "    }\n",
       "    return sequence;\n",
       "  };\n",
       "\n",
       "  // Check all nodes.\n",
       "  for (let i = 0; i < board.length; i++) {\n",
       "    // Check all directions (not the most efficient).\n",
       "    for (let d = 0; d < 8; d++) {\n",
       "      const seq = getSequence(graph[i], d);\n",
       "      if (seq) {\n",
       "        drawLine(seq[0], seq[inarow - 1]);\n",
       "        i = board.length;\n",
       "        break;\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  // Upgrade the legend.\n",
       "  if (agents.length && (!agents[0].color || !agents[0].image)) {\n",
       "    const getPieceImage = mark => {\n",
       "      const pieceCanvas = document.createElement(&quot;canvas&quot;);\n",
       "      parent.appendChild(pieceCanvas);\n",
       "      pieceCanvas.style.marginLeft = &quot;10000px&quot;;\n",
       "      pieceCanvas.width = 100;\n",
       "      pieceCanvas.height = 100;\n",
       "      c = pieceCanvas.getContext(&quot;2d&quot;);\n",
       "      c.translate(10, 10);\n",
       "      c.scale(0.8, 0.8);\n",
       "      drawPiece(mark);\n",
       "      const dataUrl = pieceCanvas.toDataURL();\n",
       "      parent.removeChild(pieceCanvas);\n",
       "      return dataUrl;\n",
       "    };\n",
       "\n",
       "    agents.forEach(agent => {\n",
       "      agent.color = getColor(agent.index + 1);\n",
       "      agent.image = getPieceImage(agent.index + 1);\n",
       "    });\n",
       "    update({ agents });\n",
       "  }\n",
       "};\n",
       "\n",
       "\n",
       "    \n",
       "    </script>\n",
       "    <script>\n",
       "      const h = htm.bind(preact.h);\n",
       "      const { useContext, useEffect, useRef, useState } = preactHooks;\n",
       "      const styled = window.styled.default;\n",
       "\n",
       "      const Context = preact.createContext({});\n",
       "\n",
       "      const Loading = styled.div`\n",
       "        animation: rotate360 1.1s infinite linear;\n",
       "        border: 8px solid rgba(255, 255, 255, 0.2);\n",
       "        border-left-color: #0cb1ed;\n",
       "        border-radius: 50%;\n",
       "        height: 40px;\n",
       "        position: relative;\n",
       "        transform: translateZ(0);\n",
       "        width: 40px;\n",
       "\n",
       "        @keyframes rotate360 {\n",
       "          0% {\n",
       "            transform: rotate(0deg);\n",
       "          }\n",
       "          100% {\n",
       "            transform: rotate(360deg);\n",
       "          }\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const Logo = styled(\n",
       "        (props) => h`\n",
       "        <a href=&quot;https://kaggle.com&quot; target=&quot;_blank&quot; className=${props.className}>\n",
       "          <svg width=&quot;62px&quot; height=&quot;20px&quot; viewBox=&quot;0 0 62 24&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;>\n",
       "            <g fill=&quot;#1EBEFF&quot; fill-rule=&quot;nonzero&quot;>\n",
       "              <path d=&quot;M10.2,17.8c0,0.1-0.1,0.1-0.2,0.1H7.7c-0.1,0-0.3-0.1-0.4-0.2l-3.8-4.9l-1.1,1v3.8 c0,0.2-0.1,0.3-0.3,0.3H0.3c-0.2,0-0.3-0.1-0.3-0.3V0.3C0.1,0.1,0.2,0,0.3,0h1.8c0.2,0,0.3,0.1,0.3,0.3V11L7,6.3 c0.1-0.1,0.2-0.2,0.4-0.2h2.4c0.1,0,0.2,0,0.2,0.1c0,0.1,0,0.2,0,0.2l-4.9,4.7l5.1,6.3C10.2,17.6,10.2,17.7,10.2,17.8z&quot;/>\n",
       "              <path d=&quot;M19.6,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3v-0.4c-0.8,0.6-1.8,0.9-3,0.9c-1.1,0-2-0.3-2.8-1 c-0.8-0.7-1.2-1.6-1.2-2.7c0-1.7,1.1-2.9,3.2-3.5c0.8-0.2,2.1-0.5,3.8-0.6c0.1-0.6-0.1-1.2-0.5-1.7c-0.4-0.5-1-0.7-1.7-0.7 c-1,0-2,0.4-3,1C12.2,9.1,12.1,9.1,12,9l-0.9-1.3C11,7.5,11,7.4,11.1,7.3c1.3-0.9,2.7-1.4,4.2-1.4c1.1,0,2.1,0.3,2.8,0.8 c1.1,0.8,1.7,2,1.7,3.7v7.3C19.9,17.8,19.8,17.9,19.6,17.9z M17.5,12.4c-1.7,0.2-2.9,0.4-3.5,0.7c-0.9,0.4-1.2,0.9-1.1,1.6 c0.1,0.4,0.2,0.7,0.6,0.9c0.3,0.2,0.7,0.4,1.1,0.4c1.2,0.1,2.2-0.2,2.9-1V12.4z&quot;/>\n",
       "              <path d=&quot;M30.6,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3v11.7C32,20,31.5,21.5,30.6,22.5z M29.7,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7V9.9z&quot;/>\n",
       "              <path d=&quot;M42.9,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3H44c0.2,0,0.3,0.1,0.3,0.3v11.7C44.3,20,43.8,21.5,42.9,22.5z M42,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7L42,9.9 L42,9.9z&quot;/>\n",
       "              <path d=&quot;M48.3,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3V0.3c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3 v17.3C48.5,17.8,48.5,17.9,48.3,17.9z&quot;/>\n",
       "              <path d=&quot;M61.4,12.6c0,0.2-0.1,0.3-0.3,0.3h-8.5c0.1,0.9,0.5,1.6,1.1,2.2c0.7,0.6,1.6,0.9,2.7,0.9 c1,0,1.8-0.3,2.6-0.8c0.2-0.1,0.3-0.1,0.4,0l1.2,1.3c0.1,0.1,0.1,0.3,0,0.4c-1.3,0.9-2.7,1.4-4.4,1.4c-1.8,0-3.3-0.6-4.4-1.8 c-1.1-1.2-1.7-2.7-1.7-4.5c0-1.7,0.6-3.2,1.7-4.4c1-1.1,2.4-1.6,4.1-1.6c1.6,0,2.9,0.6,4,1.7c1.1,1.2,1.6,2.6,1.5,4.4L61.4,12.6 z M58,8.7c-0.6-0.5-1.3-0.8-2.1-0.8c-0.8,0-1.5,0.3-2.1,0.8c-0.6,0.5-1,1.2-1.1,2H59C59,9.9,58.6,9.3,58,8.7z&quot;/>\n",
       "            </g>\n",
       "          </svg>\n",
       "        </a>\n",
       "      `\n",
       "      )`\n",
       "        display: inline-flex;\n",
       "      `;\n",
       "\n",
       "      const Header = styled((props) => {\n",
       "        const { environment } = useContext(Context);\n",
       "\n",
       "        return h`<div className=${props.className} >\n",
       "          <${Logo} />\n",
       "          <span><b>Left / Right Arrow:</b> Increase / Decrease Step</span><span><b>0-9 Row Keys:</b> Playback Speed</span><span><b>Space:</b> Pause / Play</span>\n",
       "          ${environment.title}\n",
       "        </div>`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        border-bottom: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        color: #fff;\n",
       "        display: flex;\n",
       "        flex: 0 0 36px;\n",
       "        font-size: 14px;\n",
       "        justify-content: space-between;\n",
       "        padding: 0 8px;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Renderer = styled((props) => {\n",
       "        const context = useContext(Context);\n",
       "        const { animate, debug, playing, renderer, speed } = context;\n",
       "        const ref = preact.createRef();\n",
       "\n",
       "        useEffect(async () => {\n",
       "          if (!ref.current) return;\n",
       "\n",
       "          const renderFrame = async (start, step, lastFrame) => {\n",
       "            if (step !== context.step) return;\n",
       "            if (lastFrame === 1) {\n",
       "              if (!animate) return;\n",
       "              start = Date.now();\n",
       "            }\n",
       "            const frame =\n",
       "              playing || animate\n",
       "                ? Math.min((Date.now() - start) / speed, 1)\n",
       "                : 1;\n",
       "            try {\n",
       "              if (debug) console.time(&quot;render&quot;);\n",
       "              await renderer({\n",
       "                ...context,\n",
       "                frame,\n",
       "                height: ref.current.clientHeight,\n",
       "                hooks: preactHooks,\n",
       "                parent: ref.current,\n",
       "                preact,\n",
       "                styled,\n",
       "                width: ref.current.clientWidth,\n",
       "              });\n",
       "            } catch (error) {\n",
       "              if (debug) console.error(error);\n",
       "              console.log({ ...context, frame, error });\n",
       "            } finally {\n",
       "              if (debug) console.timeEnd(&quot;render&quot;);\n",
       "            }\n",
       "            window.requestAnimationFrame(() => renderFrame(start, step, frame));\n",
       "          };\n",
       "\n",
       "          await renderFrame(Date.now(), context.step);\n",
       "        }, [ref.current, context.step, context.renderer]);\n",
       "\n",
       "        return h`<div className=${props.className} ref=${ref} />`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        box-sizing: border-box;\n",
       "        display: flex;\n",
       "        height: 100%;\n",
       "        left: 0;\n",
       "        justify-content: center;\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Processing = styled((props) => {\n",
       "        const { processing } = useContext(Context);\n",
       "        const text = processing === true ? &quot;Processing...&quot; : processing;\n",
       "        return h`<div className=${props.className}>${text}</div>`;\n",
       "      })`\n",
       "        bottom: 0;\n",
       "        color: #fff;\n",
       "        font-size: 12px;\n",
       "        left: 0;\n",
       "        line-height: 24px;\n",
       "        position: absolute;\n",
       "        text-align: center;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Viewer = styled((props) => {\n",
       "        const { processing } = useContext(Context);\n",
       "        return h`<div className=${props.className}>\n",
       "          <${Renderer} />\n",
       "          ${processing && h`<${Processing} />`}\n",
       "        </div>`;\n",
       "      })`\n",
       "        background-color: #000b2a;\n",
       "        background-image: radial-gradient(\n",
       "          circle closest-side,\n",
       "          #000b49,\n",
       "          #000b2a\n",
       "        );\n",
       "        display: flex;\n",
       "        flex: 1;\n",
       "        overflow: hidden;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      // Partitions the elements of arr into subarrays of max length num.\n",
       "      const groupIntoSets = (arr, num) => {\n",
       "        const sets = [];\n",
       "        arr.forEach(a => {\n",
       "          if (sets.length === 0 || sets[sets.length - 1].length === num) {\n",
       "            sets.push([]);\n",
       "          }\n",
       "          sets[sets.length - 1].push(a);\n",
       "        });\n",
       "        return sets;\n",
       "      }\n",
       "\n",
       "      // Expects `width` input prop to set proper max-width for agent name span.\n",
       "      const Legend = styled((props) => {\n",
       "        const { agents, legend } = useContext(Context);\n",
       "\n",
       "        const agentPairs = groupIntoSets(agents.sort((a, b) => a.index - b.index), 2);\n",
       "\n",
       "        return h`<div className=${props.className}>\n",
       "          ${agentPairs.map(agentList =>\n",
       "            h`<ul>\n",
       "                ${agentList.map(a =>\n",
       "                  h`<li key=${a.id} title=&quot;id: ${a.id}&quot; style=&quot;color:${a.color || &quot;#FFF&quot;}&quot;>\n",
       "                      ${a.image && h`<img src=${a.image} />`}\n",
       "                      <span>${a.name}</span>\n",
       "                    </li>`\n",
       "                )}\n",
       "              </ul>`)}\n",
       "        </div>`;\n",
       "      })`\n",
       "        background-color: #000b2a;\n",
       "        font-family: sans-serif;\n",
       "        font-size: 14px;\n",
       "        height: 48px;\n",
       "        width: 100%;\n",
       "\n",
       "        ul {\n",
       "          align-items: center;\n",
       "          display: flex;\n",
       "          flex-direction: row;\n",
       "          justify-content: center;\n",
       "        }\n",
       "\n",
       "        li {\n",
       "          align-items: center;\n",
       "          display: inline-flex;\n",
       "          transition: color 1s;\n",
       "        }\n",
       "\n",
       "        span {\n",
       "          max-width: ${p => (p.width || 400) * 0.5 - 36}px;\n",
       "          overflow: hidden;\n",
       "          text-overflow: ellipsis;\n",
       "          white-space: nowrap;\n",
       "        }\n",
       "\n",
       "        img {\n",
       "          height: 24px;\n",
       "          margin-left: 4px;\n",
       "          margin-right: 4px;\n",
       "          width: 24px;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const StepInput = styled.input.attrs({\n",
       "        type: &quot;range&quot;,\n",
       "      })`\n",
       "        appearance: none;\n",
       "        background: rgba(255, 255, 255, 0.15);\n",
       "        border-radius: 2px;\n",
       "        display: block;\n",
       "        flex: 1;\n",
       "        height: 4px;\n",
       "        opacity: 0.8;\n",
       "        outline: none;\n",
       "        transition: opacity 0.2s;\n",
       "        width: 100%;\n",
       "\n",
       "        &:hover {\n",
       "          opacity: 1;\n",
       "        }\n",
       "\n",
       "        &::-webkit-slider-thumb {\n",
       "          appearance: none;\n",
       "          background: #1ebeff;\n",
       "          border-radius: 100%;\n",
       "          cursor: pointer;\n",
       "          height: 12px;\n",
       "          margin: 0;\n",
       "          position: relative;\n",
       "          width: 12px;\n",
       "\n",
       "          &::after {\n",
       "            content: &quot;&quot;;\n",
       "            position: absolute;\n",
       "            top: 0px;\n",
       "            left: 0px;\n",
       "            width: 200px;\n",
       "            height: 8px;\n",
       "            background: green;\n",
       "          }\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const PlayButton = styled.button`\n",
       "        align-items: center;\n",
       "        background: none;\n",
       "        border: none;\n",
       "        color: white;\n",
       "        cursor: pointer;\n",
       "        display: flex;\n",
       "        flex: 0 0 56px;\n",
       "        font-size: 20px;\n",
       "        height: 40px;\n",
       "        justify-content: center;\n",
       "        opacity: 0.8;\n",
       "        outline: none;\n",
       "        transition: opacity 0.2s;\n",
       "\n",
       "        &:hover {\n",
       "          opacity: 1;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const StepCount = styled.span`\n",
       "        align-items: center;\n",
       "        color: white;\n",
       "        display: flex;\n",
       "        font-size: 14px;\n",
       "        justify-content: center;\n",
       "        opacity: 0.8;\n",
       "        padding: 0 16px;\n",
       "        pointer-events: none;\n",
       "      `;\n",
       "\n",
       "      const Controls = styled((props) => {\n",
       "        const { environment, pause, play, playing, setStep, step } = useContext(\n",
       "          Context\n",
       "        );\n",
       "        const value = step + 1;\n",
       "        const onClick = () => (playing ? pause() : play());\n",
       "        const onInput = (e) => {\n",
       "          pause();\n",
       "          setStep(parseInt(e.target.value) - 1);\n",
       "        };\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            <${PlayButton} onClick=${onClick}><svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24px&quot; height=&quot;24px&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;#FFFFFF&quot;>${\n",
       "          playing\n",
       "            ? h`<path d=&quot;M6 19h4V5H6v14zm8-14v14h4V5h-4z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n",
       "            : h`<path d=&quot;M8 5v14l11-7z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n",
       "        }</svg><//>\n",
       "            <${StepInput} min=&quot;1&quot; max=${\n",
       "          environment.steps.length\n",
       "        } value=&quot;${value}&quot; onInput=${onInput} />\n",
       "            <${StepCount}>${value} / ${environment.steps.length}<//>\n",
       "          </div>\n",
       "        `;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        border-top: 4px solid #212121;\n",
       "        display: flex;\n",
       "        flex: 0 0 44px;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const Info = styled((props) => {\n",
       "        const {\n",
       "          environment,\n",
       "          playing,\n",
       "          step,\n",
       "          speed,\n",
       "          animate,\n",
       "          header,\n",
       "          controls,\n",
       "          settings,\n",
       "        } = useContext(Context);\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            info:\n",
       "            step(${step}),\n",
       "            playing(${playing ? &quot;T&quot; : &quot;F&quot;}),\n",
       "            speed(${speed}),\n",
       "            animate(${animate ? &quot;T&quot; : &quot;F&quot;})\n",
       "          </div>`;\n",
       "      })`\n",
       "        color: #888;\n",
       "        font-family: monospace;\n",
       "        font-size: 12px;\n",
       "      `;\n",
       "\n",
       "      const Settings = styled((props) => {\n",
       "        const { environment, pause, play, playing, setStep, step } = useContext(\n",
       "          Context\n",
       "        );\n",
       "\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            <${Info} />\n",
       "          </div>\n",
       "        `;\n",
       "      })`\n",
       "        background: #fff;\n",
       "        border-top: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        padding: 20px;\n",
       "        width: 100%;\n",
       "\n",
       "        h1 {\n",
       "          font-size: 20px;\n",
       "        }\n",
       "      `;\n",
       "\n",
       "      const Player = styled((props) => {\n",
       "        const context = useContext(Context);\n",
       "        const { agents, controls, header, legend, loading, settings, width } = context;\n",
       "        return h`\n",
       "          <div className=${props.className}>\n",
       "            ${loading && h`<${Loading} />`}\n",
       "            ${!loading && header && h`<${Header} />`}\n",
       "            ${!loading && h`<${Viewer} />`}\n",
       "            ${!loading && legend && h`<${Legend} width=${width}/>`}\n",
       "            ${!loading && controls && h`<${Controls} />`}\n",
       "            ${!loading && settings && h`<${Settings} />`}\n",
       "          </div>`;\n",
       "      })`\n",
       "        align-items: center;\n",
       "        background: #212121;\n",
       "        border: 4px solid #212121;\n",
       "        box-sizing: border-box;\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "        height: 100%;\n",
       "        justify-content: center;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "      `;\n",
       "\n",
       "      const App = () => {\n",
       "        const renderCountRef = useRef(0);\n",
       "        const [_, setRenderCount] = useState(0);\n",
       "\n",
       "        // These are bindings to the 0-9 keys and are milliseconds of timeout per step\n",
       "        const speeds = [\n",
       "          0,\n",
       "          3000,\n",
       "          1000,\n",
       "          500,\n",
       "          333, // Default\n",
       "          200,\n",
       "          100,\n",
       "          50,\n",
       "          25,\n",
       "          10,\n",
       "        ];\n",
       "\n",
       "        const contextRef = useRef({\n",
       "          animate: false,\n",
       "          agents: [],\n",
       "          controls: false,\n",
       "          debug: false,\n",
       "          environment: { steps: [], info: {} },\n",
       "          header: window.innerHeight >= 600,\n",
       "          height: window.innerHeight,\n",
       "          interactive: false,\n",
       "          legend: true,\n",
       "          loading: false,\n",
       "          playing: false,\n",
       "          processing: false,\n",
       "          renderer: () => &quot;DNE&quot;,\n",
       "          settings: false,\n",
       "          speed: speeds[4],\n",
       "          step: 0,\n",
       "          width: window.innerWidth,\n",
       "        });\n",
       "\n",
       "        // Context helpers.\n",
       "        const rerender = (contextRef.current.rerender = () =>\n",
       "          setRenderCount((renderCountRef.current += 1)));\n",
       "        const setStep = (contextRef.current.setStep = (newStep) => {\n",
       "          contextRef.current.step = newStep;\n",
       "          rerender();\n",
       "        });\n",
       "        const setPlaying = (contextRef.current.setPlaying = (playing) => {\n",
       "          contextRef.current.playing = playing;\n",
       "          rerender();\n",
       "        });\n",
       "        const pause = (contextRef.current.pause = () => setPlaying(false));\n",
       "\n",
       "        const playNext = () => {\n",
       "          const context = contextRef.current;\n",
       "\n",
       "          if (\n",
       "            context.playing &&\n",
       "            context.step < context.environment.steps.length - 1\n",
       "          ) {\n",
       "            setStep(context.step + 1);\n",
       "            play(true);\n",
       "          } else {\n",
       "            pause();\n",
       "          }\n",
       "        };\n",
       "\n",
       "        const play = (contextRef.current.play = (continuing) => {\n",
       "          const context = contextRef.current;\n",
       "          if (context.playing && !continuing) return;\n",
       "          if (!context.playing) setPlaying(true);\n",
       "          if (\n",
       "            !continuing &&\n",
       "            context.step === context.environment.steps.length - 1\n",
       "          ) {\n",
       "            setStep(0);\n",
       "          }\n",
       "          setTimeout(playNext, context.speed);\n",
       "        });\n",
       "\n",
       "        const updateContext = (o) => {\n",
       "          const context = contextRef.current;\n",
       "          Object.assign(context, o, {\n",
       "            environment: { ...context.environment, ...(o.environment || {}) },\n",
       "          });\n",
       "          rerender();\n",
       "        };\n",
       "\n",
       "        // First time setup.\n",
       "        useEffect(() => {\n",
       "          // Timeout is used to ensure useEffect renders once.\n",
       "          setTimeout(() => {\n",
       "            // Initialize context with window.kaggle.\n",
       "            updateContext(window.kaggle || {});\n",
       "\n",
       "            if (window.kaggle.playing) {\n",
       "                play(true);\n",
       "            }\n",
       "\n",
       "            // Listen for messages received to update the context.\n",
       "            window.addEventListener(\n",
       "              &quot;message&quot;,\n",
       "              (event) => {\n",
       "                // Ensure the environment names match before updating.\n",
       "                try {\n",
       "                  if (\n",
       "                    event.data.environment.name ==\n",
       "                    contextRef.current.environment.name\n",
       "                  ) {\n",
       "                    updateContext(event.data);\n",
       "                  }\n",
       "                } catch {}\n",
       "              },\n",
       "              false\n",
       "            );\n",
       "            // Listen for keyboard commands.\n",
       "            window.addEventListener(\n",
       "              &quot;keydown&quot;,\n",
       "              (event) => {\n",
       "                const {\n",
       "                  interactive,\n",
       "                  isInteractive,\n",
       "                  playing,\n",
       "                  step,\n",
       "                  environment,\n",
       "                } = contextRef.current;\n",
       "                const key = event.keyCode;\n",
       "                const zero_key = 48\n",
       "                const nine_key = 57\n",
       "                if (\n",
       "                  interactive ||\n",
       "                  isInteractive() ||\n",
       "                  (key !== 32 && key !== 37 && key !== 39 && !(key >= zero_key && key <= nine_key))\n",
       "                )\n",
       "                  return;\n",
       "\n",
       "                if (key === 32) {\n",
       "                  playing ? pause() : play();\n",
       "                } else if (key === 39) {\n",
       "                  contextRef.current.playing = false;\n",
       "                  if (step < environment.steps.length - 1) setStep(step + 1);\n",
       "                  rerender();\n",
       "                } else if (key === 37) {\n",
       "                  contextRef.current.playing = false;\n",
       "                  if (step > 0) setStep(step - 1);\n",
       "                  rerender();\n",
       "                } else if (key >= zero_key && key <= nine_key) {\n",
       "                  contextRef.current.speed = speeds[key - zero_key];\n",
       "                }\n",
       "                event.preventDefault();\n",
       "                return false;\n",
       "              },\n",
       "              false\n",
       "            );\n",
       "          }, 1);\n",
       "        }, []);\n",
       "\n",
       "        if (contextRef.current.debug) {\n",
       "          console.log(&quot;context&quot;, contextRef.current);\n",
       "        }\n",
       "\n",
       "        // Ability to update context.\n",
       "        contextRef.current.update = updateContext;\n",
       "\n",
       "        // Ability to communicate with ipython.\n",
       "        const execute = (contextRef.current.execute = (source) =>\n",
       "          new Promise((resolve, reject) => {\n",
       "            try {\n",
       "              window.parent.IPython.notebook.kernel.execute(source, {\n",
       "                iopub: {\n",
       "                  output: (resp) => {\n",
       "                    const type = resp.msg_type;\n",
       "                    if (type === &quot;stream&quot;) return resolve(resp.content.text);\n",
       "                    if (type === &quot;error&quot;) return reject(new Error(resp.evalue));\n",
       "                    return reject(new Error(&quot;Unknown message type: &quot; + type));\n",
       "                  },\n",
       "                },\n",
       "              });\n",
       "            } catch (e) {\n",
       "              reject(new Error(&quot;IPython Unavailable: &quot; + e));\n",
       "            }\n",
       "          }));\n",
       "\n",
       "        // Ability to return an action from an interactive session.\n",
       "        contextRef.current.act = (action) => {\n",
       "          const id = contextRef.current.environment.id;\n",
       "          updateContext({ processing: true });\n",
       "          execute(`\n",
       "            import json\n",
       "            from kaggle_environments import interactives\n",
       "            if &quot;${id}&quot; in interactives:\n",
       "                action = json.loads('${JSON.stringify(action)}')\n",
       "                env, trainer = interactives[&quot;${id}&quot;]\n",
       "                trainer.step(action)\n",
       "                print(json.dumps(env.steps))`)\n",
       "            .then((resp) => {\n",
       "              try {\n",
       "                updateContext({\n",
       "                  processing: false,\n",
       "                  environment: { steps: JSON.parse(resp) },\n",
       "                });\n",
       "                play();\n",
       "              } catch (e) {\n",
       "                updateContext({ processing: resp.split(&quot;\\n&quot;)[0] });\n",
       "                console.error(resp, e);\n",
       "              }\n",
       "            })\n",
       "            .catch((e) => console.error(e));\n",
       "        };\n",
       "\n",
       "        // Check if currently interactive.\n",
       "        contextRef.current.isInteractive = () => {\n",
       "          const context = contextRef.current;\n",
       "          const steps = context.environment.steps;\n",
       "          return (\n",
       "            context.interactive &&\n",
       "            !context.processing &&\n",
       "            context.step === steps.length - 1 &&\n",
       "            steps[context.step].some((s) => s.status === &quot;ACTIVE&quot;)\n",
       "          );\n",
       "        };\n",
       "\n",
       "        return h`\n",
       "          <${Context.Provider} value=${contextRef.current}>\n",
       "            <${Player} />\n",
       "          <//>`;\n",
       "      };\n",
       "\n",
       "      preact.render(h`<${App} />`, document.body);\n",
       "    </script>\n",
       "  </body>\n",
       "</html>\n",
       "\" width=\"300\" height=\"300\" frameborder=\"0\"></iframe> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "env.run([agent,\"negamax\"])\n",
    "env.render(mode=\"ipython\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T18:23:48.950220Z",
     "iopub.status.busy": "2020-09-01T18:23:48.915858Z",
     "iopub.status.idle": "2020-09-01T18:39:02.223197Z",
     "shell.execute_reply": "2020-09-01T18:39:02.223831Z"
    },
    "papermill": {
     "duration": 913.369225,
     "end_time": "2020-09-01T18:39:02.224027",
     "exception": false,
     "start_time": "2020-09-01T18:23:48.854802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 Win Percentage: 0.94\n",
      "Agent 2 Win Percentage: 0.04\n",
      "Number of Invalid Plays by Agent 1: 0\n",
      "Number of Invalid Plays by Agent 2: 0\n"
     ]
    }
   ],
   "source": [
    "get_win_percentages(agent1=agent, agent2=\"negamax\",n_rounds = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025034,
     "end_time": "2020-09-01T18:39:02.274712",
     "exception": false,
     "start_time": "2020-09-01T18:39:02.249678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Please upvote if you liked my work. I have tried to make this as intuitive as possible. Any suggestions are welcome. Thank You!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025358,
     "end_time": "2020-09-01T18:39:02.325361",
     "exception": false,
     "start_time": "2020-09-01T18:39:02.300003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "duration": 4769.002249,
   "end_time": "2020-09-01T18:39:02.460461",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-01T17:19:33.458212",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
